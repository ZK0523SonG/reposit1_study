■ 리눅스 수업 --> 하둡 수업---> 스파크 수업


  SQL --> 파이썬 --> R --> 머신러닝 --> 리눅스 --> 하둡 ---> 스파크 --> 딥러닝

설치 프로그램 다운로드 하겠습니다. 

■ 리눅스란 무엇인가 ?

  유닉스(unix) 가 너무 고가여서 리눅스 오픈소스를 핀란드의 리누즈 토발즈 학생이
  1991년 11월 개발한 os 운영 시스템입니다.   
  리누즈 토발즈가 리눅스 커널(자동차의 엔진과 같음)을 개발하고 
  소스를 무료로 공개를 했다. 그리고 전세계의 개발자들이 이 오픈소스를 가져다가
  더 좋게 개선해서 다시 인터넷에 올리고 또 올리고 하는 작업을 반복하다보니
  지금은 리눅스 os 가 유닉스보다 더 가볍고 안정적이고 더 대중화가 되었습니다. 

 GNU 프로젝트 ? 누구든지 배포된 오픈소스를 가져다가 개발할 수 있고 돈을 벌 목적으로
                       상용화를 할 수도 있는데 한가지 지켜야할 약속은 이 소스를 가져다가
                       더 좋게 수정했으면 그 코드를 인터넷에 올려줘야하는 약속입니다. 

    레드헷(유료) --------------> Cent os(무료)

▩ 리눅스의 종류 

 1. Oracle linux
 2. Cent os
 3. Ubunt 
 4. 기타 

▩ 하둡(Hadoop) 이란 ?

 하둡은 하나의 성능 좋은 컴퓨터를 이용하여 데이터를 처리하는 대신, 적당한 
 성능의 범용 컴퓨터 여러대를 클러스터화하고, 큰 크기의 데이터를 클러스터에서
 병렬로 동시에 처리하여 처리 속도를 높이는 분산처리 시스템입니다.

▩ 스파크(Spark) 란 ?

  하둡의 멥리듀스의 단점을 보완한 분산처리 엔진입니다.
   disk 기반으로 처리되는 하둡과는 달리 메모리 기반으로 처리되기 때문에
  하둡보다 속도가 10~1000배까지 빠르게 설계되었다.

 하둡위에 스파크를 얹어서 실시간 처리하는 아키텍쳐가 많이 쓰이고 있는데 
 예를 들어 zepplelin 이 있는데 데이터 분석의 불편함을 웹기반의 노트북을 통해서
 해결해보고자 만든 에플리케이션 시각화 툴등을 이용할 수 있습니다.

▩ 가상화란 ?

 여러분들 컴퓨터에 지금 윈도우 os 가 설치되어있는데 리눅스 os 를 배우기 위해서
 윈도우를 지워버리고 거기에 리눅스 os 시스템을 설치하게 되면 윈도우를 사용하지
 못하므로 너무 불편합니다. 

 여러분들 컴퓨터에 윈도우 os 안에 컴퓨터를 하나 넣고 거기에 리눅스 os 를 설치하게
 하는걸 가능하게 하는게 가상화 입니다. 

 * 가상화 툴 2가지 ?

  1. Oracle  VMware
  2. VMware

■ 리눅스 설치시 주의 사항 !

 1. 소프트웨어 설치할 때 GNOME 으로 설치하세요 ~
 2. centos7 설치파일이 있는 경로에 한글이 포함되어져 있으면 안됩니다.

■ 게스트 CD 확장 설치 

 왜 이 작업을 해야하는가 ?  마우스와 키보드를 윈도우와 리눅스 가상 컴퓨터를 왔다갔다 하게
                                      되면 불편한게 있어서 좀 편하게 가상 컴퓨터의 리눅스를 이용하기
                                     위해 작업을 해야 합니다.

 1.  root 로 접속한다.
 2.  장치 ---> 게스트 확장 cd 삽입을 누룹니다.
 3.  바로 실행하겠습니까라고 물어보면 바로 실행을 합니다.
 4.  그게 아니라 그냥 바탕화면에 Vbox 의 큰 원형cd 모양이 생성만 되었다면
      클릭해서 열고 상단 옆에 프로그램 실행을 눌러서 설치합니다
 5. 재부팅 합니다. 
 6. 재부팅하고 root 로 접속합니다. 

■ 리눅스 시스템에서 인터넷이 되게 설정하는 방법

 1. root 로 접속합니다. 
 2. 리눅스의 시작 버튼을 누른다.
 3. 시스템 도구의 설정을 누룹니다. 
 4. 네트워크를 누룹니다. 
 6. 유선을 켭니다. 
 7. firfox 를 켜고 네이버로 접속합니다. 

■ 윈도우와 복사 붙여넣기를 자유롭게 할 수 있도록 하는 방법 

1. 터미널 창을 엽니다. 

2. 아래의 명령어를 실행합니다. 

1) yum install kernel sources

2) yum install kernel-devel

3) yum install make

4) yum install gcc

5 ) 재부팅 (reboot)

6) 리눅스 창 상단에 장치>클립보드공유>양방향 하면 복붙가능

7) Ctrl + Shift + C , V 를 눌러도 복사 붙여넣기 가능 

■ 리눅스 기본 명령어 

▩ 1. cd 명령어 

 Change Directory 명령어로 디렉토리를 이동하는 명령어 입니다.

실습:  # whoami   <--- 접속한 내가 누구인지 확인하는 명령어
        # pwd    <--- 현재 내가 있는 디렉토리를 확인하는 명령어
                           (print  working directory) 
        # ls     <---- list 명령어로 현재 디렉토리의 있는 폴더와 파일을 확인 

        # cd ..   <-- 상위 디렉토리로 이동하겠다
        # pwd 
 
        # cd media   <--- media 디렉토리로 이동한다

문제1.  현재 디렉토리가 어딘지 확인하시오 !

# pwd

문제2.  pwd 했을때 현재 디렉토리가 아래의 디렉토리가 되게하시오 !

# pwd

/home

문제3. 지금 디렉토리에서 다음의 디렉토리로 이동하는데 pwd 했을때 아래의 디렉토리가
        되게 하시오 !

# pwd

/media 

※ 경로에는 크게 2가지 경로가 있다.

1. 절대경로 :  cd "내가 가고자하는 위치" 
예:
[root@localhost media]# pwd
/media
[root@localhost media]# 
[root@localhost media]# cd /root   <--- 내가 이동하고자 하는 위치 
[root@localhost ~]# pwd
/root

2. 상대경로 : 나의 현재위치를 상대로 이동하겠다

  예: cd  ..  <---  나의 현재위치를 상대로 상위 디렉토리로 이동하겠다.

예:
[root@localhost ~]# pwd
/root
[root@localhost ~]# cd ..   <-- 현재 내 디렉토리에서 상위 디렉토리로 이동하겠다.
[root@localhost /]# pwd
/
[root@localhost /]# cd root  <-- 현재 내 디렉토리에 있는 root 폴더로 이동하겠다. 
[root@localhost ~]# pwd
/root

문제4. pwd 했을때 아래의 디렉토리가 되게하시오 !

# pwd

/home/oracle 

문제5. 지금 현재 상태에서 나의 집으로 돌아가고 싶다면 ?

# whoami   <--- 유져이름의 폴더가 바로 이 유져의 집입니다. 

# cd    

※ cd 하고 바로 엔터를 치면 자기 집으로 바로 이동합니다. 

문제6. 나의 집에서 test01 이라는 디렉토리를 생성하시오 !

# cd

# mkdir  test01 

# ls 

문제7.  나의 집에서 test02 라는 디렉토리를 생성하고 test02 로 이동하시오 !


문제8.  다시 test01 디렉토리로 이동하세요 


문제9. 지금 현재 디렉토리인 /root/test01 에서 /home/oracle 밑으로 바로 이동하세요! 

[root@localhost test01]# cd /home/oracle
[root@localhost oracle]# pwd
/home/oracle

문제10. 그럼 다시 원래 있었던 위치로 이동하시오 !

[root@localhost oracle]# cd -   <--- 바로 전에 있었던 위치로 한번에 이동하는 방법 
/root/test01
[root@localhost test01]# pwd
/root/test01

 " 회사의 모든 데이터는 다 리눅스 서버에 저장되어있다 "

■ 2. touch 명령어 

 " 파일의 용량이 0 인 파일을 생성하는 명령어 "

예:  
     # cd  
     # touch  a1.txt 
     # ls -l a1.tx
     -rw-r--r--. 1 root root   0    8월  9 10:23 a1.txt
                                    ↑
                              파일의 크기 

문제11.  나의 집 디렉토리에서 아래의 파일들을 크기가 0으로 생성하시오 

 a.txt    b.txt    c.txt    e.txt    f.txt 

# cd

# touch  a.txt   b.txt   c.txt   e.txt   f.txt 

# ls

# ls  -l   *.txt     <------  확장자가  .txt 로 끝나는 파일들을 보여달라 ~
      ↑
   파일에 대한 정보를 보여달라는 옵션

■ 3. mkdir 명령어 

 " 디렉토리를 만드는 명령어 "

예:  # mkdir  bigdata   <--  bigdata 라는 디렉토리 생성

      # whatis  mkdir   <--- mkdir 명령어의 메뉴얼 확인 

      # man  mkdir  <--- mkdir 명령어의 메뉴얼 확인 

             q  <--- 메뉴얼 화면 빠져나오는 명령어 

문제12. /root/bigdata 디렉토리 밑에 아래와 같이 하위 디렉토리들을 생성하시오 !

/root/bigdata/test1/test2/test3/test4/test5 

문제13.  /root/bigdata 밑에 아래의 디렉토리를 아래와 같이 생성하시오 !

/root/bigdata/data1/data2/data3/data4/data5

답:
[root@localhost bigdata]# pwd
/root/bigdata
[root@localhost bigdata]# mkdir -p data1/data2/data3/data4/data5

설명:  -p 옵션은 디렉토리를 만들면서 한번에 하위 디렉토리를 생성하는 옵션 

■ 4. rm 명령어 

 " 파일이나 디렉토리를 삭제하는 명령어"

※ 주의사항 !!!!  

  리눅스나 유닉스는 윈도우와 같은 휴지통이 없기 때문에 삭제할 때 특히 주의해야합니다. !!!
  잘못해서 리눅스 운영에 필요한 시스템 파일들을 삭제하게 되면 리눅스 시스템이 망가질수 
  있습니다. 

예제:  #  cd
        #  touch  bbb.txt
        #  ls
        # rm  bbb.txt
        #  ls  

문제14.  root 집에 있는 a.txt 와 b.txt 를 rm 으로 지우시오 ~

# cd

※  rm  -rf   *  

설명:  현재 디렉토리 밑에 있는 모든 파일과 디렉토리를 다 삭제하겠다. 

 -r 옵션 :  현재 디렉토리 밑에 있는 모든 파일과 디렉토리를 삭제하겠다.
 -f 옵션 :  삭제할 때 원래는 삭제할까요? 라고 물어보는데 물어보지않고 그냥 강제로 
             다 삭제해라 ~

■ 5. rmdir  명령어 

 " 디렉토리를 삭제하는 명령어 "

예제: # rmdir  디렉토리명 
       # cd
       # mkdir  ddd 
       # ls
       # rmdir  ddd
       # ls  

문제15. 집에 있는 bigdata 라는 디렉토리를 삭제하시오 !

# rm  -rf  bigdata

문제16. 리눅스용 emp.txt 를 리눅스 시스템에 넣으시오 !


■ 6. alias 명령어 

 "자주 수행하는 명령어들을 쉽게 사용할 수 있도록 설정하는 명령어 "

예:  파이썬으로 접속하세요

python 명령어에 대한 alias 를 p 로 생성합니다. 

# alias  p="python"
# p

문제17. alias 로 등록된 명령어들을 보시오 ~

# alias   <--- 등록된 alias 들을 다 볼 수 있습니다. 

문제18.  스티븐 잡스 연설문 jobs.txt 를 리눅스 시스템에 넣으시오 

  root 집인 /root 밑에 가져다 놓으세요 ~

■ 7. cat 명령어 

 " 파일의 내용을 화면에 출력하는 명령어 "

예제: # cat  emp.txt 
       # cat  jobs.txt 

       # more  jobs.txt   

    스페이스바 또는 엔터를 누르면 아래로 내려오는데 q 를 누르면 바로 빠져나와 버립니다.


■ 8. redirection 명령어 

 " 화면에 출력되는 결과를 파일로 저장하는 명령어 "

 >>  :  없으면 파일을 생성하고 있으면 기존 파일 뒤에 덧붙이겠다.
 >    :  파일을 생성하겠다. 기존에 파일이 있으면 그냥 덮어 쓰겠다.

예제:  #  cat  emp.txt  >>  emp2.txt 
   
설명:  emp.txt 를 출력하고 출력되는 결과를 emp2.txt 로 저장해라 ~

       # ls  emp2.txt
       #  cat  emp.txt  >> emp2.txt

설명:  emp2.txt 가 이미 존재하므로 내용 아래에 덧붙였습니가. 그래서 28개의 행이 되었습니다. 

문제19. jobs.txt 를 출력한 결과를 jobs2.txt 로 저장하시오 ~

[root@localhost ~]# cat jobs.txt >> jobs2.txt

문제20.  ls -l  *.txt  로 출력되는 결과를  test_list.txt 로 생성하시오 !
               ↑
  확장자가 .txt 로 끝나는 파일들의 리스트를 보여달라 ~

■ 9. more 명령어 

  1페이지가 넘는 문서의 내용을 화면에 출력할 때 페이지 단위로 볼 수 있는 명령어 

예제:  $ more  jobs.txt  

   전진키:  스페이스
   후진키:  b
   페이지 단위로 내려가는것은 :  f  

■ 10. head 명령어 

 "문서의 처음 몇줄을 화면에 출력하는 명령어"

예제:  # head  출력줄수  파일명
        # head -20  jobs.txt  

설명: 처음부터 20줄까지만 보여달라 ~

문제21. emp.txt 의  위의 3줄을 출력하시오 !

# head -3  emp.txt

문제22. emp.txt 의 뒤의 3줄을 출력하시오 !

# tail -3  emp.txt 

문제23. (점심시간 문제)  jobs.txt 의 뒤의 10줄을 jobs_tail.txt 로 저장하고 jobs_tail.txt 를
          출력하시오 !

■ 11. wc 명령어 

 " 파일안의 단어의 갯수 또는 라인수를 출력하는 명령어 "

예제: $ wc   파일명 
       $ wc  jobs.txt 

 143        2260           12176      jobs.txt
  ↑          ↑                ↑
라인수  단어의 갯수     문자수를 출력 

  # wc -l  jobs.txt
  # wc -w jobs.txt
  # wc -c jobs.txt   

문제24.  emp.txt 의 전체 라인수를 출력하시오 !

 # wc -l  emp.txt 

■ 12. grep 명령어 

 " 파일안에 포함된 특정 단어나 구문을 검색하는 명령어"

예:  # grep '찾고 싶은 단어'  파일명 
  
      # grep  'SCOTT'  emp.txt 

      # grep  -i  'scott'  emp.txt  

설명: -i 옵션은 대소문자를 구분하지 않겠다.

문제25. 직업이 salesman 인 사원들의 모든 행을 출력하시오 !

# grep -i 'salesman'  emp.txt

문제26. 직업이 salesman인 사원들의 이름과 월급을 출력하시오 !

# grep -i 'salesman'  emp.txt  |  awk '{ print $2, $6 }' 


 ☞ pipe 명령어 ?   앞의 명령어 | 뒤의 명령어

    앞의 명령어의 출력을 뒤의 명령어의 입력으로 보냄으로써 실행결과를
    다음 명령어로 전달하는 기능 

 ☞ awk 명령어 ?  열을 검색하는 명령어 

문제27.  이름이 scott 인 사원의 이름과 월급과 직업을 출력하시오 !

grep -i 'scott' emp.txt | awk '{print $2, $6, $3}'

문제28. 직업이 analyst 인 사원들의 이름과 직업과 부서번호를 출력하시오 !

grep -i 'analyst' emp.txt | awk '{print $2, $3, $8}' 

2억건 되는 csv 파일 데이터를 테이블을 생성, insert 도 해줘야 sql 로 검색가능
2억건 데이터에서 40대인 데이터만 따로 파일로 생성하겠다. 
리눅스 명령어가 훨씬 빠르고 간편하다. 

문제29. 부서번호가 10번인 사원들의 이름과 월급을 출력하시오 !

grep  -iw  '10'  emp.txt

※ 설명:  옵션 -w 는 단어별 검색 

위의 데이터를 검색하려면 awk 명령어를 알아야 합니다.

문제30. 직업이 salesman 인 사원들이 전부 몇명인지 출력하시오 !

grep -i salesman emp.txt | wc -l

문제31.  ls -l *.txt 로 출력된 결과의 라인수를 출력하시오 !

ls  -l  *.txt  |  wc  -l

                                           
■ 13. awk 명령어 

  " 특정 컬럼을 출력하고자 할때 사용하는 명령어 "

예:  # awk  '$3=="SALESMAN"  {print $2, $3}'   emp.txt
                         ↑                 ↑                 ↑
                       조건              컬럼선택        대상파일 

문제32. 월급이 3000 이상인 사원들의 이름과 월급을 출력하시오 !

awk '$6>=3000 {print $2,$6}' emp.txt

※ 리눅스의 연산자 3가지 

1. 산술 연산자 :  +, -, *, /
2. 비교 연산자 : >, <, >=, <=, ==, !=
3. 논리 연산자 :  &&, ||, !

문제33.  직업이 salesman 이 아닌 사원들의 이름과 직업을 출력하시오 

awk '$3 != "SALESMAN"  {print $2, $3}' emp.txt

문제34. 지금 위에서 출력된 결과를 notsalesman.txt 로 저장하시오 !

# awk '$3 != "SALESMAN" {print $2,$3}' emp.txt >> notsalesman.txt

문제35. 부서번호가 10번인 사원들의 이름과 월급과 부서번호를 출력하시오

awk '$8==10 {print $2, $6, $8}' emp.txt

문제36.  직업이 salesman 이고 월급이 1200 이상인 사원들의 이름과 월급과
            직업을 출력하시오 !

# awk '$3 == "SALESMAN" &&  $5 >= 1200 {print $2,$6,$3}' emp.txt

문제37.  1981년도에 입사한 사원들의 이름과 입사일을 출력하시오 !

# awk  'substr($5, 1, 4)=="1981" {print $2, $5}'  emp.txt

# man  awk

※ 설명: substr( 문자열, 시작자릿수, 끝자릿수) 

문제38. emp.txt 에서 입사일이 1981년 데이터의 모든 행들만 emp_1981.csv 로
          저장하시오 !

# awk 'substr($5, 1, 4) == 1981' emp.txt >> emp_1981.csv

문제39. 이름의 첫글자가 A 로 시작하는 사원들의 이름과 월급을 출력하시오 !

awk 'substr($2, 1, 1) == "A" {print $2 $6}' emp.txt

■ 14. sort 명령어 

 " data 를 특정 컬럼을 기준으로 정렬하는 명령어 "

예제:  $ sort  옵션   파일명 
        $ sort  -nk  6  emp.txt  # 월급이 낮은 사원부터 높은 사원순으로 출력해라
        $ sort  -nrk 6  emp.txt  # 월급이 높은 사원부터 낮은 사원순으로 출력해라

문제40. 직업이 SALESMAN 인 사원들의 이름과 월급을 출력하는데
          월급이 높은사원부터 출력하시오 !

# 직업이 SALESMAN 인 사원들의 이름과 월급을 출력 | sort 명령어 

awk '$3=="SALESMAN" {print $2,$6}' emp.txt  | sort -nrk 2

문제41.  문제40번에서 출력된 결과에서 위의 1줄만 출력하시오 !

awk '$3=="SALESMAN" {print $2,$6}' emp.txt  | sort -nrk 2 | head -1

■ 15. uniq 명령어 

 "중복된 라인을 제거하는 명령어"

예:  $ uniq  옵션  파일명 

 "직업을 중복 제거해서 출력해라 ~ "

예제1. emp.txt 에서 직업만 출력하시오 !

# awk  '{ print $3 }'  emp.txt 

예제2. 위의 결과를 abcd 순으로 정렬해서 출력하시오 !

# awk  '{ print $3 }'  emp.txt  | sort -k 1

예제3. 위의 결과를 출력할때 중복제거해서 출력하시오 !

# awk  '{ print $3 }'  emp.txt  | sort -k 1 | uniq 

문제42.  부서번호를 출력하는데 중복제거해서 출력하시오 !

awk '{ print $8 }' emp.txt | sort -k 1 | uniq

문제43. 부서번호가 20번인 사원들의 직업을 출력하는데 중복을 제거해서 출력하시오

# awk ' $8 == 20 {print $3} ' emp.txt | sort -k 1 | uniq

■ putty 로 리눅스 서버에 접속하는 방법 

1. oracle vm virtual box 의 파일--> 호스트 네트워크 관리자를 엽니다. 

 192.168.56.1 이  호스트 네트워크 아이피 주소입니다.

2. 리눅스 터미널창에서  vi /etc/hosts.allow  을 열고 맨아래에 다음의 명령어를 입력하고
  저장하고 나옵니다. 

sshd: 192.168.56.1

3. 리눅스 터미털창에서 ifconfig 명령어로 리눅스 서버의 ip 주소가 어떻게 되는지 
   확인합니다.


4.  포트포워딩을 해줘야합니다. 

5. putty 를 이용해서 리눅스 서버에 접속합니다. 

문제44. (오늘의 마지막 문제) emp.txt 의 데이터를 3개로 만드는데
부서번호가 10번인 사원들은 deptno_10.csv 로 생성하고
부서번호가 20번인 사원들은 deptno_20.csv 로 생성하고 
부서번호가 30번인 사원들은 deptno_30.csv 로 생성하시오 ~


 리눅스 --> 마리아 디비 ---> 하둡 ---> hive 

 빅데이터든 스몰 데이터든 대부분의 데이터들은 다 리눅스 시스템에 저장되어 있습니다. 


■ 리눅스 명령어 복습 

 1. cd  : 디렉토리 이동
 2. mkdir :  디렉토리 생성
 3. ls  :    디렉토리에 있는 파일이나 폴더 리스트를 보는 명령어
 4. rm :  파일 삭제
 5. rmdir : 디렉토리 삭제
 6. wc :   파일에 라인수,워드수, 단어수를 카운트
 7. grep :  파일에 특정 단어를 검색할 때
 8. awk  :  파일에 특정 컬럼을 검색할 때
 9. sort  :  데이터를 정렬해서 볼때
 10. uniq:  중복제거 
 11. touch : 0 바이트 파일 생성 
 12. cat : 파일의 내용확인

문제45.  직업이 MANAGER 인 사원들의 이름과 월급과 직업을 출력하시오 !

# awk '$3=="MANAGER" {print $2,$6,$3}' emp.txt

문제46. 직업이 SALESMAN 인 사원들의 이름과 월급과 직업을 출력하는데 월급이
          높은 사원부터 출력하시오 !


문제47. 네이버 영화에서 최근에 스크롤링한 영화리뷰와 평점(게시글 75번)을
          리눅스 서버에 올리시오 ~ ( /root 밑에 올리세요)


문제48.  네이버 영화 리뷰에서 모가디슈가 포함된 행들을 출력하시오 !

# grep -i '모가디슈' reviewData2.csv

문제49. 위에서 출력된 행들의 갯수를 출력하시오 !

# grep -i '모가디슈' reviewData2.csv  | wc -l

3581

문제50.  reviewData2.csv 에서 첫번째 열이 모가디슈인 행들을 모두 출력하시오!

# awk -F ','  '$1=="모가디슈"'  reviewData2.csv

문제51. 최신 네이버 영화 리뷰(reviewData2.csv) 에서 첫번째 열이 모가디슈인
          행들만  moga.csv 로 저장하시오

# awk -F ','  '$1=="모가디슈"'  reviewData2.csv >> moga.csv 

문제52. moga.csv 에서 영화평점이 10점인 리뷰들만 출력하시오 !

# awk -F ','  '$2=="10"'  moga.csv 

문제53. moga.csv 에서 영화평점이 1점인 리뷰들만 출력하시오 !

# awk -F ','  '$2=="1"'  moga.csv 

문제54. moga.csv 에서 영화평점이 7이상인 리뷰들이 몇건이 있는지 출력하고
           7 보다 작은 리뷰들이 몇건이 있는지 출력하시오 !

 답글로 올려주세요 ~   45분까지 쉬세요 ~

awk -F ',' '$2>= 7' moga.csv  |wc -l

더블 쿼테이션 마크를 안써야 10점이 위의 코드에서 10점이 나옵니다.

 숫자 10은 숫자 7보다 크지만  만약에 문자가 되면 문자 10 은 문자 7보다 작은값입니다. 

[root@localhost ~]# awk -F ',' '$2>=7' moga.csv | wc -l
2395

[root@localhost ~]# awk -F ',' '$2<7' moga.csv | wc -l
1173

문제55.  네이버 최신영화 리뷰에서 조인성이라는 단어를 포함하는 영화제목을 출력하시오

# grep -i  '조인성'   reviewData2.csv | awk -F ',' '{print $1}'  |  sort | uniq

■ 16. echo 명령어 

  출력하고자 하는 글자를 출력할 때 사용하는 명령어 인데 
  파이썬으로 예를 들면 print 와 같은 명령어 입니다. 변수에 있는 데이터 출력하는 
  명령어 입니다. 

예제:  # a=1
        # echo $a
        # b='scott'
        # echo $b 

설명: 변수안에 있는 값을 출력할 때는 $ 를 앞에 붙여줘야합니다. 

예: 
# echo "hi ~~~~"

▦ vi 편집기 명령어를 간단하게 연습해보기 

 vi 편집기는 윈도우로 치면 메모장 같은 것입니다. 
 리눅스의 메모장 기능인 vi 편집기는 명령어를 알고 있어야 사용할 수 있습니다.

예제1. 제목이 a100.txt 인 파일을 생성하는 방법

#  vi  a100.txt 

 i : 입력 모드 

 esc 키를 누르면  입력모드에서 command 모드로 변경됩니다. 

 * vi 편집기 명령모드 3가지

1. command 모드:
      vi 편집기의 기본 모드이며 vi 를 실행하면 바로 보이는 화면을 말합니다. 
      이 상태에서는 방향키로 왔다갔다 할 수 있습니다. 

   h : 왼쪽으로 이동
   l  : 오른쪽으로 이동
   j  : 아래로 이동
   k : 위로 이동 

2. edit 모드 :
   
   a, i, o, x 등을 누르면서 내용을 입력 또는 삭제하는 명령모드

  i : 입력모드
 a : 입력모드인데 계속 덧붙여서 쓰겠다.
 o  : 입력모드인데 다음라인에 쓰겠다
 x  :  철자하나 삭제 

3. last line 모드 

 입력모드에서 저장, 종료, 강제종료등의 명령어를 입력하는 모드 

 :wq!    저장하고 종료 (단축키: ZZ)
 : q!      저장안하고 종료 (단축키: ZQ)

문제56.  bbb.txt 를 생성하는데 bbb.txt 에 아래의 내용이 저장되게하시오 

select ename, sal
 from emp
 where empno = 7788;

▩ vi 편집기 내에서 커서 이동 

 1. j : 아래로 이동
 2. k : 위로 이동
 3. h : 왼쪽으로 이동
 4. l  : 오른쪽으로 이동
 5. 1G : 맨위로 이동
 6. G : 맨 아래로 이동
 7. :set nu   : 파일내의 텍스트에 번호 표시
 8. :set nonu : 번호 안보이게 하는 명령어 
 9. gg : 맨위로 이동하는 단축키 

예제1. jobs.txt 를 열어서 맨 아래로 이동하시오 !

▩ vi 편집기의 삭제 명령어 

1. x  : 철자 하나 삭제
2. dd :  한 행 삭제 
3. dw :  커서가 있는 단어 삭제
4. :5,10 d : 5~10번째 행 삭제
5. D :  커서 오른쪽 행 삭제 

예제1.  jobs.txt 를 jobs2.txt 로 백업합니다. 

# cp  jobs.txt  jobs2.txt 

예제2. jobs2.txt 를 열어서 5번째 행을 지우시오 

예제3. jobs2.txt 를 열어서 위에 3줄만 남기고 다 지우시오 !

▩ vi 편집기의 취소 명령어

 u :  방금 작업했던거 취소하겠다

▩ vi 편집기의 복사/붙여넣기 명령어 

1. yy : 하나의 행을 복사
2. p  : 붙여넣기
3. yG : 현재행부터 파일 끝까지 복사
4. :1,2 co 3  :  1~2행을 3행 다음으로 복사 
5. :1,2 m  3  : 1~2행을 3행 다음으로 이동 

예제1. jobs.txt 를 jobs3.txt 로 백업하시오 !  

# cp  jobs.txt   jobs3.txt  

예제2. jobs3.txt 를 열어서 맨위에 한줄을 복사해서 다음 라인에 붙여넣으시오 

▩ vi 편집기 내에서 특정 문자를 검색하는 방법 

1.  / 검색어     : 검색어를 찾아줍니다. 

 n 을 누르면 전진하면서 검색어를 찾아주고
 shift + n 을 누르면 후진하면서 검색어를 찾아줍니다. 

예제1. emp.txt 를 열어서 SCOTT 이라는 문자가 있는지 검색하시오 !

/SCOTT

문제57. 스티븐 잡스 연설문(jobs.txt) 에서 about 이라는 단어를 검색하시오 !


▩ vi 편집기 명령어로 문자를 변경하는 방법 

문법 :   :%s/기존문자/변경할 문자/g

예제1. emp.txt 에서 KING 을 aaa 로 변경하시오 !


문제58.  (점심시간 문제) 스티븐 잡스 연설문(jobs.txt) 에서  about 이라는 단어 모두를 
            kkkkkk 로 변경하시오!
         
화면 캡쳐한것을 답글올려주세요 ~~~

문제59.  emp.txt 를 emp1.txt ~ emp20.txt 로 복사하세요 

$ cp  emp.txt  emp1.txt
$ cp  emp.txt  emp2.txt 
           :
$ cp  emp.txt  emp20.txt 

문제60.  emp.txt  ~  emp20.txt 까지의 내용중에서 SALESMAN 을 jjj 로 변경하시오!

$ vi  emp*.txt 

 :argdo  %s/SALESMAN/jjj/g  | update 


▩ echo 명령어 

 1. 변수에 있는값을 출력할때 사용
 2. 문자열을 그대로 출력할 때 사용 

문제61.  이름이 SCOTT 인 사원의 이름과 월급을 출력하시오 !

# awk  '$2=="SCOTT"  {print $2, $6}'  emp.txt 

문제62. 이름을 물어보게하고 이름을 입력하면 해당 사원의 이름과 월급이 출력되게
           하시오 !

# vi  find_sal.sh 

echo -n 'Enter the ename ~~'
read  ename
awk -v num=$ename '$2==toupper(num) {print $2,$6}' emp.txt

설명: echo 의 -n 옵션을 사용하면 Enter  the ename ~~ 메세지 출력해주고 
       그 다음 라인을 실행합니다. 
       awk 의 -v 옵션을 사용해야 $ename 의 변수의 값이 num 이라는 변수에 들어갑니다

문제63. 이름을 물어보게하고 이름을 입력하면 해당 사원의 직업이 출력되는 
           쉘스크립트를 작성하시오 !

# sh  find_job.sh

 Enter  the  ename :  scott

  ANALYST 

# vi  find_job.sh 

echo -n 'Enter the ename ~~'
read  ename
awk -v num=$ename '$2==toupper(num) {print $3}' emp.txt

문제64.  네이버 영화 리뷰 데이터(reviewData2.csv)에서 영화이름이 모가디슈인
           행들 평점 컬럼만 출력하시오 !

awk -F ',' '$1=="모가디슈" {print $2}' reviewData2.csv

문제65. 위의 결과중에 평점이 10점인 행들의 건수를 출력하시오 !

awk -F ',' '$1=="모가디슈" {print $2}' reviewData2.csv  | grep -i '10' | wc -l

문제66. 다음과 같이 영화이름을 물어보게하고 영화이름을 입력하면 10점인 행들의
           건수가 출력되게하는 쉘스크립트를 작성하시오 

# sh  find_10_cnt.sh

  Enter  the  cinema :   딥워터

답: 
# vi  find_10_cnt.sh 

echo -n "Enter the cinema: "
read cinema 
awk -F ','  -v  num="${cinema}"  '$1==num {print $2}' reviewData2.csv  | grep -i '10' | wc -l

동민이 코드:
echo -n 'Enter the movie name ~ '
read name
awk -v mn="$name" -F ',' '$1==mn && $2==10 {print $2}' reviewData2.csv | wc -l

sh find_10.sh
Enter the movie name ~ 정글 크루즈
#183


문제67.  dept.txt 를 리눅스 서버에 올리시오 


▩ 모바텀(mobaterm) 프로그램 사용하기 

 putty 같은 프로그램 인데 리눅스 서버로 파일전송이 쉽습니다. 



문제68.  dept.txt 에서  부서번호 10번의 부서위치를 출력하시오 !

# awk -F ','  '$1==10  {print $3}'  dept.txt 

문제69.  부서위치 DALLAS 의 부서번호를 출력하시오 !

# awk -F ',' '$3=="DALLAS" {print $1}'  dept2.txt 

문제70.  DALLAS 에서 근무하는 사원들의 이름과 월급을 출력하시오 

# deptno=`awk -F ',' '$3=="DALLAS" {print $1}'  dept2.txt`
# awk -v  num=$deptno '$8==num {print $2, $6}'  emp.txt 

문제71.  다음과 같이 부서위치를 물어보게하고 부서위치를 입력하면 
           해당사원들의 이름과 월급을 출력하시오 !

# sh   find_loc2.sh      

  Enter  the  loc:    dallas

echo -n 'Enter the loc:  '
read  loc
deptno=`awk -F ',' -v  num2=$loc  '$3==toupper(num2) {print $1}'  dept2.txt`
awk -v  num=$deptno '$8==num {print $2, $6}'  emp.txt

문제72. 위의 shell script 는 new york 을 입력하면 실행되지 않습니다. 
           그래서 new york 도 입력되겠금 코드를 수행하세요!


echo -n 'Enter the loc:  '
read  loc
deptno=`awk -F ',' -v  num2="$loc"  '$3==toupper(num2) {print $1}'  dept2.txt`
awk -v  num=$deptno '$8==num {print $2, $6}'  emp.txt

▩ 리눅스에 마리아 디비 설치하기 

* DATABASE 소프트웨어 

  오라클   ,  mySQL  ,  Maria db (mySQL 과 똑같은 오픈소스)

//mariadb 실행
# systemctl start mariadb

//비밀번호 변경
# /usr/bin/mysqladmin -u root password '1234'

//포트 및 데몬 이름 확인
# netstat -anp | grep 3306

4시 25분에 시작할께요 ~~

문제73.  직업이 ANALYST  인 사원들의 이름과 월급과 직업을 출력하는데
            월급이 높은 사원부터 출력하시오 !

문제74.  emp 와 dept 를 조인해서 DALLAS 에서 근무하는 사원들의 사원이름과
           월급과 부서위치를 출력하시오 !


문제75. (오늘의 마지막 문제)  JONES 보다 더 많은 월급을 받는 사원들의 
           이름과 월급을 출력하세요 ~~~~

■ 리눅스의 하둡과 스파크 환경 

▩ 17. diff 명령어 

  두 파일간의 차이점을 찾아서 알려주는 명령어 

예: # diff  emp.txt  emp2.txt 

예제1. emp2.txt 를 vi 편집기로 열어서 이름이 ALLEN 인 사원의 월급을 6000으로
        수정하시오 !


예제2. 네이버 영화리뷰 데이터인 reviewData2.csv 를  review1.csv 와 review2.csv 
        로 백업하시오 !

#  cp  reviewData2.csv   review1.csv
#  cp  reviewData2.csv   review2.csv
# wc  -l   review1.csv
# wc  -l   review2.csv

예제3. review2.csv 의 파일의 내용을 일부 변경하고 저장하세요


예제4. review1.csv 와  review2.csv 의 데이터의 차이가 있는지 확인하시오 !


예제5.  금값(gold.csv) 데이터를 리눅스 서버에 올리시오 ! (mobaterm 이용해서)


예제6. gold.csv 를  gold1.csv 와 gold2.csv 로 백업하시오 !

# cp  gold.csv   gold1.csv

# cp  gold.csv   gold2.csv 

예제7. gold2.csv 를  vi 편집기로 열어서 일부 데이터를 수정하고 저장하시오


예제8. gold1.csv 와 gold2.csv 파일의 데이터의 차이가 존재하는지 확인하시오 !

▩ 18. find 명령어 

  검색하고자 하는 파일을 찾을 때 사용하는 명령어 

예: # find  디렉토리  -name  파일명  -print 
                  ↑                     ↑
          검색할 디렉토리     검색할 파일명 

     # find  /root  -name  'emp.txt'  -print 

설명:  /root 디렉토리 밑에 emp.txt 라는 파일이 있는지 검색하시오!


예제1. /root 디렉토리 밑에 dept.txt 라는 파일이 있는지 검색하시오 !


예제2. /root 디렉토리 밑에 test300 이라는 디렉토리를 생성하시오 !

# mkdir  test300
# ls  -ld  test300
       ↑
    디렉토리 리스트를 검색할 때 사용하는 옵션 

예제3. /root 디렉토리 밑에 있는 emp.txt 를 복사해서 /root/test300 밑에 
        붙여넣으시오

# cp  /root/emp.txt   /root/test300/emp.txt 
             ↑                              ↑
       원본 디렉토리와 파일명    복사할 곳의 디렉토리와 파일명

예제4. /root 디렉토리 밑에 emp.txt 가 있는지 찾아보시오

# find  /root  -name  'emp.txt'  -print 

/root/바탕화면/emp.txt  <-- root 밑에 있는 하위디렉토리 바탕화면 밑에 있는 emp.txt
/root/test300/emp.txt      <--- root 밑에 있는 하위디렉토리 test300 밑에 있는 emp.txt
/root/emp.txt                 <---- root 바로 밑에 있는 emp.txt 이록 

예제5. /root 디렉토리 바로 밑에 있는 emp.txt 만 검색하시오 !

# find  /root  -maxdepth  1  -name  'emp.txt'  -print 

예제6. 마리아 디비에 문제가 생겨서 마리아 디비에 대한 데몬 프로세서 관련 
         파일이 어디에 있는지 찾아보려할 때 find 명령어로 찾을 수 있는데  
         / 밑에 mysqld 라는 파일이 있는지 검색하시오 !

# find  /  -name  'mysqld'  -print 

예제7. 마리아 디비에 문제가 생겨서 환경설정 파일을 찾아봐야하려 한다.
          my.cnf 로 시작하는 파일이나 디렉토리가 있는지 검색하시오 !

# find   /   -name  my.cnf*  -print

▩ 19. tar 명령어 

 파일을 압축하고 압축을 해제하는 명령어 

예제:  1.  압축할 때
         # tar   cvf   압축파일명    압축파일대상 

        2. 압축을 해제할 때
        # tar  xvf  압축파일명   압축을 해제할 위치

※ 옵션:  c   :  compress ,  여러개의 파일을 하나로 만들어라 ~~
            v   :  view ,  압축되는 과정을 보여달라 ~~
            f   :  file,  생성되는 파일명을 지정 
            x  :  extract,  묶어있는 파일을 풀어줘라 ~~
           -C :  압축이 풀릴 위치를 지정 

예제1.  /root 밑에 emp 로 시작하는 확장자 .txt 파일들이 무엇이 있는지 검색하시오

 # ls  -l  emp*.txt 

 # ls -l emp*.txt | wc -l

예제2. 현재 디렉토리에 emp 로 시작하는 모든 text 파일을 empall.tar 라는 이름으로
         압축하시오 !

 # tar  cvf  empall.tar  ./emp*.txt

 # ls -l empall.tar


예제3.  dept.txt 가 /root 밑에 있는지 찾아보시오 !

 # find /root  -name 'dept.txt'  -print 

예제4. dept.txt 를 복사해서 dept2.txt 와 dept3.txt 로 생성하시오


예제5.  /root 밑에 있는 dept로 시작하는 모든 text 파일들을 deptall.tar 
          로 압축하시오 !


예제6.  /root 밑에  test1000 이라는 디렉토리를 생성하시오 ~~


예제7.  /root 밑에 deptall.tar 파일을 /root/test1000 밑에 deptall.tar 라는 이름으로 
         복사하시오 !

 # cp  /root/deptall.tar    /root/test1000/deptall.tar 

예제8. test1000 으로 이동해서 deptall.tar  압축파일의 압축을 해제하시오!

# tar xvf deptall.tar

# rm -rf root

예제9. deptall.tar 파일을 리눅스에서 윈도우쪽으로 가져오시오 !


예제10. /root 밑에 있는 emp 로 시작하는 텍스트 파일 전체를 다음 방법으로 
           압축 하시오 !

# cd
# tar  cvfz   empall2.tar  emp*.txt

설명:  z 옵션을 사용하면 압축 효율이 좀더 높아집니다. 

예제11.  /root 밑에 test2000 이라는 디렉토리를 만들고 empall2.tar 파일을 복사하시오

# mkdir  test2000
# cp empall2.tar  ./test2000/empall2.tar 

예제12. /root/test2000 밑에 있는 empall2.tar 파일의 압축을 푸시오

# tar  xvfz  empall2.tar
# ls

설명:  이번에는 root 디렉토리 없이 압축이 풀렸습니다.

※  tar 는  압축한다는것 보다는 하나로 합쳐주는 도구이다.
    tar.gz 은 tar 파일을 gzip 으로 압축해주는 도구입니다. 

# cd
# tar  -zcvf   empall3.tar.gz   emp*.txt 

# ls  -l  empall3.tar.gz

예제13.  /root 밑에 test4000 이라는 디렉토리를 만들고 empall3.tar.gz 를 거기로 복사
          하고 압축을 푸시오 

[root@localhost ~]# cp empall3.tar.gz ./test4000/
[root@localhost ~]# cd test4000
[root@localhost test4000]# ls
empall3.tar.gz
[root@localhost test4000]# tar -zxvf empall3.tar.gz

예제14.  윈도우에서 유방암 데이터와 독버섯 데이터 2개를 압축해서 data7.tar 파일로
           압축하고 리눅스로 올리세요 ~

유방암 데이터(wisc_bc_data.csv)
독버섯 데이터(mushrooms.csv )

예제15.(점심시간문제) 지금 리눅스에 올린 data7.tar 파일의 압축을 풀고 위의 두개의 
           파일이 잘 압축풀렸는지 화면 캡쳐해서 올리세요 ~~

▩ 20.  sed 명령어 

 grep 명령어는 파일의 특정 내용을 검색하는 기능을 갖는 다면
 sed 명령어는 검색뿐만 아니라 내용을 변경할 수 도 있습니다.

예제:  # cd
        # ls  -l  emp.txt 
        # sed  's/KING/yyy/'  emp.txt   

emp.txt 에서 KING 을 yyy 로 보이게 하겠다. yyy 로 변경해서 보여주기만 하는것이지
실제로 emp.txt 에서 데이터가 변경되는것은 아닙니다.

  # cat  emp.txt

문제76.  sed  's/KING/yyy/'  emp.txt    이 명령어로 출력된 결과를 emp900.txt 로 저장
           하시오 !

# sed  's/KING/yyy/'  emp.txt   >>  emp900.txt

# cat  emp900.txt

문제77.  emp.txt 에서 직업 SALESMAN 을  ANALYST 로 변경한 결과를 emp905.txt 로
            저장하시오 !

# sed  's/SALESMAN/ANALYST/'  emp.txt  >>  emp905.txt
# cat  emp905.txt

▩ 21. cp 명령어 

  파일을 복사하는 명령어 

예제:  # cp  파일명    복사할파일명
        # cp  위치/파일명   위치/복사할 파일명
        # cp  emp.txt   emp400.txt 
        # mkdir  test9000
        # cp /root/emp.txt   /root/test9000/emp400.txt

문제78. /root 밑에 backup 이라는 디렉토리를 만들고 이곳으로 /root 밑에 있는
          확장자가 .txt 인 파일들을 모두 복사하시오 !


▩ 22. mv 명령어

 파일의 이름을 바꾸거나 파일을 다른 디렉토리로 이동하는 명령어 

예제:  # cd
        # mv  기존파일명  새로운파일명 
        # cp  dept.txt   dept2000.txt
        # mv  dept.txt  ddd.txt
        # ls  -l  dept.txt 

문제79.  ddd.txt 를 다시 dept.txt 로 이름을 변경하시오!

예제:   # cp  emp.txt   emp9000.txt
         # mkdir   backup2
         # mv  emp9000.txt   ./backup2/
         # cd  backup2
         # ls

문제80.  /root 밑에 backup3 라는 디렉토리를 만들고 /root 밑에 있는 모든
           .txt 파일들을 이동시키오 ~

▩ 마리아 디비 사용하기 

문제81.  직업, 직업별 토탈월급을 출력하는데 직업별 토탈월급이 높은것부터
            출력하시오 !

select  job, sum(sal)
from emp
group by job
order by  2;

문제82.  직업, 직업별 토탈월급을 출력하는데 직업이 SALESMAN은 제외하고
           출력하고 직업별 토탈월급이 4000 이상인것만 출력하고 직업별 토탈월급이
           높은것부터 출력하시오 !

  select job, sum(sal)
    from emp
   where  job !='SALESMAN'
   group by job
   having  sum(sal) >= 4000
   order  by  2  desc;

문제83. (oracle 와 mysql 의 차이) 이름, 부서번호, 월급, 보너스를 출력하는데 
          보너스가 부서번호가 10번이면 300 을 출력하고 나머지는 0 을 출력해라!

oracle> select  ename, deptno, sal, 
                    decode( deptno, 10, 300, 0 ) as  bonus
            from emp;

mysql> select  ename, deptno, sal,
                     if ( deptno=10, 300, 0 ) bonus 
           from  emp; 

문제84.  이름, 부서번호, 월급, 보너스를 출력하는데 부서번호가 10번이면 보너스를
           300을 출력하고 20번이면 500을 출력하고 나머지는 0 을 출력하세요

oracle> select  ename, deptno, sal, decode( deptno, 10, 300, 
                                                                      20, 500, 0 ) as bonus
               from   emp;
                                   

mysql> select ename, deptno, sal, if(deptno=10, 300,
                                                 if(deptno=20, 500, 0) ) as bonus
from emp;

▩   오라클과 mySQL(Maria DB) 의 차이점
 
        Oracle             vs         mySQL(Maria DB) 

1.     decode                         if
2.     case 문                         case 문 

문제85.  이름, 부서번호, 월급, 보너스를 출력하는데 보너스가 부서번호가 
            10번이면 5000 을 출력하고 20번이면 6000을 출력하고 나머지는 0 을
             출력하시오 ! (case 문으로 수행)

select  ename, deptno, sal, case  deptno  when  10  then  5000
                                                       when  20  then  6000
                                                       else  0  end  bonus
   from  emp;

문제86.  부서번호, 부서번호별 토탈월급을 출력하는데 가로로 출력하시오 !

Oracle> select   sum( decode(deptno, 10, sal ) ) as "10",
                      sum( decode(deptno, 20, sal) ) as  "20",
                      sum( decode(deptno, 30, sal) ) as  "30"
           from  emp;

mySQL> select  sum( if(deptno=10, sal, 0 )  )  as "10",
                     sum( if(deptno=20, sal, 0 )  )  as  "20",
                     sum( if(deptno=30, sal, 0)  )  as  "30"
              from  emp;

문제87. 아래와 같이 결과를 출력하시오 ! (직업별 부서번호별 토탈월급)

select    job,    sum( if(deptno=10, sal, 0 )  )  as "10",
                     sum( if(deptno=20, sal, 0 )  )  as  "20",
                     sum( if(deptno=30, sal, 0)  )  as  "30"
       from  emp
       group by   job; 

문제88. 아래와 같이 직업별 부서번호별 인원수가 출력되게하시오 !

select job, count(if(deptno=10,empno,null)) as "10",
              count(if(deptno=20,empno,null)) as "20",
              count(if(deptno=30,empno,null)) as "30"
from emp
group by job;

select  job, sum( if(deptno=10, 1, 0 )  )  as "10",
               sum( if(deptno=20, 1, 0 )  )  as  "20",
               sum( if(deptno=30, 1, 0)  )  as  "30"
     from  emp
     group by job;


▩   오라클과 mySQL(Maria DB) 의 차이점
 
        Oracle             vs         mySQL(Maria DB) 

1.     decode                         if
2.     case 문                         case 문 
3.     nvl 함수                        ifnull

문제89. 이름과 커미션을 출력하는데 커미션이 null 인 사원들은 0으로 
          출력하시오 !

Oracle> select  ename, nvl(comm,0)  
              from  emp;

Maria> select  ename, ifnull(comm,0)
              from  emp;

▩   오라클과 mySQL(Maria DB) 의 차이점
 
        Oracle             vs         mySQL(Maria DB) 

1.     decode                         if
2.     case 문                         case 문 
3.     nvl 함수                        ifnull 
4.     to_char                         date_format 

문제90.  입사한 년도(4자리), 입사한 년도별 토탈월급을 출력하시오  !

Oracle> select  to_char(hiredate, 'RRRR'),  sum(sal)
              from  emp
              group  by to_char(hiredate,'RRRR');

Maria> select  date_format(hiredate, '%Y'), sum(sal)
            from  emp
            group by  date_format(hiredate,'%Y');

※ Maria db 의 주요날짜포멧

1. %Y : 연도 4자리
2. %y :  연도 2자리 
3. %M : 달(영문)
4. %m : 달(숫자)
5. %W : 요일 

문제91.  수요일에 입사한 사원들의 이름과 입사일을 출력하시오 !

select ename, hiredate
  from emp
 where date_format(hiredate , '%W')='Wednesday';


▩   오라클과 mySQL(Maria DB) 의 차이점
 
        Oracle             vs         mySQL(Maria DB) 

1.     decode                         if
2.     case 문                         case 문 
3.     nvl 함수                        ifnull 
4.     to_char                         date_format 
5.     to_date                         str_to_date

문제92.  1981년도에 입사한 사원들의 이름과 입사일을 출력하시오 !

Oracle>  select   ename, hiredate
               from   emp
               where  hiredate  between  to_date('1981/01/01','RRRR/MM/DD')
                                         and     to_date('1981/12/31','RRRR/MM/DD');

Maria>  select  ename, hiredate
               from  emp
               where  hiredate  between  str_to_date('1981/01/01','%Y/%m/%d')
                                         and     str_to_date('1981/12/31','%Y/%m/%d');

문제93. 1981년도에 입사한 사원들이고 직업이 salesman 인 사원들의 
           이름과 월급과 입사일을 출력하는데 월급이 높은 사원부터 출력하시오 !

select ename,sal,hiredate
   from emp
   where hiredate between str_to_date('1981/01/01','%Y/%m/%d')
                        and str_to_date('1981/12/31','%Y/%m/%d') 
    and job='salesman'
    order by sal desc;

※ mySQL 은 기본 셋팅이 대소문자를 구분하지 않아도 검색되게 되어있습니다.
   이 기본 셋팅값을 변경하고 싶다면 ?

select ename,sal,hiredate
   from emp
   where hiredate between str_to_date('1981/01/01','%Y/%m/%d')
                        and str_to_date('1981/12/31','%Y/%m/%d') 
    and binary job='salesman'
    order by sal desc;

select ename,sal,hiredate
   from emp
   where hiredate between str_to_date('1981/01/01','%Y/%m/%d')
                        and str_to_date('1981/12/31','%Y/%m/%d') 
    and binary job='SALESMAN'
    order by sal desc;

        Oracle             vs         mySQL(Maria DB) 

1.     decode                         if
2.     case 문                         case 문 
3.     nvl 함수                        ifnull 
4.     to_char                         date_format 
5.     to_date                         str_to_date
6.     대소문자 구분               대소문자 구분하려면 binary 사용 
7.     rollup                           with rollup

문제94.  부서번호, 부서번호별 토탈월급을 출력하는데 맨 아래에 전체 토탈월급을
            출력하시오 !

Oracle>  select  deptno, sum(sal)
               from   emp
               group  by  rollup(deptno);

Maria>   select  deptno, sum(sal)
                from  emp
                group by  deptno  with  rollup;

문제95.  직업, 직업별 토탈월급을 출력하는데 맨 밑에 전체 토탈월급을 
           출력하고 아래와 같이 null 값이 나오는 부분에 total: 이라고 출력하시오

select  ifnull(job,'total:') , sum(sal)
   from emp
   group by job with rollup;

select  nvl(job,'total:') , sum(sal)
   from emp
   group by job with rollup;


        Oracle             vs         mySQL(Maria DB) 

1.     decode                         if
2.     case 문                         case 문 
3.     nvl 함수                        ifnull 
4.     to_char                         date_format 
5.     to_date                         str_to_date
6.     대소문자 구분               대소문자 구분하려면 binary 사용 
7.     rollup                           with rollup
8.    listagg                           group_concat 

문제96.  부서번호, 부서번호별로 속한 사원들의 이름을 가로로 출력하시오

Oracle>  select  deptno, listagg(ename, ',') within group (order by ename asc) 
                from  emp
                group  by deptno; 

Mariadb>  select  deptno, group_concat(ename order by ename)
                 from  emp
                 group by deptno; 


        Oracle             vs         mySQL(Maria DB) 

1.     decode                         if
2.     case 문                         case 문 
3.     nvl 함수                        ifnull 
4.     to_char                         date_format 
5.     to_date                         str_to_date
6.     대소문자 구분               대소문자 구분하려면 binary 사용 
7.     rollup                           with rollup
8.    listagg                           group_concat 
9.     ||                                 concat

문제97.  이름과 월급을 출력하는데 아래와 같이 붙여서 출력하시오 !

Oracle> select  ename || sal
               from  emp;

mariadb> select  concat( ename, sal)
                from emp;

문제98. 아래와 같이 결과를 출력하시오 !

select  deptno, group_concat(concat(ename,sal)  order by ename)
        from  emp
        group by deptno; 

문제99. 다음과 같이 결과를 출력하시오 !  (답글로 올려주세요 ~~) 
+--------+--------------------------------------------------------------------------+
|     10   | CLARK(2450),KING(5000),MILLER(1300)                     |
|     20   | ADAMS(1100),FORD(3000),JONES(2975),SCOTT(3000),SMITH(800)   |
|     30   | BLAKE(2850),JAMES(950),MARTIN(1250),TURNER(1500),WARD(1250) |
+--------+-----------------------------------------------------------------------------+

select deptno, group_concat(concat(ename, '(', sal, ')' ) order by ename)
  from emp
  group by deptno;

문제100.  사원 테이블을 모두 delete 하고 commit 은 하지 마시오 !


설명: mySQL(Maria) 는 기본적으로 auto commit 이 활성화 되어있습니다.

문제101. 내가 접속한  mySQL(Maria) 의  auto commit 이 활성화 되어져있는지
            비활성화 되어져 있는지 확인하시오 !

show  variables  like  'autocommit%' ;
set  autocommit = FALSE;
show  variables  like  'autocommit%' ;

Mysql 에서 emp 와 dept 테이블 생성하는 스크립트를 다시 수행하세요~


        Oracle             vs         mySQL(Maria DB) 

1.     decode                         if
2.     case 문                         case 문 
3.     nvl 함수                        ifnull 
4.     to_char                         date_format 
5.     to_date                         str_to_date
6.     대소문자 구분               대소문자 구분하려면 binary 사용 
7.     rollup                           with rollup
8.    listagg                           group_concat 
9.     ||                                 concat
10.   자동 커밋이 비활성화     자동 커밋이 활성화 

문제102.  이름, 월급, 월급에 대한 순위를 출력하시오 !

select  ename, sal, rank()  over ( order  by sal  desc)  rnk
  from  emp;

문제103. 위의 결과에서 순위가 1등인 사원만 출력하시오 !
  
select  ename, sal, rank()  over ( order  by sal  desc)  rnk
  from  emp
  where  rnk = 1;

oracle> select  *
             from  ( 
                    select  ename, sal, rank()  over ( order  by sal  desc)  rnk
                      from  emp
                      )
             where  rnk =1;
 
※ 설명: 오라클과는 다르게 from 절의 서브쿼리가 지원되지 않습니다.
            대신 아래와 같이 구현할 수 있습니다. 

maria> select  ename, sal, rank()  over ( order  by sal  desc)  rnk
             from  emp
             limit  1; 
             
문제104. (오늘의 마지막 문제)  직업, 이름, 월급, 순위를 출력하는데 
            순위가 직업별로 각각 월급이 높은 순서데로 순위가 부여되게하시오!

■ 리눅스 수업 복습

1. 리눅스 설치
2. 리눅스 기본 명령어
3. 마리아 디비 설치
4. 마리아 디비 SQL 작성법 


        Oracle             vs         mySQL(Maria DB) 

1.     decode                         if
2.     case 문                         case 문 
3.     nvl 함수                        ifnull 
4.     to_char                         date_format 
5.     to_date                         str_to_date
6.     대소문자 구분               대소문자 구분하려면 binary 사용 
7.     rollup                           with rollup
8.    listagg                           group_concat 
9.     ||                                 concat
10.   자동 커밋이 비활성화     자동 커밋이 활성화 
11. from  절의 서브쿼리 사용가능     from 절의 서브쿼리 사용불가능(limit 사용)
12.   to_char(sal,'999,999')         format 

문제105.  다음의 오라클에서 수행한 SQL의 결과를 MySQL 로 수행하시오 !

Oracle> select   ename, to_char(sal, '999,999')
               from  emp;

mariadb> select  ename,  format(sal, 0)
                from  emp;

설명: format 은 숫자 세자리마다 쉼표(콤마)를 찍는 함수 입니다.

문제106. 다음의 오라클에서 수행한 SQL의 결과를 MySQL 에서 수행하시오 !

Oracle> select   ename, to_char(sal*2000, '999,999,999')
               from  emp;

mariadb> select ename, format(sal*2000, 0)
                from emp;

문제107. 다음의 오라클에서 수행한 SQL의 결과를 MySQL 에서 수행하시오 !

Oracle> select   ename, to_char(sal*2000, '999,999,999.99')
               from  emp;


mariadb> select ename, format(sal*2000, 2)
                from emp;


        Oracle             vs         mySQL(Maria DB) 

1.     decode                         if
2.     case 문                         case 문 
3.     nvl 함수                        ifnull 
4.     to_char                         date_format 
5.     to_date                         str_to_date
6.     대소문자 구분               대소문자 구분하려면 binary 사용 
7.     rollup                           with rollup
8.    listagg                           group_concat 
9.     ||                                 concat
10.   자동 커밋이 비활성화     자동 커밋이 활성화 
11. from  절의 서브쿼리 사용가능     from 절의 서브쿼리 사용불가능(limit 사용)
12.   to_char(sal,'999,999')         format 
13.   테이블 생성시 데이터 타입의 차이가 있습니다. 

▩ Maria db 에서 테이블 생성 

예제1.  내가 가지고 있는 테이블 리스트를 확인합니다.

Oracle> select  table_name  from  user_tables; 

MariaDB> show  tables; 

예제2.  emp2 테이블 생성하기 

Oracle>  create  table  emp2
           ( empno   number(10),
             ename   varchar2(20),
              job       varchar2(10),
             mgr        number(10),
             hiredate    date,
             sal         number(10),
           comm       number(10),
           deptno      number(10) );

MariaDB>  create  table  emp2
               ( empno    int(4),
                 ename    varchar(10),
                 job         varchar(10),
                mgr        int(4),
                hiredate    date,
                sal     int(7),
                comm  int(7),
                deptno   int(4)  );

예제3.  Oracle 의 dept2 테이블을 maria db 에서 생성하시오 

Oracle>  create   table   dept2
            ( deptno    number(10),
              dname    varchar2(10),
              loc         varchar2(10) );

MariaDB>  create table dept2
               ( deptno  int(10),
                dname  varchar(10),
                loc   varchar(10));


        Oracle             vs         mySQL(Maria DB) 

1.     decode                         if
2.     case 문                         case 문 
3.     nvl 함수                        ifnull 
4.     to_char                         date_format 
5.     to_date                         str_to_date
6.     대소문자 구분               대소문자 구분하려면 binary 사용 
7.     rollup                           with rollup
8.    listagg                           group_concat 
9.     ||                                 concat
10.   자동 커밋이 비활성화     자동 커밋이 활성화 
11. from  절의 서브쿼리 사용가능     from 절의 서브쿼리 사용불가능(limit 사용)
12.   to_char(sal,'999,999')         format 
13.   테이블 생성시 데이터 타입의 차이가 있습니다. 
14.   csv 파일을 로드하려면        load 명령어로 쉽게 입력  
       sqldeveloper 를 사용 

▩ 마리아 디비 테이블에 csv 파일 로드하기

1.  emp.csv 를 리눅스 서버에 /root 밑에 올립니다.

 데이터 게시판에 emp.csv 가 있습니다. emp.csv 를 모바텀을 이용해서 리눅스에 올리세요

2. emp.csv 를 vi 편집기로 열어서 맨위에 컬럼명 행을 지우시오 


3. emp.csv 를 vi 편집기로 열어서 null 값에 해당하는 부분을 모두 \N 으로 변경합니다.

:%s/,,/,\\N,/g

4.  변경한 emp.csv 의 데이터를 마리아디비에 emp2 테이블에 입력하시오

load  data  local  infile   '/root/emp.csv'
replace
into   table   orcl.emp2
fields  terminated  by  ',' 
enclosed  by  '"'                         
lines  terminated  by '\n' 
ignore  1  lines 
(empno, ename, job, mgr, hiredate, sal, comm, deptno);

설명:   
load  data  local  infile   '/root/emp.csv'      로드할 csv 파일명 
replace             기존에 테이블에 데이터가 있다면 지금 로드할 데이터로 대체하겠다
into   table   orcl.emp2      orcl 데이터베이스의 emp2 테이블에 입력
fields  terminated  by  ','     값과 값은 콤마로 구분되어있다.
enclosed  by  '"'   데이터 중에 혹시 더블쿼테이션 마크로 둘러져있는 데이터도 입력되게
lines  terminated  by '\n'    행과 행은 엔터로 구분되어져 있다
ignore  1  lines                첫번째행은 무시하겠다
(empno, ename, job, mgr, hiredate, sal, comm, deptno);

5. emp2 테이블을 truncate 하고 다시 ignore 1 lines 없이 emp.csv 를 로드하시오

MariaDB [orcl]> truncate  table emp2;

load  data  local  infile   '/root/emp.csv'
replace
into   table   orcl.emp2
fields  terminated  by  ',' 
enclosed  by  '"'                         
lines  terminated  by '\n' 
(empno, ename, job, mgr, hiredate, sal, comm, deptno);

예제1.  dept2 테이블에 dept.csv 를 로드하시오 ~

load data local infile '/root/dept.csv'
replace
into table orcl.dept2
fields terminated by ','
enclosed by '"'
lines terminated by '\n'
ignore  1  lines  
(deptno, dname, loc);

예제2. 네이버 영화 리뷰 데이터를 마리아 디비에 생성하기

 "csv 과 text 파일 심지어 이미지까지 전부 database 에서 넣고 관리합니다. "

 그래서 데이터 유실도 방지할 수 있고 데이터 관리가 되어집니다. 
 그리고 여러 유져들이 그 데이터에 엑세스 할 수 있습니다. 

create  table   naver2
( cname    varchar(100),
  score      int(2),
  review    varchar(1000) );

truncate  table  naver2;

load data local infile '/root/reviewData2.csv'
replace
into table orcl.naver2
fields terminated by ','
enclosed by '"'
lines terminated by '\r\n'
(cname, score, review) ;

설명:  \n 은 엔터이고 \r 은 리턴 입니다.

예제3.  최근에 스크롤링한 영화 데이터인 naver2 테이블에서 영화이름을 출력하는데
          중복제거해서 출력하시오 !

select distinct cname
  from naver2;

예제4.  영화 모가디슈의 평점, 평점별 건수를 출력하시오 !

 select score, count(*)
  from naver2
  where cname = '모가디슈'
  group by score;

예제5. 위의 결과를 다시 출력하는데 평점의 건수값이 높은것부터 출력하시오 !

select score, count(score) 
 from naver2
 where cname = '모가디슈' 
 group by score 
 order by 2 desc;

예제6. 위의 결과를 다시 출력하는데 위의 결과중에 위의 3건만 출력하시오 

select score, count(*), rank() over (order by count(*) desc)
  from naver2 
  where cname='모가디슈' 
  group by score 
  order by 2 desc
  limit 3;

▩ 오라클의 sqldeveloper 와 같은 툴인 workbench 툴을 설치해서 maria 디비 이용하기 

예제7.  네이버(naver2) 영화 리뷰 테이블에서 영화이름이 모가디슈인 모든 행을 출력
           하시오

▩ centos 에서 한글 키보드가 되겠금 설정하는 방법 


예제8.  리뷰글에 조인성이 포함된 리뷰들을 모두 출력하시오 !

select *
 from  naver2
 where  review  like  '%조인성%';

예제9.  리뷰글에 최고라는 단어가 포함된 영화명을 중복제거해서 출력하시오 !

select distinct(cname)
from naver2
where review like '%최고%;

예제10.  리뷰글에 최고라는 단어가 포함된 영화명과 영화명 건수를 출력하시오 !

select cname, count(*)
 from naver2
 where review like '%최고%'
 group by cname
 order by 2 desc;

예제11.  평점 1점이 가장 많은 영화제목은 무엇인지 출력하시오 !

select cname, count(*)
  from naver2
  where score = 1
  group by cname
  order by 2 desc
  limit 1;

▩ 내자리에서 서버실에 있는 workbench 프로그램을 실행하는 방법 

 1.  mobaxterm ---> settings ---> configuration --> x11 ---> x11 remote access ---> full

 2. 도스창을 열고 자신의 아이피 주소를  확인합니다.

C:\Users\YYS> ipconfig

 192.168.19.68  <--- 반드시 자기 자신의 아이피 주소를 확인해야합니다.

 3. 모바텀 터미널 창에서 다음과 같이 수행합니다.

  # export  DISPLAY=192.168.19.68:0.0
  # mysql-workbench

▩ centos 에 아나콘다 설치하기 

  
 bash Anaconda3-2020.11-Linux-x86_64.sh 

 위의 명령어는 아나콘다 설치하는 명령어인데 실행하면 라이센스 읽어보는
 화면이 나올때 q 누르고 빠져나오면 do you accept ... ? yes

unpacking payload....  엔터치면서 기다리세요 ~

$ source  .bashrc   <--- 리눅스 전체의 환경설정 파일을 실행한다.

$ ls      <---  anaconda3 라는 폴더가 생겼으면 잘 된겁니다. 

■ 리눅스 수업 복습 

 1.  리눅스 설치 
 2.  리눅스 기본 명령어
 3.  마리아 디비 설치
 4.  workbench 설치 
 5.  아나콘다 설치중

데이터 분석가가 리눅스를 왜 배워야하는가 ?   회사의 데이터는 다 리눅스서버에
                                                             저장되어있고 database 에서 관리하고 
                                                             있기 때문입니다. 

오전: 리눅스 명령어,  

오후:  마리아 디비와 파이썬과 연동해서 데이터 시각화

■ 리눅스 권한 관리 명령어 3가지

 1.  chmod : 특정 파일의 권한을 조정하는 명령어 
 2.  chown :  특정 파일이나 디렉토리의 소유자를 변경하는 명령어
 3.  chattr  :  루트 유져만 권한을 조정할 수 있도록 설정하는 명령어 

예제1.  emp.csv 의 권한이 어떻게 되어있는지 확인하시오 !

$ ls -l  emp.csv

       -rw-                               r--                    r--
         ↓                                ↓                      ↓
     소유자에 대한 권한     그룹에 대한 권한        기타유져
                                     ↓
                           다음카페에 우수회원, 특별회원, 준회원과 같은것 

 r   :  읽기 권한
 w  :  쓰기 권한
 x   :  실행 권한 

위의 권한을 해석 ?  소유자는 emp.csv 에 대해서 읽기권한과 쓰기권한이 있습니다. 
                          그룹에 속한 유져들은 emp.csv 에 대해서 읽기 권한이 있습니다.
                          기타 유져들은 emp.csv 에 대해서 읽기권한이 있습니다. 

예제2.  mkdir 로 test700 이라는 디렉토리를 만들고  test700  에 대한 권한이 
          어떻게 되어있는지 확인하시오 !

박건우 학생이 대답해봅니다. 

     drwx          r-x          r-x.


 디렉토리에 대해서 r(읽기) 권한은 디렉토리에서 ls 를 할 수 있다는것입니다.
 디렉토리에 대해서 w(쓰기) 권한은 디렉토리에서 vi 편집기로 파일을 생성할 수 있습니다. 
                                               또는 디렉토리도 생성할 수 있습니다.
 디렉토리에 대해서 x(실행) 권한은 디렉토리에 cd 명령어로 접근할 수 있다는 것입니다.


예제3. mobaterm 을 이용해서 /root 디렉토리에 제주시소상공인 데이터를 올리시오



예제4.  지금 올린 16.csv 의 권한을 확인하세요 ~

# ls   -l   16.csv

-rw-r--r--. 1 root root 25253368  8월 17 10:18 16.csv

권한해석:  root 유져는 16.csv 에 대해서 읽고 쓰는 권한이 있습니다. 
              root 그룹에 속한 유져들은 16.csv 에 대해서 읽을수 있는 권한만 있습니다.
              기타유져들은 16.csv 에 대해서 읽을수 있는 권한만 있습니다. 

예제5. /root 밑에 있는 16.csv 를 /home/oracle 밑으로 카피하시오 

# cp  /root/16.csv  /home/oracle/16.csv

예제6. 터미널 창에서 바로 oracle 유져로 스위치유져 하시오 !

# su - oracle

$ whoami

예제7. oracle 유져에서 16.csv 의 파일의 권한을 확인하고  16.csv 를 head 명령어로
         보시오

 $ ls -l  16.csv
 $ head  16.csv 

설명: oracle 유져는 16.csv 에 대해서 읽을 수 있는  권한이 있어서 head, cat 또는 vi 편집기
        명령어로 볼 수는 있습니다. 

(base) [oracle@localhost ~]$ ls -l 16.csv
-rwx   r-x  r-- 1 root root 25253368  8월 17 10:25 16.csv

예제8. oracle 유져에서 16.csv 를 vi 편집기 명령어로 열어서 안의 내용을 수정하고
        저장하고 나오시오!


설명:  oracle 유져에서 vi 편집기로 16.csv 를 열어서 수정한 다음에 wq! 로 강제로 
        저장하고 나왔더니 소유자가 root 에서 oracle 로 변경되었습니다. 
        이렇게 소유자를 변경하는것은 비정상적인 방법이고 다음과 같이 해야
        제대로 소유자를 변경하는것입니다.

■ chown 명령어

 " 파일이나 디렉토리의 소유자를 변경하는 명령어 "

예제1:  root 로 접속해서  /root 밑에 있는 16.csv 의 소유자를 oracle 로 변경하시오

# chown oracle:oracle 16.csv
# ls -l 16.csv
-rw-r--r--. 1 oracle oracle 25253368  8월 17 10:18 16.csv

예제2.  /root 밑에 있는 16.csv 를 /home/oracle 밑으로 복사하시오 !

# cp  /root/16.csv   /home/oracle/16.csv

예제3. 이제 oracle 유져로 스위치 유져하고  /home/oracle 밑에 있는 16.csv 를
         head 로 열어봅니다.


예제4. 소상공인 데이터에서 세종시 데이터를 17.csv 로 이름을 바꿔서 모바텀으로
         리눅스 서버에 올리시오



예제5. root 유져에서 /root 밑에 있는 17.csv 의 소유자를 oracle 유져, 그룹도 oracle 그룹
         으로 변경하시오 !

# chown oracle:oracle 17.csv

예제6.  /root 밑에 있는 17.csv 를 /home/oracle 밑으로 복사하시오 !

# cp  /root/17.csv    /home/oracle/17.csv

파일의 소유자는 위와 같이 chown 명령어로 변경하면 됩니다. 
그런데 이번에는 소유자를 그대로 두고 다른 유져들이 파일을 읽거나 수정할 수 있게
하려면 다음 명령어를 사용하면 됩니다. 

■ chmod 명령어 

권한 관리표 

번호       권한       대표문자         파일               디렉토리 
  4      읽기권한        r            읽고, copy        디렉토리에서 ls 가능
  2      쓰기권한       w               수정             디렉토리에서 파일 생성 가능
  1      실행권한       x                실행             디렉토리에서 cd 로 접근가능 

예제1.  소상공인 데이터에서 서울 데이터를 seoul.csv 라는 이름으로 변경해서 
          리눅스 서버에 올리시오 !


예제2. seoul.csv 파일에 대한 권한을 유져, 그룹, 기타유져 모두 읽을 수만 있도록 변경
         하시오 !

# chmod u-rwx,g-rwx,o-rwx  seoul.csv

# ls -l seoul.csv

# chmod u+r,g+r,o+r seoul.csv

# ls -l seoul.csv 

예제3.  이번에는 파일에 대한 권한을 유져, 그룹, 기타유져 모두 읽고 쓸수 있도록 
           권한을 부여하시오 !

# chmod u+rw,g+rw,o+rw seoul.csv

# ls -l seoul.csv
-rw-rw-rw-. 1 root root 166616658  8월 17 11:27 seoul.csv

예제4. 이번에는 파일에 대한 권한을 유져, 그룹, 기타유져 모두 읽고, 쓰고, 실행할 수 
         있도록 권한을 부여하시오!

# chmod u+rwx,g+rwx,o+rwx seoul.csv

예제5. 다시 모든 권한을 다 취소하시오 !

# chmod u-rwx,g-rwx,o-rwx  seoul.csv 

예제6. 이번에 읽기 권한을 다시 부여하는데 숫자로 부여하시오 !

읽기: 4,  쓰기: 2, 실행: 1 

# chmod 444 seoul.csv

예제7. 이번에는 읽기와 쓰기권한을 숫자로 부여하시오 !

# chmod 666 seoul.csv 

예제8. 이번에는 읽기와 쓰기와 실행 모두 숫자로 권한을 부여하시오 !

# chmod 777 seoul.csv

예제9. seoul.csv 에 대해서 아래와 같이 권한이 부여되게하시오 !

-rwxr-xr-x. 1 root root 166616658  8월 17 11:27 seoul.csv

# chmod 755 seoul.csv

예제10.  seoul.csv 에 대해서 아래와 같이 권한이 부여되게하시오 !

# chmod 751 seoul.csv

예제11.(점심시간 문제)  seoul.csv 에 대해서 아래와 같이 권한이 부여되게하시오 !

■ 디렉토리 소유자의 권한을 변경하는 방법 

 디렉토리의 소유자 권한을 변경하게 되면 그 디렉토리에 있는 모든 파일들의
 소유자를 한번에 변경할 수 있습니다. 

예제1. root 유져에서 /home/oracle 밑에  test500 이라는 디렉토리를 생성합니다.


예제2. root 유져에서  /root 밑에 있는 emp.csv 와 dept.csv 를 /home/oracle/test500/ 밑에
        복사합니다.


예제3. /home/oracle/test500 밑에 있는 emp.csv 와 dept.csv 의 소유자가 누구인지
         확인하시오 !


/home/oracle/test500 디렉토리의 소유자는 root 이고
/home/oracle/test500 디렉토리 밑에 있는 emp.csv 와 dept.csv 의 소유자도 root 입니다.

예제4. /home/oracle/test500 디렉토리의 소유자를 root 에서 oracle 로 변경하시오 !

# cd /home/oracle
# chown  oracle:oracle  test500
# ls -ld  test500

test500 의 소유자가 root 에서 oracle 로 변경되었습니다.

# cd  test500
# ls -l 

test500 의 디렉토리의 소유자는 oracle 로 변경되었지만 test500 에 있는 파일들의
소유자는 그대로 root 입니다.

예제5. /home/oracle/test500 밑에 있는 파일들의 소유자도 전부 oracle 이 되게 하시오

# cd /home/oracle

# chown -R  oracle:oracle  test500

설명:  -R 옵션을 붙여주게 되면 test500 디렉토리 뿐만 아니라 test500 디렉토리 밑에 있는
         파일들의 소유자도 전부 oracle 로 변경됩니다. 



■ chattr 명령어

  chattr 명령어를 이용하면 chmod 명령어 수행을 막을 수 있습니다.
  chattr 명령어는 최상위 계정인 root 에서만 수행할 수 있습니다.
  oracle 유져로 특정파일에 대해서 chmod 명령어를 수행하지 못하도록 막는 명령어 

예제:  # cd  /home/oracle
        # ls  -l  emp.txt
        # cp  /root/emp.csv   /home/oracle/emp.csv
        # cd  /home/oracle
        # ls -l emp.csv
  
emp.csv 의 소유자는 root 입니다.  그럼 oracle 유져로 스위치 유져해서 emp.csv 의
권한을 777 로 변경합니다.

         # su - oracle
         $ chmod 777 emp.csv

퍼미션이 없어서 변경이 안된다고 합니다. 그러면 다시 root 로 접속하여 
emp.csv 의 소유자를 oracle 로 변경 합니다. 

        # chown  oracle:oracle  emp.csv
        # ls -l emp.csv

이제 다시 oracle 로 접속해서 emp.csv 의 권한을 777 로 변경하시오 

       # su - oracle
       $ chmod 777  emp.csv

다시 oracle 유져에서 emp.csv 의 원한을 711 로 변경하시오 

       $ chmod 711 emp.csv

이제 root 유져로 접속해서 oracle 유져가 emp.csv 에 대해서 권한을 조정하지 못하도록
막아버리시오 !

  $ su -
  # cd  /home/oracle
  # chattr +i  emp.csv
  # lsattr  emp.csv

그러면 다시 oracle 유져로 접속해서 emp.csv 의 권한을 777 로 변경하시오 !

 # su - oracle
 $ chmod 777 emp.csv

마지막으로 다시 root 유져에서 oracle 유져가 emp.csv 에 대해서 chmod 를 수행할 수 
있도록 설정하시오 !

$ su -
# cd  /home/oracle
# chattr  -i  emp.csv
# lsattr   emp.csv
# su - oracle
$ chmod 777 emp.csv

예제1.  oracle 유져에서  vi 로  emp40.txt 를 열고 아래와 같이 데이터를 넣고 
         저장하시오 ~

$ vi  emp40.txt 

1111, aaa, bbb
2222, ccc, ddd

예제2.  emp40.txt 를 oracle 유져가 chmod 못하게 막으시오 ~

■ 리눅스에 아나콘다 설치후 스파이더 실행 

예제1.  emp.csv 를  pandas 의 데이터 프레임으로 생성하시오 !

import  pandas  as  pd

emp = pd.read_csv("/home/oracle/emp.csv", header=None)
emp.columns=['empno','ename','job','mgr','hiredate','sal','comm','deptno']
print(emp)

예제2.  dept.csv 를 pandas 의 데이터 프레임으로 생성하시오 !

$ cp /home/oracle/test500/dept.csv /home/oracle/

import  pandas  as  pd
dept = pd.read_csv("/home/oracle/dept.csv")
print(dept)

예제3. 직업이 SALESMAN 인 사원들의 이름과 월급을 출력하시오 !

result = emp[['ename','sal']] [ emp['job']=='SALESMAN' ] 
print(result)

예제4. 직업, 직업별 토탈월급을 출력하시오 !

print(emp.groupby('job')['sal'].sum().reset_index())

예제5. 부서번호, 부서번호별 평균월급을 출력하시오 !

승연
result=emp.groupby('deptno')['sal'].mean().reset_index()
print(result)

예제6. 위의 결과를 원형 그래프로 그리시오 !

result=emp.groupby('deptno')['sal'].mean()
result.plot( kind='pie')

예제7. 직업, 직업별 토탈월급을 막대그래프로 시각화 하시오 !

result=emp.groupby('job')['sal'].mean()
result.plot(kind='bar')

예제8. 입사한 년도 4자리, 입사한 년도별 토탈월급을 출력하시오 !

emp['hire_year'] =emp['hiredate'].apply(lambda x:x[:4])
result =  emp.groupby('hire_year')['sal'].sum()
print(result)

예제9. 예제8번의 결과를 막대그래프로 시각화하시오 !

emp['hire_year'] =emp['hiredate'].apply(lambda x:x[:4])
print(emp)
result =  emp.groupby('hire_year')['sal'].sum()
result.plot(kind='bar')

예제10. (오늘의 마지막 문제)  부서번호, 부서번호별 토탈월급을 막대그래프로 
          시각화 하시오 !   그래프를 올리세요 ~

오전: 리눅스 명령어
오후: 아나콘다와 마리아디비를 연동


아나콘다 설치할 때 가상환경을 왜 생성하는지?

  $ conda  create  -n  가상환경이름 python=3.8

  1. 일반 사진 ---> 미술작품으로 변환 프로젝트:  python 3.7, numpy 2.1, ....
  2. 주가예측을 하는 신경망 구현 프로젝트 :   python 3.8, numpy 2.8, .........

   내컴퓨터 안에   파이썬 가상환경1 (미술작품으로 변환하는 프로젝트)
                        파이썬 가상환경2 ( 주가예측 프로젝트)

  $ conda create -n  ariticle_picture  python=3.8
  $ conda create -n  kospi  python=3.7

  * 가상환경 리스트를 확인 

  $ conda env list

■ 리눅스 명령어

1. 리눅스 기본 명령어
2. vi 편집기
3. 권한 관리 명령어 
4. 디스크 관리 명령어 

■ 디스크 관리 명령어 3가지 

1. df 명령어
2. du 명령어
3. sar 명령어 

▩ 1. df 명령어

 " 현재 파일 시스템의 총 사용율을 확인하는 명령어 "

예제:  $ df -h


예제1. oracle 유져로 접속해서 df -h 명령어를 수행하시오 !

 $ df -h

 리눅스 시스템 전체의 공간 사용율을 보여주는거라서 root 유져에서 위의 명령어를
 수행하던 oracle 에 하던 결과가 같습니다. 

▩ 2. du 명령어

 " 현재 있는 디렉토리의 디스크 사용량을 표시하는 명령어 "

예제:  현재 디렉토리의 csv 파일들의 총 크기를 확인하려면?

 # du *.csv

 # du -h  *.csv

 # du -c  *.csv  

예제1.  oracle 유져의 홈디렉토리인 /home/oracle 밑에 있는 csv 파일들의 총크기를
          확인하시오 !

예제2. /home/oracle 밑에 있는 확장자가  .sh 로 끝나는 파일들의 총 크기를 확인하시오

▩ 3. sar 명령어 

 만약에 리눅스에서 어떤 작업을 하다가 리눅스 서버가 너무 느려서 작업이 진행이
 잘 안될때 현재 리눅스의 디스크의 사용율을 확인하는 명령어 

예제: $ sar  1  100  

설명: %user 부분을 집중적으로 모니터링 하면 됩니다. 
        리눅스 서버에 부하가 심한 작업을 수행하면 %user 부분의 사용율이 100에 가깝게
        올라갑니다. 

%user :  oracle 유져와 같이 일반 유져가 사용하는 disk i/o 입니다.
%nice :  cpu 를 양보하는 친절도 
%system:  system 이 사용하는 disk i/o
%iowait :  i/o 를 일으키면서 얼마나 대기하는지
%idle : 작업을 안하고 있는 idle 한 상태
%steal : 다른 프로세서의 자원을 얼마나 뺏고 있는지

예제1. 내가 자리를 비운동안 시스템의 disk i/o 가 얼마나 발생했는지 확인하려면 ?

#  sar  1   20   >>  sar_20210818.txt

예제2. 위의 명령어가 백그라운드로 돌아가게 하고 싶다면 ?

#  sar  1   20   >>  sar_20210819.txt  &

■ 리눅스 프로세서 관리 명령어 

 1. top 명령어
 2. ps 명령어
 3. kill 명령어
 4. jobs 명령어 

▩ top 명령어

 "지금 현재 작동중인 프로세스들의 cpu 사용율과 메모리 사용율을 확인하는 명령어"

 내가 수행한 파이썬 프로그램이 cpu 를 얼마나 많이 사용하고 있는지
 확인하고 싶을때나 아니면 잘못 프로그래밍을 해서 무한루프를 돌렸거나 했을때
 리눅스의 자원을 많이 사용하고 있다면 문제가 발생하는 것이므로
 top 명령어로 확인해 볼 필요가 있습니다. 

 예: # top

예제1. 숫자 1 ~ 10000000000000000 을 출력하는 파이썬 프로그램을 실행하고 
         다른 터미널 창을 열어서 top 을 수행합니다. 


예제2. 지금 cpu 를 과도하게 사용하고 있는 oracle 유져의 프로세서 4185를 kill
         시키시오 !

▩ 2. ps 명령어

 "현재 시스템에서 수행되고 있는 프로세서의 정보를 표시하는 명령어"

문법:  # ps  옵션  프로세서번호 
        # ps  -p  25017

옵션:  -p :  프로세서 아이디
        -e :  현재 실행중인 모든 프로세서
        -f :  실제 유져명, 개시시간등을 표시
        -l :  프로세서의 상태, 우선도등과 같은 상세한 정보를 표시 

예제1.  현재 리눅스 시스템에 떠있는 모든 프로세서들을 다 출력하시오 !

# ps -ef 

예제2. 현재 리눅스 시스템에 있는 oracle 유져에 대한 프로세서들만 출력하시오 !

# ps -ef | grep  oracle


예제3. 다른 터미널 창에서 vi 편집기를 다음과 같이 열고 작업을 하시오 !

# vi  aaa.txt

select  ename, sal, deptno
 from emp
 where deptno = 10;

예제4. 다른 터미널 창에서 maria 디비에 접속을 하고 emp 테이블을 select 하시오



예제5. mysql 로 접속한 유져의 프로세서 번호를 알아내시오 ~

# ps -ef |grep mysql

 45분까지 쉬세요 ~~

prosessor (리눅스의 데몬)
process (절차)

▩  4. jobs 명령어 

 동작중인 작업의 상태를 확인하는 명령어

* 상태정보 4가지 

1. running : 실행중
2. stopped : 일시중단중
3. Done : 종료
4. termianted : 강제종료됨 

예제:  # vi  hhh.txt

select  ename, sal, job, deptno
 from  emp
 where 

esc 키를 누르고 ctl + z 를 눌러서 하던 작업을 취소합니다.

  [1]              +                             Stopped                   vi hhh.txt
  ↑              ↑                                ↑
 job번호   현재 진행중이었던 job       일시중단중 

# jobs    <--- 동작중인 작업의 상태를 확인하는 명령어

# fg   <--- 현재 진행중이었던 job 으로 접속하는 명령어 


■ 리눅스 프로세서 관리 명령어 

 1. top 명령어
 2. ps 명령어
 3. kill 명령어
 4. jobs 명령어

■ 리눅스의 쉘 스크립트 작성법 

 " 내가 하고 있는 업무를 자동화하고 싶을때 사용하는 기술" 

자동화에 관한 대표적인 리눅스 명령어 ?  case 문

당장 자동화 하고 싶은 명령어?   1. maria 디비에 root 로 접속
                                           2. maria 디비에 scott 으로 접속 
                                           

예제1. 아래의 case 문을 메모장에서 작성하시오 !

echo "마리아 디비에 root 로 접속하려면 1번을 누르세요" 

echo  -n  "번호를 입력하세요"
read choice
case  $choice  in  
      1)
          mysql  -u  root  -p 
esac 

위에서 작성한 코드를 전부 복사해서  vi  a.sh 를 열고 붙여넣으시오 
실행은  sh  a.sh   입니다.

예제2.  find 명령어로 특정 파일을 찾는 명령어를 수행하는데 /root 밑에
          emp.csv 를 find 명령어로 찾으시오 !

# find   /   -name  emp.csv

예제3. 위의 find 명령어에서 찾을 파일명만 쉽게 변경할 수 있도록 아래와 같이
          스크립트를 작성하고 성공적으로 수행되는지 확인하시오 !
         (메모장에 먼저 쓰고 복사한다음에 vi 에서 붙여넣으세요)

# vi  file_find.sh

echo -n '검색할 파일명을 입력하세요 ~'
read file_name
find  / -xdev  -name  $file_name  

# sh file_find.sh
검색할 파일명을 입력하세요 ~ emp.csv

예제4.  지금 만든 file_find.sh 스크립트를 자동화 스크립트인 a.sh 에 추가하시오

echo "1. 마리아 디비 접속
2. 파일검색    "

echo  -n  "번호를 입력하세요"
read choice
case  $choice  in
      1)
          mysql  -u  root  -p ;;
      2)
         sh /root/file_find.sh ;;
esac

예제5.  특정 파일의 권한을 777 높이는 자동화 스크립트를 만들기 위해서 
          /root 밑에  경기도 소상공인 데이터인 20.csv 를 올리시오 


예제6. 20.csv 의 권한을 777 로 조정하시오 !

# chmod  777  20.csv

# ls -l  20.csv 

예제7. 다음과 같이 p.sh 를 생성하는데 p.sh 를 실행하면 다음과 같이 물어보게하고
        권한이 조정되게 하시오

# sh  p.sh

   권한을 조정할 파일명을 디렉토리와 함께 입력하시오 ~   /root/20.csv
   권한 숫자를 입력하세요 ~    755

# vi  p.sh

echo -n  '권한을 조정할 파일명을 디렉토리와 함께 입력하시오 ~  '
read  filename
echo -n  '권한 숫자를 입력하세요 ~ '
read  num1

chmod $num1  $filename
ls -l  $filename

예제8. 위에서 만든 p.sh 를 자동화 스크립트(a.sh) 의 3번에 추가하시오 

echo "1. 마리아 디비 접속
2. 파일검색    
3. 권한조정  "

echo  -n  "번호를 입력하세요"
read choice
case  $choice  in
      1)
          mysql  -u  root  -p ;;
      2)
         sh /root/file_find.sh ;;
      3)
         sh /root/p.sh  ;;
esac

예제9.  /root/ 밑에 있는 20.csv /home/oracle 밑에 copy 하시오 !

# cp  /root/20.csv    /home/oracle/20.csv 

예제10.  아래와 같이 복사를 편하게 할 수 있는 쉘 스크립트를 작성하시오 !

# sh  c.sh 
  복사할 파일명을 디렉토리와 함께 입력하세요 ~  /root/20.csv
  복사될 파일명을 디렉토리와 함께 입력하세요 ~  /home/oracle/20.csv 

답:
# vi  c.sh

echo -n  '복사할 파일명을 디렉토리와 함께 입력하세요 ~ '
read before
echo -n  '복사될 파일명을 디렉토리와 함께 입력하세요 ~ ' 
read after

cp $before $after 
ls  -l  $after 

예제11. 위에서 만든 c.sh 를 자동화 스크립트(a.sh) 의 4번으로 등록하시오 !

echo "1. 마리아 디비 접속
2. 파일검색    
3. 권한조정  
4. 복사하기   "

echo  -n  "번호를 입력하세요"
read choice
case  $choice  in
      1)
          mysql  -u  root  -p ;;
      2)
         sh /root/file_find.sh ;;
      3)
         sh /root/p.sh  ;;
      4) 
        sh /root/c.sh  ;;
esac

예제12.  두개의 파일의 차이를 확인하는 diff 명령어를 아래와 같이 수행하시오 !

# cp  emp.csv   emp100.csv

# vi   emp100.csv      <--- 맨 밑에 있는 행을 지우고 저장하고 나옵니다.

# diff emp.csv emp100.csv

예제13.  아래와 같이  d.sh 라는 스크립트를 만드시오 !

# sh   d.sh
      비교할 첫번째 파일을 입력하세요 ~  emp.csv
      비교할 두번째 파일을 입력하세요 ~  emp100.csv

# vi  d.sh

echo -n '비교할 첫번째 파일을 입력하세요 ~  '
read  first
echo -n '비교할 두번째 파일을 입력하세요 ~  '
read  second

diff   $first  $second

예제14. 위의 d.sh 를 자동화 스크립트 5번에 넣으시오 ~

echo "1. 마리아 디비 접속
2. 파일검색    
3. 권한조정  
4. 복사하기  
5. 차이비교 "

echo  -n  "번호를 입력하세요"
read choice
case  $choice  in
      1)
          mysql  -u  root  -p ;;
      2)
         sh /root/file_find.sh ;;
      3)
         sh /root/p.sh  ;;
      4) 
        sh /root/c.sh  ;;
      5)
       sh /root/d.sh ;;
esac

■ 마리아 디비와 아나콘다를 연동하는 방법 

  os 에 떨궈져있는 파일로 데이터를 관리하고 분석할것인지?
 
  아니면
  
  데이터 베이스에 데이터를 입력하고 안정적으로 데이터를 보관하고 
  누구든지 데이터베이스를 통해서 데이터를 접근할 수 있도록 하고 분석할것인지 ?

※ 반드시 putty 에서 작업하면 안된고 리눅스 서버안에서 작업해야하는데
   리눅스 서버에 접속할 때 부터 oracle 로 접속해야합니다. 

1. py389 를 activate 시키고  mysql 모듈을 설치한다.

$ conda activate py389

(py389) [oracle@centos ~]$ pip install mysql-connector-python-rf

2. mysql 로 접속해서 모든 ip 의 접속 권한을 부여합니다.

(py389) [oracle@centos ~]$ mysql -u root -p

MariaDB [(none)]> use orcl;

MariaDB [orcl]> select Host,User,plugin,authentication_string FROM mysql.user;

MariaDB [orcl]> GRANT ALL PRIVILEGES ON orcl.* to   scott@'192.168.122.1';
Query OK, 0 rows affected (0.021 sec)

MariaDB [orcl]> exit;
scott 으로 접속이 잘되는지 확인합니다.

$ mysql -h 192.168.122.1 -u scott -p

MariaDB [orcl]> exit;

3. 마리아 디비에 접속하겠금 방화벽 설정을 합니다.

py389) [oracle@centos ~]$ su -
Password:
Last login: Wed Jan 13 01:16:13 EST 2021 on pts/5
[root@centos ~]# firewall-cmd --list-all-zones
[root@centos ~]# firewall-cmd --permanent --zone=public --add-port=3306/tcp
success
[root@centos ~]# exit
logout

4. 스파이더를 실행하고 연동합니다.

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Aug 18 15:18:59 2021

@author: oracle
"""

import mysql.connector

 

config = {
    "user": "scott",
    "password": "tiger",
    "host": "192.168.122.1", #local
    "database": "orcl", #Database name
    "port": "3306" #port는 최초 설치 시 입력한 값(기본값은 3306)
}

conn = mysql.connector.connect(**config)

# db select, insert, update, delete 작업 객체
cursor = conn.cursor()


# 실행할 select 문 구성
sql = "SELECT * FROM emp ORDER BY 1 DESC"

# cursor 객체를 이용해서 수행한다.
cursor.execute(sql)

# select 된 결과 셋 얻어오기
rows= cursor.fetchall()  # tuple 이 들어있는 list
print(rows)

예제1. 위에서 출력된 결과를 판다스 데이터 프레임으로 생성하시오 !

import pandas as pd
colname = cursor.description  #  위에서 select해서 메모리 cursor 에 담긴 컬럼명을 가져옴
col = []
for i in colname:
    col.append(i[0])  # 깔끔하게 컬럼명만 col 이라는 변수에 담는다. 
    
emp = pd.DataFrame( list(rows), columns=col) # 컬럼명과 함께 emp 데이트 프레임 생성
emp.columns = emp.columns.str.lower() # 컬럼명을 소문자로 전부 변경
print(emp)

예제2.  마리아 디비에 있는 dept 테이블을 파이썬으로 가져와서 dept 데이터프레임으로
          생성하시오 !

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Aug 18 15:18:59 2021

@author: oracle
"""

import mysql.connector


config = {
    "user": "scott",
    "password": "tiger",
    "host": "192.168.122.1", #local
    "database": "orcl", #Database name
    "port": "3306" #port는 최초 설치 시 입력한 값(기본값은 3306)
}

conn = mysql.connector.connect(**config)

# db select, insert, update, delete 작업 객체
cursor = conn.cursor()


# 실행할 select 문 구성
sql = "SELECT * FROM dept "

# cursor 객체를 이용해서 수행한다.
cursor.execute(sql)

# select 된 결과 셋 얻어오기
rows= cursor.fetchall()  # tuple 이 들어있는 list
print(rows)


import pandas as pd
colname = cursor.description  #  위에서 select해서 메모리 cursor 에 담긴 컬럼명을 가져옴
col = []
for i in colname:
    col.append(i[0])  # 깔끔하게 컬럼명만 col 이라는 변수에 담는다. 
    
dept = pd.DataFrame( list(rows), columns=col) # 컬럼명과 함께 emp 데이트 프레임 생성
dept.columns = dept.columns.str.lower() # 컬럼명을 소문자로 전부 변경
print(dept)


예제3.  마리아 디비에 scott 으로 접속해서 dept 테이블에 아래의 데이터를 입력하시오 !

 deptno : 60
 dname :  research
 loc   :  seoul 

mysql -h 192.168.122.1 -u scott -p

예제4. 지금 입력한 dept 테이블의 60번 부서번호 데이터를 지우고 commit 하세요.

delete  from   dept  
where  deptno = 60;

commit; 

예제5. 사원 테이블에 아래의 데이터를 입력하고 commit 하시오 !

 사원번호: 9912
 사원이름: jack
  월급    :  3000
 직업  :  salesman
 부서번호:  20 

예제6.  직업, 직업별 토탈월급을 출력하는데 토탈월급이 높은것부터 출력하시오 !

 select job, sum(sal)
           from emp
           group by  1
           order by 2 desc;

※ 오라클과는 다르게 마리아 디비는 group by 절에 select 절의 컬럼 순서를 나타내는
   숫자를 사용할 수 있습니다.

예제7.  마리아 디비에서 현재 가지고 있는 테이블이 무엇인지 조회하시오!

MariaDB [orcl]> show tables;
+----------------+
| Tables_in_orcl |
+----------------+
| dept           |
| dept2          |
| emp            |
| emp2           |
| naver          |
| naver2         |
+----------------+

예제8. naver 테이블의 데이터를 spyder 에서 naver 라는 데이터 프레임으로 생성하시오

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Aug 18 15:18:59 2021

@author: oracle
"""

import mysql.connector

 

config = {
    "user": "scott",
    "password": "tiger",
    "host": "192.168.122.1", #local
    "database": "orcl", #Database name
    "port": "3306" #port는 최초 설치 시 입력한 값(기본값은 3306)
}

conn = mysql.connector.connect(**config)

# db select, insert, update, delete 작업 객체
cursor = conn.cursor()


# 실행할 select 문 구성
sql = "SELECT * FROM naver"

# cursor 객체를 이용해서 수행한다.
cursor.execute(sql)

# select 된 결과 셋 얻어오기
rows= cursor.fetchall()  # tuple 이 들어있는 list
print(rows)

import pandas as pd
colname = cursor.description  #  위에서 select해서 메모리 cursor 에 담긴 컬럼명을 가져옴
col = []
for i in colname:
    col.append(i[0])  # 깔끔하게 컬럼명만 col 이라는 변수에 담는다. 
    
naver = pd.DataFrame( list(rows), columns=col) # 컬럼명과 함께 emp 데이트 프레임 생성
naver.columns = naver.columns.str.lower() # 컬럼명을 소문자로 전부 변경
print(naver)

예제9. 사원 테이블의 월급을 막대 그래프로 시각화 하시오 !  

import  matplotlib.pyplot  as  plt

emp['sal'].plot(kind='bar')

예제10.  x축으로 나오는 숫자를 사원이름으로 변경하시오 !

import  matplotlib.pyplot  as  plt

result=emp['sal']
result.index =emp['ename']
result.plot(kind='bar', color='red') 

예제11.  직업, 직업별 토탈월급을 출력하시오 !  ( 연동하는 SQL에서 변경하시오) 

sql = "SELECT  job, sum(sal) as sumsal from  emp  group by  job "

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Aug 18 15:18:59 2021

@author: oracle
"""

import mysql.connector

config = {
    "user": "scott",
    "password": "tiger",
    "host": "192.168.122.1", #local
    "database": "orcl", #Database name
    "port": "3306" #port는 최초 설치 시 입력한 값(기본값은 3306)
}

conn = mysql.connector.connect(**config)

# db select, insert, update, delete 작업 객체
cursor = conn.cursor()


# 실행할 select 문 구성
sql = "select job, sum(sal) as sumsal from emp group by job"

# cursor 객체를 이용해서 수행한다.
cursor.execute(sql)

# select 된 결과 셋 얻어오기
rows= cursor.fetchall()  # tuple 이 들어있는 list
print(rows)

import pandas as pd
colname = cursor.description  #  위에서 select해서 메모리 cursor 에 담긴 컬럼명을 가져옴
col = []
for i in colname:
    col.append(i[0])  # 깔끔하게 컬럼명만 col 이라는 변수에 담는다. 
    
result = pd.DataFrame( list(rows), columns=col) # 컬럼명과 함께 emp 데이트 프레임 생성
result.columns = result.columns.str.lower() # 컬럼명을 소문자로 전부 변경
print(result)

예제12.  위의 결과를 막대그래프로 그리시오 !

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Aug 18 15:18:59 2021

@author: oracle
"""

import mysql.connector

 

config = {
    "user": "scott",
    "password": "tiger",
    "host": "192.168.122.1", #local
    "database": "orcl", #Database name
    "port": "3306" #port는 최초 설치 시 입력한 값(기본값은 3306)
}

conn = mysql.connector.connect(**config)

# db select, insert, update, delete 작업 객체
cursor = conn.cursor()


# 실행할 select 문 구성
sql = "select job, sum(sal) as sumsal from emp group by job"

# cursor 객체를 이용해서 수행한다.
cursor.execute(sql)

# select 된 결과 셋 얻어오기
rows= cursor.fetchall()  # tuple 이 들어있는 list
print(rows)

import pandas as pd
colname = cursor.description  #  위에서 select해서 메모리 cursor 에 담긴 컬럼명을 가져옴
col = []
for i in colname:
    col.append(i[0])  # 깔끔하게 컬럼명만 col 이라는 변수에 담는다. 
    
result = pd.DataFrame( list(rows), columns=col) # 컬럼명과 함께 emp 데이트 프레임 생성
result.columns = result.columns.str.lower() # 컬럼명을 소문자로 전부 변경
print(result)

import  matplotlib.pyplot  as  plt

result2=result['sumsal'].apply(int)   # 숫자로 변경해주는 작업을 해줍니다. 
result2.index =result['job']
result2.plot(kind='bar', color='red') 

예제13.  부서번호, 부서번호별 토탈월급을 막대그래프로 그리시오 !

import mysql.connector

config = {
    "user": "scott",
    "password": "tiger",
    "host": "192.168.122.1", #local
    "database": "orcl", #Database name
    "port": "3306" #port는 최초 설치 시 입력한 값(기본값은 3306)
}

conn = mysql.connector.connect(**config)

# db select, insert, update, delete 작업 객체
cursor = conn.cursor()


# 실행할 select 문 구성
sql = "select deptno, sum(sal) as sumsal from emp group by deptno"

# cursor 객체를 이용해서 수행한다.
cursor.execute(sql)

# select 된 결과 셋 얻어오기
rows= cursor.fetchall()  # tuple 이 들어있는 list
print(rows)

import pandas as pd
colname = cursor.description  #  위에서 select해서 메모리 cursor 에 담긴 컬럼명을 가져옴
col = []
for i in colname:
    col.append(i[0])  # 깔끔하게 컬럼명만 col 이라는 변수에 담는다. 
    
result = pd.DataFrame( list(rows), columns=col) # 컬럼명과 함께 emp 데이트 프레임 생성
result.columns = result.columns.str.lower() # 컬럼명을 소문자로 전부 변경
print(result)

import  matplotlib.pyplot  as  plt

result2=result['sumsal'].apply(int)
result2.index =result['deptno']
result2.plot(kind='bar', color='red') 

45분까지 쉬세요 ~~~~  

오늘의 마지막 문제.  다음과 같이 scott 으로 마리아 디비에 자동으로 접속되는
                            스크립트를 6번으로 생성하시오 ! 화면 캡쳐해서 올리세요 ~~~

어제 배웠던 내용:

  1. 리눅스의 디스크 관리 명령어 :  1. top
                                               2. ps
                                               3. kill
                                               4. sar 
  2. 자동화 스크립트 구현    

  3. 마리와 디비와 파이썬을 연동

어제 받았던 질문?  리눅스 가상서버의 네트워크 구조 

■ 쉘스크립트 작성법 

case 문으로 자동화 스크립트를 구현 

▷ 쉘(shell) 이란 무엇인가?

  shell 이란 운영체제에서 제공하는 명령을 실행하는 프로그램입니다.

▷ 쉘(shell) 스크립트란?

   인터프리터(통역사) 역활을 하는것으로 시스템에서 지원하는 명령어들의
   집합을 묶어서 프로그램화 한것을 말합니다. 

▷ 쉘(shell) 의 종류 
 
1. Boune shell
2. C shell
3. Korn shell
4. base  shell :  가장 많이 사용하는 쉘

쉘스크립트 작성시 맨위에다가 지금부터 작성하는 shell 스크립트 문법은
bash shell 이다라고 명시하고 프로그래밍을 합니다.

#!/bin/bash  ----> 쉘중에서 bash 쉘을 쓰겠다.

▷ 쉘 스크립트 프로그래밍이란 ?

 1. c 언어와 유사한 프로그래밍
 2. 변수, 반복문(loop문), 제어문(if문) 이 사용가능
 3. 별도로 컴파일을 하지 않고 텍스트 파일 형태로 바로 실행이 가능합니다.
 4. vi 편집기로 작성이 가능합니다.
 5. 리눅스의 많은 부분이 쉘 스크립트로 작성이 되어져 있습니다. 

▷ 쉘 스크립트를 작성하고 실행하는 방법

$ vi  a100.sh

#!/bin/bash

echo "yahoo ~~~~~~~~~~~~~~~~~~~~~~~~~~~"

$ sh  a100.sh 

▷변수 사용법 

1. 모든 변수는 문자열(string) 으로 취급됩니다.
2. 변수 이름은 대소문자를 구분합니다.
3. 변수에 값을 대입할 때는 '=' 좌우에 공백이 없어야합니다.
4. 변수에 들어간 문자를 출력하려면 변수 앞에 $ 를 붙이고 echo 명령어로
    출력하면 됩니다.

예:  #  myvar="Hi ~~~~~~~~~~~~~~~"
     #  echo $myvar

▷ 변수의 숫자 계산하는 방법 

1. 변수에 대입한 값은 모두 문자열로 취급이 됩니다.
2. 변수에 들어있는 값을 숫자로 해서 사칙연산(+ - * /)을 하려면
    expr 을 사용해야 합니다.
3. 수식에 괄호 또는 곱하기(*) 를 사용하려면 그 앞에 반드시 역슬래쉬(\) 를 
    붙여야 합니다.

예제: #  num1=100
       #  num2=200
       # echo $num1
       # echo $num2
       # echo $num1 + $num2
       # expr  $num1 + $num2

예제1. num1 과 num2 의 곱을 구하세요 ~

답:  # expr $num1 \* $num2

예제2. 아래의 계산식을 구현하시오 !

 ($num2 + 200) * $num1 

답: # expr \( $num2 + 200 \) \* $num1

■ 파라미터 변수 

 1. 파라미터 변수는 $0, $1, $2, ... 의 형태를 가집니다.
 2. 전체 파라미터는 $* 로 표현합니다.

예제:  
# vi  add.sh

num1=$1
num2=$2
num3=`expr $num1 + $num2`
echo "$num1 와 $num2 를 더하면 $num3 입니다"

# sh add.sh 24 18 

num1=$1
num2=$2
num3=`expr $num1 + $num2`
echo "$num1 와 $num2 를 더하면 $num3 입니다"

설명: 역따옴표를 써야 역따옴표 안의 실행문이 실행되어서 num3 변수에 할당됩니다.

변수=`리눅스 명령어`

리눅스 명령어에 의해서 수행된 결과가 변수에 입력되어야 한다면
역따옴표를 사용해야합니다 

예제1. 아래의 두수를 곱한 결과가 출력되는 쉘 스크립트를 작성하시오 !

# sh  two_number.sh 12 54

 12와 54를 곱하면 648 입니다.

답글로 올려주세요 ~~~

vi two_number.sh
 
num1=$1
num2=$2
num3=`expr $num1 \* $num2`
echo "$num1 와 $num2 를 곱하면 $num3 입니다."
 
sh two_number.sh 12 54

설명: 대입연산자는 양쪽에 공백없이 딱 붙이고
       다른 명령어들은 왠만하면 한칸씩 떼면서 작성합니다. 

▩ 리눅스에서 if 문 사용하기 

 - 문자열 비교

1. "문자열1"=="문자열2"   :  두 문자열이 같으며 True
2. "문자열1" != "문자열2"  :  두 문자열이 같지 않으면 True

 - 숫자열 비교 

1. 숫자1 -eq 숫자2  :  두 숫자가 같으면 True (=)
2. 숫자1 -ne 숫자2  :  두 숫자가 같지않으면 true (!=)
3. 숫자1 -gt 숫자2  :  숫자1 이 숫자2보다 크다면 true (>)
4. 숫자1 -ge 숫자2 :  숫자1 이 숫자2보다 크거나 같다면 true (>=)
5. 숫자1 -lt  숫자2 :  숫자1 이 숫자2보다 작으면 true (<)
6. 숫자1 -le  숫자2 : 숫자1 이 숫자2보다 작거나 같으면 true(<=)
7. !숫자1             :  숫자1 이 거짓이라면 true  (not)

예제:  # vi  if1.sh

if [ 100 -eq 200 ]; then
   echo "100 과 200은 같습니다."
else
   echo "100 과 200은 같지 않습니다."
fi

# sh if1.sh 

예제1. 위의 스크립트에서 파라미터 변수를 이용해서 아래와 같이 실행될 수 있게
         하시오!

# sh  if1.sh 100  200

 100 과 200은 같지 않습니다.

# sh  if1.sh  100  100
 
  100 과 100은 같습니다. 

# vi if1.sh

if [ $1 -eq $2 ]; then
   echo "$1 과 $2은 같습니다."
else
   echo "$1 과 $2은 같지 않습니다."
fi

예제2.  이번에는 아래와 같이 실행되게 if1.sh 의 코드를 수정하시오 

# sh if1.sh 100  200 

100 은 200보다 작습니다.

# sh if1.sh 200  100

200 은 100보다 큽니다.

# sh if1.sh 100 100

100 은 100 과 같습니다. 

답:
if [ $1 -lt $2 ]; then
   echo "$1은 $2보다 작습니다"
elif [ $1 -gt $2 ]; then
   echo "$1은 $2보다 큽니다"
else
   echo "$1 과 $2은 같습니다."
fi

▩ 리눅스의 논리 연산자

1. and  -->  &&  또는 -a
2. or    -->  ||   또는  -o
3. not   --> !

예제:  if [ $sal -lt 2000 ] && [ $job=="SALESMAN" ]; then

                           또는 

       if [ $sal -lt 2000 -a $job=="SALESMAN" ]; then

예제1. emp.txt 에서 scott 의 월급을 출력하시오 ( awk 이용)

# awk -F ',' '$2=="SCOTT" {print $6}' emp.csv

예제2. 위의 스크립트에 파라미터 변수를 사용해서 아래와 같이 실행되는 
          쉘 스크립트를 작성하시오!

# sh find_sal.sh  scott

3000

답:  # vi  find_sal.sh

awk -F ',' -v name=$1 '$2==toupper(name) {print $6}' emp.csv

예제3. 위의 스크립트를 수정해서 아래와 같이 실행되는 쉘스크립트를 작성하시오

# sh find_sal.sh

scott 의 월급은 3000 입니다. 

답:

sal=`awk -F ',' -v name=$1 '$2==toupper(name) {print $6}' emp.csv`
echo "$1 의 월급은 $sal 입니다."

예제4. 위의 스크립트를 이용해서 아래와 같이 실행되게 하시오 !

# sh find_job.sh   allen

allen 의 직업은 SALESMAN 입니다.

답:
job=`awk -F ',' -v name=$1 '$2==toupper(name) {print $3}' emp.csv`
echo "$1 의 직업은 $job 입니다."

데이터 분석가 또는 데이터 엔지니어에게 쉘스크립트가 유용하게 사용되는 경우는?

  데이터 전처리를 보다 효율적이고 쉽게 하기 위해서 사용됩니다.

예제5. 부서번호가 20번인 사원들의 데이터만 20.txt 로 생성하시오 

awk -F ','  '$8==20 {print $0}'  emp.csv >> 20.txt
cat 20.txt

예제6. 다음과 같이 쉘 스크립트를 실행하면 해당 부서번호에 해당하는 데이터만
          생성되겠금 하시오!

# sh  generate_deptno.sh  30

30.txt 가 생겨야 합니다. 

답: # vi generate_deptno.sh

awk -F ','  -v num=$1 '$8==num {print $0}'  emp.csv >> $1.txt
ls -l  $1.txt

예제7. 위의 generate_deptno.sh 스크립트를 이용해서 다음과 같이 실행되게하시오

#sh  generate_deptno.sh  

 생성하고 싶은 데이터의 부서번호를 입력하세요 ~  10

10.txt 가 생성되면 됩니다.        즐거운 점심시간 되세요 ~~~

답: # vi generate_deptno.sh  

echo -n "생성하고 싶은 데이터의 부서번호를 입력하세요 ~ "
read  deptno
awk -F ','  -v num=$deptno '$8==num {print $0}'  emp.csv >> $deptno.txt
ls -l  $deptno.txt

예제8.  위에서 만든 generate_deptno.sh  를 자동화 스크립트(a.sh) 에 추가하시오

echo "1. 마리아 디비 접속
2. 파일검색
3. 권한조정
4. 복사하기
5. 차이비교
6. scott 으로 접속
7. 부서번호 분할 데이터 만들기"

echo  -n  "번호를 입력하세요"
read choice
case  $choice  in
      1)
          mysql  -u  root  -p ;;
      2)
         sh /root/file_find.sh ;;
      3)
         sh /root/p.sh  ;;
      4)
        sh /root/c.sh  ;;
      5)
       sh /root/d.sh ;;
      6)
      mysql -h 192.168.122.1 -u scott -p ;;
      7)
      sh  /root/generate_deptno.sh ;;
esac

▩ 리눅스 쉘에서 loop 문 사용법 

문법:  for  변수  in 값1,값2,값3
        do
             반복할 문장 
        done 

예제: # vi  for1.sh
 
for  i  in  {1..10}
do
    echo $i
done

예제1. emp.csv 를 복사해서 emp1.csv ~  emp100.csv 로 생성하는 쉘스크립트를 
         작성하시오 !

# vi  cp_emp.sh

for  i  in {1..100}
do
    cp  emp.csv  emp$i.csv
done

예제2. 지금 복사한 emp1.csv ~ emp100.csv 의 이름을 employee1.csv ~ employee100.csv
         로 변경하시오 ( 이름 변경하는 명령어 ? mv )

# vi  mv_emp.sh 

for  i  in {1..100}
do
    mv  emp$i.csv  employee$i.csv
done

예제3. employees1.csv ~ employess100.csv 의 파일중에 하나를 랜덤으로 골라서
         파일을 연후에 숫자 3000을 3900 으로 변경하시오 !

# vi employee80.csv

:%s/3000/3900/g 

예제4.  emp.csv 와 employee80.csv 의 파일의 차이가 있는지 확인하시오 !

# diff  --brief   emp.csv  employee80.csv

예제5. for loop 문을 이용해서 employee1.csv ~ employee100.csv 중에
         emp.csv 와 차이가 있는 파일이 무엇인지 한번에 알아내시오 ~

# sh  diff_emp.sh 

for  i  in {1..100}
do
    diff --brief  emp.csv  employee$i.csv
done

예제6. ls -l find_sal.sh 를 했을때 출력되는 결과에서 파일 크기에 해당하는 부분만
        출력하시오 !


#  ls -l find_sal.sh | awk '{print $5}'

문제7. size100 이라는 디렉토리를 /home/oracle 밑에 생성하시오 !


예제8. 확장가 .sh 인 쉘 스크립트중에서 사이즈가 100 바이트 이상인 파일들만
         출력하시오 ( /root 밑에 있는 파일들 중에서...)

# vi  size_100.sh

size2=`ls -l *.sh | awk '{print $5}'`

for  i  in  $size2
do
   if [ ${i:0:3} -gt 100 ]; then      # i 가 문자형인데 ${i:0:3} 을 하면 i 가 숫자로 변경됩니다.
       echo $i                         # 사이즈가 3자리가 안넘어가므로 3으로 적음 
   fi
done

예제9. 사이즈 100바이트 이상인 확장자 .sh 파일들을 /home/oracle/size100 밑에 
         옮기시오 

# vi  mv_size_100.sh

list=`ls -l *.sh | awk '{print $9}'`

for  i  in  $list
do
   size2=`ls -l  $i | awk '{print $5}'`
   if [ $size2 -gt 100 ]; then     
      mv  $i   /home/oracle/size100/                    
   fi
done

■ centos 에 주피터 노트북 설치하기 

설치는 카페 하둡 목차 게시판 참고

예제1. 마리아 디비에 있는 emp 테이블을 주피터 노트북에서 판다스 데이터 프레임으로
         생성하시오

import mysql.connector

config = {
    "user": "scott",
    "password": "tiger",
    "host": "192.168.122.1", #local
    "database": "orcl", #Database name
    "port": "3306" #port는 최초 설치 시 입력한 값(기본값은 3306)
}

conn = mysql.connector.connect(**config)

# db select, insert, update, delete 작업 객체
cursor = conn.cursor()


# 실행할 select 문 구성
sql = "SELECT * FROM emp ORDER BY 1 DESC"

# cursor 객체를 이용해서 수행한다.
cursor.execute(sql)

# select 된 결과 셋 얻어오기
rows= cursor.fetchall()  # tuple 이 들어있는 list

import pandas as pd
colname = cursor.description
col = []
for i in colname:
    col.append(i[0])
    
emp = pd.DataFrame( list(rows), columns=col)
emp.columns = emp.columns.str.lower()
print(emp)

예제2.  직업, 직업별 토탈월급을 출력하시오 !

import mysql.connector

config = {
    "user": "scott",
    "password": "tiger",
    "host": "192.168.122.1", #local
    "database": "orcl", #Database name
    "port": "3306" #port는 최초 설치 시 입력한 값(기본값은 3306)
}

conn = mysql.connector.connect(**config)

# db select, insert, update, delete 작업 객체
cursor = conn.cursor()


# 실행할 select 문 구성
sql = "SELECT job,sum(sal) as sumsal from emp group by job"

# cursor 객체를 이용해서 수행한다.
cursor.execute(sql)

# select 된 결과 셋 얻어오기
rows= cursor.fetchall()  # tuple 이 들어있는 list

import pandas as pd
colname = cursor.description
col = []
for i in colname:
    col.append(i[0])
    
result = pd.DataFrame( list(rows), columns=col)
result.columns = emp.columns.str.lower()
print(result)

예제3. 위의 결과를 막대그래프로 시각화 하시오 !

import  matplotlib.pyplot  as  plt

result2=result['sumsal'].apply(int)   # 숫자로 변경해주는 작업을 해줍니다. 
result2.index =result['job']
result2.plot(kind='bar', color='red') 

▩ 마리아 디비와 파이썬을 연동해서 시각화 하기1

질문:  우리나라에 코로나 확진자가 많은 도시는 어디인가 ? 순위가 어떻게 되는가?

예제1.  코로나 확진자 데이터인 Case.csv 를 리눅스 서버에 올립니다.


예제2. putty 로 root 로 접속해서 자동화 스크립트를 실행하여 scott 유져로 
         접속합니다. 


예제3.  마리아 디비에서 cov_case 테이블을 생성하시오 

create  table  cov_case
(
case_id  int(8),
province   varchar(30),
city    varchar(20),
group2   varchar(20),
infection_case  varchar(50),
confirmed   float,
latitude  varchar(20),
longitude  varchar(20) );

예제4.  Case.csv 를  cov_case 테이블에 입력하시오

LOAD DATA LOCAL INFILE '/root/Case.csv'
REPLACE
INTO TABLE  orcl.cov_case
fields TERMINATED BY ','
ENCLOSED BY '"'
LINES TERMINATED BY '\n'
IGNORE 1 LINES
(case_id, province, city, group2, infection_case, confirmed, latitude, longitude);

예제5.  주피터 노트북에서 마리아 디비에 있는 cov_case 테이블을 데이터 프레임으로
          만드시오 

import mysql.connector
import  pandas as  pd

config = {
    "user": "scott",
    "password": "tiger",
    "host": "192.168.122.1", #local
    "database": "orcl", #Database name
    "port": "3306" #port는 최초 설치 시 입력한 값(기본값은 3306)
}

conn = mysql.connector.connect(**config)

# db select, insert, update, delete 작업 객체
cursor = conn.cursor()


# 실행할 select 문 구성
sql = """select * from  orcl.cov_case
           """

# cursor 객체를 이용해서 수행한다.
cursor.execute(sql)

# select 된 결과 셋 얻어오기
rows = cursor.fetchall()  # tuple 이 들어있는 list

import pandas as pd
colname = cursor.description
col = []
for i in colname:
    col.append(i[0])
    
result = pd.DataFrame( list(rows), columns=col)
result

예제6. 집단감염자가 더 많은지 일반감염자수가 더 많은지 조회하시오 
         ( group2 컬럼의 데이터가 True 면 집단감염, False 면 일반감염입니다.)

result.groupby('group2')['case_id'].count()

또는 

result['group2'].value_counts()

예제7. 위의 결과를 원형 그래프로 시각화 하시오 !

result2 = result['group2'].value_counts()
result2.index=['집단감염','일반감염']
result2.plot(kind='pie')

예제8. 그래프에 한글이 표시되도록 하시오 !

# 리눅스에서 폰트들이 저장된 위치로 이동합니다.
cd /usr/share/fonts

# 그리고 네이버 나눔 폰트를 다운로드 받습니다.
wget http://cdn.naver.com/naver/NanumFont/fontfiles/NanumFont_TTF_ALL.zip

# 그리고 NanumFont_TTF_ALL.zip 의 압축을 풉니다.
unzip NanumFont_TTF_ALL.zip -d NanumFont

# 폰트들이 있는 곳으로 이동합니다.
cd /usr/share/fonts

# 네이버 나눔 폰트를 시스템에 적용하기 위해서 폰트들을 전부 설치합니다.
fc-cache -fv 

# 나눔고딕으로 시각화 합니다.
from matplotlib import font_manager, rc
font_path = "/usr/share/fonts/NanumFont/NanumGothic.ttf"   
font_name = font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)

result2 = result['group2'].value_counts()
result2.index=['집단감염','일반감염']
result2.plot(kind='pie')

예제9.  province 를 출력하고 Province 별 확진자수를 출력하시오 !

result2 = result['province'].value_counts()
result2

오늘의 마지막 문제: 위의 결과를 원형 그래프로 시각화 하시오! 

 5시 신호 보냈습니다. 나머지 시간은 자유롭가 자습 또는 스터디 하세요~~
 6시 신호 보냈습니다. ~~~

import mysql.connector
import  pandas as  pd

config = {
    "user": "scott",
    "password": "tiger",
    "host": "192.168.122.1", #local
    "database": "orcl", #Database name
    "port": "3306" #port는 최초 설치 시 입력한 값(기본값은 3306)
}

conn = mysql.connector.connect(**config)

# db select, insert, update, delete 작업 객체
cursor = conn.cursor()


# 실행할 select 문 구성
sql = """select * from  orcl.cov_case
           """

# cursor 객체를 이용해서 수행한다.
cursor.execute(sql)

# select 된 결과 셋 얻어오기
rows = cursor.fetchall()  # tuple 이 들어있는 list

import pandas as pd
colname = cursor.description
col = []
for i in colname:
    col.append(i[0])
    
result = pd.DataFrame( list(rows), columns=col)
result


from matplotlib import font_manager, rc
font_path = "/usr/share/fonts/NanumFont/NanumGothic.ttf"   
font_name = font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)


result2 = result['province'].value_counts()
result2
#result2.index=['집단감염','일반감염']
result2.plot(kind = 'pie',autopct = '%0.0f%%')

■ 하둡과 스파크 배운 내용 복습

 1. 리눅스 설치
 2. 리눅스 기본 명령어
 3. vi 편집기
 4. 리눅스에 마리아 디비 설치
 5. 리눅스에 아나콘다 설치
 6. 마리아 디비와 아나콘다를 연동 
 7. 리눅스에 있는 데이터를 시각화1
 8. 자동화 스크립트 생성
 
 머신러닝 포트폴리오 

▩ 자동화 스크립트를 구현하기 위해 리눅스 쉘스크립트 배우기 

라이나 생명의 데이터 분석가가 어떻게 데이터 전처리를 했는지 ?

 1. 고객 데이터를 리눅스 쉘을 이용해서 데이터를 필터링을 함
      예: 라이나 생명 고객중에 40대만 따로 분리해서 text 파일을 생성한다. 

 2. 40대의 데이터를 가지고 군집분석(k-means) 을 함 : R 또는 파이썬
 
 3. 40대의 데이터를 가지고 연관분석(아프리오리 알고리즘) : R 또는 파이썬 

 새로운 보험 상품이 출시되어서 보험가입을 유도해야하는데 모든 보험가입자들에게
 다 연락해서 가입을 유도하것보다 보험 가입이 가능할 것 같은 고객들만 필터링해서 연락을
  하는게 훨씬 효과적이기 때문에 이러한 데이터 분석이 필요합니다. 

예제1.  emp.csv 에서 직업이 SALESMAN 인 사원들만 검색하시오~

# awk  -F  ','  '$3=="SALESMAN"  {print $0}'  emp.csv

예제2. 위의 결과를 salesman.csv 로 저장하시오 !

# awk  -F  ','  '$3=="SALESMAN"  {print $0}'  emp.csv  >> salesman.csv

설명: 라이나 생명에서 10대.csv , 20대.csv,  30대.csv, 40대.csv 이렇게 만들었듯이
        우리도 emp.csv 를 가지고 salesman.csv, analyst.csv, clerk.csv, manager.csv 로 
        자동으로  다 만들어지게 하고 싶은것입니다.

예제3.  emp.csv 에서 직업을 출력하는데 중복을 제거해서 출력하시오 !

# awk -F ',' '{print $3}' emp.csv | sort | uniq

예제4. 위의 직업을 하나씩 불러와서 for loop 문에서 출력하는 코드를 작성하시오 !

# vi  for_job.sh

job=`awk -F ',' '{print $3}' emp.csv | sort | uniq`

for  i  in  $job
do
    echo $i
done

예제5. 위의 스크립트를 이용해서 해당 직업의 사원들의 데이터만 직업을 이름으로 해서
         다음과 같이 생성되게하시오 !

# sh  generate_job.sh
# ls

salesman.csv   manager.csv   analyst.csv   clerk.csv ...

답:

job=`awk -F ',' '{print tolower($3)}' emp.csv | sort | uniq`  # 소문자로 변경해서 직업출력

for i in $job
do
  awk -F ',' -v job2=$i 'tolower($3)==job2 {print $0}' emp.csv >> $i.csv
ls -l $i.csv
done

예제6. 위의 스크립트를 이용해서 부서번호별로 emp.csv 가 쪼개지겠금
         스크립트를 생성하시오 !

$ sh  make_deptno.sh

$ ls -lrt

  deptno10.csv           deptno20.csv          deptno30.csv 

답:
deptno=`awk -F ','  '{print $8}'   emp.csv | sort  | uniq`

for i  in $deptno
do
  awk  -F  ','  -v  num=$i  '$8==num {print $0}'  emp.csv >>  deptno${i:0:2}.csv
done

설명: deptno${i:0:2} 를 사용하는 이유는 공백 때문인데  i 에서 앞에서 부터 
        2자리만 잘라내라 ~

예제7. 서울시 소상공인 데이터를 리눅스 서버에 올리시오 !
 
 $ head  seoul.csv


예제8. 서울시에는 부동산이 몇개가 있는가 ?  ( 5번째 컬럼이 부동산인것으로 검색하세요)

데이터에 더블쿼테이션 마크가 있으므로 더블 쿼테이션 마크를 다 없애야 합니다.

# cp  seoul.csv   s.csv

# chmod 777  s.csv 

# vi s.csv 

:%s/"//g

#awk -F ',' '$5=="부동산" {print $0}' s.csv | wc -l

예제9.  5번째 컬럼인 업종을 중복제거해서 출력하시오 !

# awk -F ',' '{print $5}'  s.csv | sort | uniq

45분까지 쉬세요 ~~

민석이 코드:
grep '부동산' seoul.csv | awk -F ',' '{print $0}' | wc -l

동민이 코드:
awk -F ',' '$5=="\"부동산\"" {print $0}' seoul.csv | wc -l

12742건 

awk -F ',' '{print $5}' seoul.csv | sort  | uniq

12748건 --->  판다스에서 확인
12742건 --->  리눅스에서 확인 

예제10. 마리아 디비로 접속해서 서울시 소상공인 데이터를 가지고 테이블을 생성하시오

마리아디비 접속할 때 scott 으로 접속하세요 

create table seoul
(storecode varchar(10),store varchar(300),branch varchar(100),seg1code varchar(2),seg1name varchar(20),
seg2code varchar(20),seg2name varchar(100),seg3code varchar(20),seg3name varchar(100),bizcode varchar(20),
bizname varchar(100),citycode varchar(30),city varchar(30),guncode varchar(10),gun varchar(30),dong1code varchar(20),
dong1 varchar(30),dong2code varchar(20),dong2 varchar(30),dgibuncode varchar(20),e1code varchar(20),e1name
varchar(80),e2code varchar(20),e3code varchar(20),address1 varchar(300),streetcode varchar(50),street
varchar(300),buidingcode1 varchar(50),buidingcode2 varchar(50),buidingcode3 varchar(50),building
varchar(100),address2 varchar(300),zipcode1 varchar(50),zipcode2 varchar(50),donginfo varchar(50),floor
varchar(20),hoinfo varchar(20),longitude varchar(50),latitude varchar(50) );

예제11. /root  밑에 있는 seoul.csv 를 seoul 테이블에 로드하시오 !

LOAD DATA LOCAL INFILE '/root/seoul.csv'
REPLACE
INTO TABLE orcl.seoul
fields TERMINATED BY ','
ENCLOSED BY '"'
LINES TERMINATED BY '\r\n'
IGNORE 1 LINES
(storecode,store,branch,seg1code,seg1name,seg2code,seg2name,seg3code,seg3name,bizcode,bizname,citycode,city,guncode,gun,dong1code,dong1,dong2code,dong2,dgibuncode,e1code,e1name,e2code,e3code,address1,streetcode,street,buidingcode1,buidingcode2,buidingcode3,building,address2,zipcode1,zipcode2,donginfo,floor,hoinfo,longitude,latitude);

예제12.  5번째 컬럼인 seg1name 을 중복제거해서 출력하시오 

MariaDB [orcl]> select distinct seg1name
                       from  seoul;

예제13.  서울시에 부동산 업종이 몇개가 있는지 조회하시오 (seg1name , 대분류명칭)

MariaDB [orcl]> select count(*)
    ->            from  seoul
    ->            where  seg1name='부동산';
+----------+
| count(*) |
+----------+
|    12748 |
+----------+

예제14. 업종(5번째 컬럼) , 업종별 건수가 어떻게 되는지 조회하시오

MariaDB [orcl]> select  seg1name, count(*)
    ->              from seoul
    ->              group by seg1name;

예제15.  위의 결과를 다시 출력하는데 건수가 높은것 부터 출력하시오 !

MariaDB [orcl]> select  seg1name, count(*)
                      from seoul
                     group by  1 
                     order  by  2  desc; 

| seg1name             | count(*) |
+----------------------+----------+
| 음식                 |   126203 |
| 소매                 |    89857 |
| 생활서비스           |    55634 |
| 학문/교육            |    21426 |
| 부동산               |    12748 |
| 관광/여가/오락       |     6633 |
| 숙박                 |     2322 |
| 스포츠               |     1255 |
+----------------------+----------+
8 rows in set (0.463 sec)

예제16. 세종시의 소상공인 데이터를 담기 위한 테이블을 생성하고 세종시 데이터를 로드하시오

# ls -l 17.csv

create table sejong
(storecode varchar(10),store varchar(300),branch varchar(100),seg1code varchar(2),seg1name varchar(20),
seg2code varchar(20),seg2name varchar(100),seg3code varchar(20),seg3name varchar(100),bizcode varchar(20),
bizname varchar(100),citycode varchar(30),city varchar(30),guncode varchar(10),gun varchar(30),dong1code varchar(20),
dong1 varchar(30),dong2code varchar(20),dong2 varchar(30),dgibuncode varchar(20),e1code varchar(20),e1name
varchar(80),e2code varchar(20),e3code varchar(20),address1 varchar(300),streetcode varchar(50),street
varchar(300),buidingcode1 varchar(50),buidingcode2 varchar(50),buidingcode3 varchar(50),building
varchar(100),address2 varchar(300),zipcode1 varchar(50),zipcode2 varchar(50),donginfo varchar(50),floor
varchar(20),hoinfo varchar(20),longitude varchar(50),latitude varchar(50) );

LOAD DATA LOCAL INFILE '/root/17.csv'
REPLACE
INTO TABLE orcl.sejong
fields TERMINATED BY ','
ENCLOSED BY '"'
LINES TERMINATED BY '\r\n'
IGNORE 1 LINES
(storecode,store,branch,seg1code,seg1name,seg2code,seg2name,seg3code,seg3name,bizcode,bizname,citycode,city,guncode,gun,dong1code,dong1,dong2code,dong2,dgibuncode,e1code,e1name,e2code,e3code,address1,streetcode,street,buidingcode1,buidingcode2,buidingcode3,building,address2,zipcode1,zipcode2,donginfo,floor,hoinfo,longitude,latitude);

예제17.  아래의 서울시 업종별 건수와 세종시 업종별 건수를 서로 옆에 비교해서 출력하시오 !
            (점심시간 문제 )

           서울시                                                       세종시 
| seg1name             | count(*) |
+----------------------+----------+
| 음식                 |   126203 |
| 소매                 |    89857 |
| 생활서비스           |    55634 |
| 학문/교육            |    21426 |
| 부동산               |    12748 |
| 관광/여가/오락       |     6633 |
| 숙박                 |     2322 |
| 스포츠               |     1255 |
+----------------------+----------+

 select  seg1name, count(*)
                      from sejong
                     group by  1 
                     order  by  2  desc; 


▩ 마리아 디비의 데이터를 파이썬에서 시각화 하기 

우리나라 소상공인 데이터에서 서울시, 세종시, 제주시의 데이터를 시각화 하기 

예제1.  리눅스 서버 안에서 주피터 노트북을 실행합니다.

$ conda activate py389

$ jupyter notebook

예제2. 마리아 디비에서 seoul 테이블을 파이썬의 판다스 데이터 프레임으로 생성하시오
import mysql.connector

config = {
    "user": "scott",
    "password": "tiger",
    "host": "192.168.122.1", #local
    "database": "orcl", #Database name
    "port": "3306" #port는 최초 설치 시 입력한 값(기본값은 3306)
}

conn = mysql.connector.connect(**config)

# db select, insert, update, delete 작업 객체
cursor = conn.cursor()


# 실행할 select 문 구성
sql = "SELECT * FROM seoul"

# cursor 객체를 이용해서 수행한다.
cursor.execute(sql)

# select 된 결과 셋 얻어오기
rows= cursor.fetchall()  # tuple 이 들어있는 list
print(rows)

import pandas as pd
colname = cursor.description
col = []
for i in colname:
    col.append(i[0])
    
seoul = pd.DataFrame( list(rows), columns=col)
seoul.columns = seoul.columns.str.lower()
print(seoul)



예제3. 업종, 업종별 건수를 출력하는데 건수가 높은것부터 출력하는 쿼리문을
         연동하는 sql 코드에 붙여서 출력하시오 !

# 실행할 select 문 구성
sql = "select  seg1name, count(*)  cnt   from  seoul group by 1 order by 2 desc"

   seg1name     cnt
0        음식  126203
1        소매   89857
2     생활서비스   55634
3     학문/교육   21426
4       부동산   12748
5  관광/여가/오락    6633
6        숙박    2322
7       스포츠    1255

예제4. 위의 결과를 막대 그래프로 시각화 하시오 !

import mysql.connector

config = {
    "user": "scott",
    "password": "tiger",
    "host": "192.168.122.1", #local
    "database": "orcl", #Database name
    "port": "3306" #port는 최초 설치 시 입력한 값(기본값은 3306)
}

conn = mysql.connector.connect(**config)

# db select, insert, update, delete 작업 객체
cursor = conn.cursor()


# 실행할 select 문 구성
sql = "select  seg1name, count(*)  cnt   from  seoul group by 1 order by 2 desc"

# cursor 객체를 이용해서 수행한다.
cursor.execute(sql)

# select 된 결과 셋 얻어오기
rows= cursor.fetchall()  # tuple 이 들어있는 list

import pandas as pd
colname = cursor.description
col = []
for i in colname:
    col.append(i[0])
    
result = pd.DataFrame( list(rows), columns=col)
result.columns = result.columns.str.lower()

# 한글이 출력되게 아래의 4줄 추가 
from matplotlib import font_manager, rc
font_path = "/usr/share/fonts/NanumFont/NanumGothic.ttf"   
font_name = font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)

# 막대그래프를 그린다. 
result.plot(kind='bar', color='red', x='seg1name')

예제5. 세종시 데이터도 위와 같이 출력하는데 막대 그래프 색깔을 파란색으로 하세요


import mysql.connector

config = {
    "user": "scott",
    "password": "tiger",
    "host": "192.168.122.1", #local
    "database": "orcl", #Database name
    "port": "3306" #port는 최초 설치 시 입력한 값(기본값은 3306)
}

conn = mysql.connector.connect(**config)

# db select, insert, update, delete 작업 객체
cursor = conn.cursor()


# 실행할 select 문 구성
sql = "select  seg1name, count(*)  cnt   from  sejong group by 1 order by 2 desc"

# cursor 객체를 이용해서 수행한다.
cursor.execute(sql)

# select 된 결과 셋 얻어오기
rows= cursor.fetchall()  # tuple 이 들어있는 list

import pandas as pd
colname = cursor.description
col = []
for i in colname:
    col.append(i[0])
    
result = pd.DataFrame( list(rows), columns=col)
result.columns = result.columns.str.lower()

# 한글이 출력되게 아래의 4줄 추가 
from matplotlib import font_manager, rc
font_path = "/usr/share/fonts/NanumFont/NanumGothic.ttf"   
font_name = font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)

# 막대그래프를 그린다. 
result.plot(kind='bar', x='seg1name')

예제6.  위의 그래프를 원형 그래프로 그리는데 그래프 안에 비율인 % 도 출력되게하시오
  
result.set_index('seg1name').plot(kind = 'pie',autopct='%0.0f%%',subplots = True,figsize=(10,10) )


질문1: 세종시에는 어떠한 업종이 많은가?
질문2: 세종시에는 어느 지자체에 상권이 많은가?

예제7. 마리아 디비에서 describe  sejong; 이라고 해봅니다. 

 describe  sejoing;

예제8.  dong1 의 데이터를 중복제거해서 출력하시오 

select  distinct  dong1
 from   sejong;

예제9.  어느 지자체에 상권이 많은지 dong1 을 출력하고 dong1 별 건수를 출력하시오 

select dong1, count(*)
       from  sejong
       group by dong1
       order  by  2 desc; 

예제10 아래와 같이 세종시 데이터를 그래프로 시각화 하시오 !

select dong1, count(*)
       from  sejong
       group by dong1
       order  by  2 desc
       limit  5;

result.set_index('dong1').plot(kind = 'pie',autopct='%0.0f%%',subplots = True,figsize=(10,10) )

예제11.  서울시와 세종시의 2개의 원형 그래프를 하나의 결과로 출력하시오 


import mysql.connector

config = {
    "user": "scott",
    "password": "tiger",
    "host": "192.168.122.1", #local
    "database": "orcl", #Database name
    "port": "3306" #port는 최초 설치 시 입력한 값(기본값은 3306)
}

conn = mysql.connector.connect(**config)

# db select, insert, update, delete 작업 객체
cursor = conn.cursor()

# 세종시의 대한 데이터 프레임 구성

# 실행할 select 문 구성
sql = "select dong1, count(*)  cnt from  sejong group by dong1 order  by  2 desc limit  5";

# cursor 객체를 이용해서 수행한다.
cursor.execute(sql)

# select 된 결과 셋 얻어오기
rows= cursor.fetchall()  # tuple 이 들어있는 list

import pandas as pd
colname = cursor.description
col = []
for i in colname:
    col.append(i[0])
    
result = pd.DataFrame( list(rows), columns=col)
result.columns = result.columns.str.lower()


# 서울시에 대한 데이터 프레임 구성

# 실행할 select 문 구성
sql2 = "select dong1, count(*) cnt from  seoul group by dong1 order  by  2 desc limit  5";

# cursor 객체를 이용해서 수행한다.
cursor.execute(sql2)

# select 된 결과 셋 얻어오기
rows= cursor.fetchall()  # tuple 이 들어있는 list

import pandas as pd
colname = cursor.description
col = []
for i in colname:
    col.append(i[0])
    
result2 = pd.DataFrame( list(rows), columns=col)
result2.columns = result2.columns.str.lower()
# 그래프 두개를 한번에 추가하는 코드 

import matplotlib.pyplot as plt

fig = plt.figure(figsize=(10,10))  #  가로 10, 세로 10 으로 전체 사이즈를 설정해라 ~
ax1 = fig.add_subplot(1,2,1)      # 하나(1)의 화면을 2개로 나눠서 첫번째(1) 를 ax1 영역을 구성
ax2 = fig.add_subplot(1,2,2)      # 하나(1)의 화면을 2개로 나워서 두번재(2) 를 ax2 영역으로 구성

ax1.pie(result['cnt'], labels=result.dong1, autopct='%0.0f%%')   # 세종시 
ax2.pie(result2['cnt'], labels=result2.dong1, autopct='%0.0f%%')  # 서울시

ax1.set_title('세종시 업종 비율')  # 제목도 각각 설정
ax2.set_title('서울시 업종 비율')

plt.show()

예제12. 제주시 소상공 데이터를 저장하기 위한 테이블을 jeju 라는 이름으로 생성하고
           제주시 데이터를 입력하시오 !

create table jeju
(storecode varchar(10),store varchar(300),branch varchar(100),seg1code varchar(2),seg1name varchar(20),
seg2code varchar(20),seg2name varchar(100),seg3code varchar(20),seg3name varchar(100),bizcode varchar(20),
bizname varchar(100),citycode varchar(30),city varchar(30),guncode varchar(10),gun varchar(30),dong1code varchar(20),
dong1 varchar(30),dong2code varchar(20),dong2 varchar(30),dgibuncode varchar(20),e1code varchar(20),e1name
varchar(80),e2code varchar(20),e3code varchar(20),address1 varchar(300),streetcode varchar(50),street
varchar(300),buidingcode1 varchar(50),buidingcode2 varchar(50),buidingcode3 varchar(50),building
varchar(100),address2 varchar(300),zipcode1 varchar(50),zipcode2 varchar(50),donginfo varchar(50),floor
varchar(20),hoinfo varchar(20),longitude varchar(50),latitude varchar(50) );

LOAD DATA LOCAL INFILE '/root/16.csv'
REPLACE
INTO TABLE orcl.jeju
fields TERMINATED BY ','
ENCLOSED BY '"'
LINES TERMINATED BY '\r\n'
IGNORE 1 LINES
(storecode,store,branch,seg1code,seg1name,seg2code,seg2name,seg3code,seg3name,bizcode,bizname,citycode,city,guncode,gun,dong1code,dong1,dong2code,dong2,dgibuncode,e1code,e1name,e2code,e3code,address1,streetcode,street,buidingcode1,buidingcode2,buidingcode3,building,address2,zipcode1,zipcode2,donginfo,floor,hoinfo,longitude,latitude);

예제13. 제주시의 업종(seg1name) , 업종별 건수를 출력하는데 건수가 높은것 부터 출력하시오

select  seg1name, count(*) as  cnt 
  from  jeju
  group  by  1
  order  by  2  desc;  

예제14.  두개의 그래프를 같이 출력하는 예제11번 코드를 가져와서 하나는 제주, 하나는 세종
            으로 해서 아래의 그래프를 시각화 하시오 !


import mysql.connector

config = {
    "user": "scott",
    "password": "tiger",
    "host": "192.168.122.1", #local
    "database": "orcl", #Database name
    "port": "3306" #port는 최초 설치 시 입력한 값(기본값은 3306)
}

conn = mysql.connector.connect(**config)

# db select, insert, update, delete 작업 객체
cursor = conn.cursor()

# 세종시의 대한 데이터 프레임 구성

# 실행할 select 문 구성
sql = "select seg1name, count(*)  cnt from  sejong group by dong1 order  by  2 desc";

# cursor 객체를 이용해서 수행한다.
cursor.execute(sql)

# select 된 결과 셋 얻어오기
rows= cursor.fetchall()  # tuple 이 들어있는 list

import pandas as pd
colname = cursor.description
col = []
for i in colname:
    col.append(i[0])
    
result = pd.DataFrame( list(rows), columns=col)
result.columns = result.columns.str.lower()


# 서울시에 대한 데이터 프레임 구성

# 실행할 select 문 구성
sql2 = "select seg1name, count(*) cnt from  seoul group by dong1 order  by  2 desc";

# cursor 객체를 이용해서 수행한다.
cursor.execute(sql2)

# select 된 결과 셋 얻어오기
rows= cursor.fetchall()  # tuple 이 들어있는 list

import pandas as pd
colname = cursor.description
col = []
for i in colname:
    col.append(i[0])
    
result2 = pd.DataFrame( list(rows), columns=col)
result2.columns = result2.columns.str.lower()
# 그래프 두개를 한번에 추가하는 코드 

import matplotlib.pyplot as plt

fig = plt.figure(figsize=(20,10))  #  가로 10, 세로 10 으로 전체 사이즈를 설정해라 ~
ax1 = fig.add_subplot(1,2,1)      # 하나(1)의 화면을 2개로 나눠서 첫번째(1) 를 ax1 영역을 구성
ax2 = fig.add_subplot(1,2,2)      # 하나(1)의 화면을 2개로 나워서 두번재(2) 를 ax2 영역으로 구성

ax1.bar(x='seg1name', height='cnt', data=result, color='red')  # 세종시
ax2.bar(x='seg1name', height='cnt', data=result2)  # 제주시

ax1.set_title('세종시 업종 비율')  # 제목도 각각 설정
ax2.set_title('제주시 업종 비율')

ax1.grid()
ax2.grid()                      45분까지 쉬세요 ~~~

plt.show()

▩ 리눅스 마리아 디비에 있는 데이터를 파이썬과 연동해서 지도 그래프 그리기

예제1.  jeju 테이블에서  업종명, 위도, 경도를 출력하시오 !

 select  store  ,longitude,  latitude
        from  jeju
        limit  10;
 
예제2.  제주도를 지도 그래프로 시각화 하시오 !

import  pandas as  pd

config = {
    "user": "scott",
    "password": "tiger",
    "host": "192.168.122.1", #local
    "database": "orcl", #Database name
    "port": "3306" #port는 최초 설치 시 입력한 값(기본값은 3306)
}

conn = mysql.connector.connect(**config)

# db select, insert, update, delete 작업 객체
cursor = conn.cursor()


# 실행할 select 문 구성
sql = """select  longitude, latitude,seg3name
               from  jeju"""

# cursor 객체를 이용해서 수행한다.
cursor.execute(sql)

# select 된 결과 셋 얻어오기
resultList = cursor.fetchall()  # tuple 이 들어있는 list

df = pd.DataFrame(resultList)

df.columns = ['lon','lat','seg3name']   # 컬럼명 지정
df['lat']=df['lat'].apply(float)             # 실수형으로 변경
df['lon']=df['lon'].apply(float)           # 실수형으로 변경 

import folium   # 지도 그래프를 그리기 위한 모듈 

lat = round(df['lat'].mean(),6)  #  위도 데이터의 평균값을 구한다
long = round(df['lon'].mean(),6) # 경도 데이터의 평균값을 구한다

map1=folium.Map(location=[lat,long],tiles='Stamen Terrain',zoom_start=12)

map1.save("/home/oracle/mymap.html")


예제3. 제주도 지도에 제주도 상권을 빨간색 점으로 시각화 하시오 !

상권시각화 부분만 가져오세요 ~

import pandas
import json
import folium

lat = round(df['lat'].mean(),6)  # 위도 평균값
long = round(df['lon'].mean(),6) # 경도 평균값 

map1=folium.Map(location=[lat,long],tiles='Stamen Terrain',zoom_start=12)  # 제주도 지도를 먼저 그린다.

for i in df.index:  # df 데이터 프레임에서 인덱스 번호를 하나씩 가져온다. 
    sub_lat = df.loc[i,'lat']
    sub_long = df.loc[i,'lon']
    title = df.loc[i,'seg3name']

    folium.CircleMarker([sub_lat,sub_long], radius=2,color = 'red',fill = True,fill_color = 'red',fill_opacity = 0.7,popup = title).add_to(map1)

map1.save("/home/oracle/mymap2.html")

예제4. 세종시의 위도, 경도, 업종을 출력하는 쿼리문을 작성하시오 !

select  longitude, latitude,seg3name
               from  sejong ;


[오늘의 마지막 문제]  세종시의 상권을 세종시 지도에 시각화 하시오 !
                            또는 소상공인 데이터에서 원하는 지역의 상권을 시각화 하세요 !

8월 30일 까지 제출 

제출물 3가지 : 1. 발표pdf 파일   2. 코드   3.데이터 첨부와 출처

데이터 분석가로 지원할때 사용하는 포트폴리오 이므로 잘 만들어주세요 ~~

■ 복습하기전에 먼저 하둡 설치파일을 다운로드 받겠습니다.

데이터분석가, 딥러닝 개발자 둘다 갖추어야할 기술 :  "하둡과 스파크" 

1. 리눅스 설치
2. 리눅스 기본 명령어
3. 마리아 디비 설치
4. 마리아 디비에서 SQL 을 사용
5. 아나콘다 설치하고 마리아 디비와 연동
6. 데이터 시각화 ( 원형 그래프, 막대 그래프, 지도 그래프)

■ 하둡 설치에 앞서서 기존 리눅스 시스템을 복제(백업) 하는 방법

 하둡설치는 정말 명령어 한줄 한줄 꼼꼼하게 진행해야하는데 혹시라도 실패하게 되면
  다시 처음부터 진행해야하는데 하둡을 삭제하고 다시 설치하는 과정에서 여러 문제들이
  생길수 있습니다.  하둡이 공짜다 보니까 그런 문제해결을 우리가 스스로 해야합니다.
  문제 해결하느라 여러시간 구글링하다 보면 수업을 못따라오니까 만약을 대비해서
  복제를 하나 하는게 현명한 방법입니다.


▩ 하둡 이란 무엇인가 ?

  하둡(hadoop) ?   대용량 데이터를 분산 처리할 수 있는 자바 기반의 오픈소스 프레임워크

 대용량 데이터를 분산 처리할 수 있는 자바 기반의 오픈 소스 프레임워크로서
 하둡은 분산 파일 시스템인 HDFS(Hadoop Distributed File System) 에 데이터를 저장하고
 분산처리시스템인 멥리듀스를 이용해서 데이터를 처리합니다.


현업에서는 데이터 분석가들이 하둡을 어떻게 활용하는가?

반정형 데이터와 비정형 데이터를 하둡 시스템에 저장하고 데이터 분석을 위해 활용합니다.
정형화된 데이터는 히스토리성 데이터를 주로 하둡에 저장하고 데이터 분석을 합니다.


데이터의 종류 3가지 ?  1. 정형화된 데이터 :  emp 테이블과 같은 rdbms 에 저장된 테이블
                                                           형태의 데이터 
                               2. 반정형화된 데이터 : 웹로그와 sns 데이터, html, json 파일
                               3. 비정형화된 데이터 : 동영상이나 이미지 데이터, 텍스트 데이터 

리눅스의 데이터를 마리아 디비에만 저장하면 되지 왜 굳이 하둡을 사용하는가?

  아주 큰 대용량 데이터를 마리아 디비에서 조인을 하면 먹통이 되면서 수행되지 않지만
  하둡에서는 수행됩니다. 

    relation  database  management  system 

    rdbms 제품                 vs   비rdbms 제품 

  1. oracle                               하둡 
  2. mssql                               스칼라 
  3. mysql    유료
-------------------
  4. maria db  무료 
  5. postgreSQL 

* 라이나 생명 데이터 분석가 

 1. 하둡에 고객 데이터(정형화 된 데이터)를 저장하고 나이대 별로 분리해서 
     CSV 파일을 생성합니다.
 2. 나이대별로 분리한 csv 파일 데이터를 가지고 군집분석
 3. 나이대별로 분리한 csv 파일 데이터를 가지고 연관분석

* 아프리카 tv 데이터 분석가

 1. 채팅 데이터(비정형 데이터)를 다 하둡에 저장한다.
 2. 특정 단어를 자주 사용하는 채팅방의 형태를 분석한다.
 3. 머신러닝을 사용해서 채팅 데이터를 학습 시키고 특정 단어를 사용하는 사람은
    불건전한 대화를 이끌 가능성이 높다는것을 미리 예측하고 채팅방을 자동 폐쇄시킨다.

* 하둡이 나온 배경지식 ?

  구글에서 구글 서버에 쌓여지는 수많은 빅데이터들을 구글에서도 처음에는 
  rdbms(오라클) 에 입력하고 데이터를 저장하려고 시도를 했으나
  너무 데이터가 많아서 실패를 하고 자체적으로 빅데이터를 저장할 기술을 개발했습니다.
  그리고 대외적으로 이 기술에 대한 논문을 하나 발표했습니다. 

 이 논문을 더그커팅(하둡을 만든이)이라는 분이 읽고 자바로 구현했다.
 하둡은 자바로 만들어졌다. 자바를 몰라도 하둡의 데이터를 쉽게 다룰수 있도록 NoSQL 이라는
 기술이 나오면서 SQL 과 같은 언어로 쉽게 빅데이터를 다룰 수 있게 되었습니다.

 NoSQL ?  ( Not  Only SQL )

 NoSQL 은 전통적인 RDBMS 와 다른 DBMS 를 지칭하기 위한 용어입니다.
 자바를 몰라도 하둡에 저장된 데이터를 검색하고 다룰 수 있는 언어

예:  1. hive  ---> SQL 과 똑같다
      2. pig  ---->  SQL 과 다름
      3. mongo db  -->  SQL 과 다름 

회사의 서버의 구조:

             OTLP 서버                                   VS        DW 서버
                ↓                                                         ↓
          Online Transaction Processing                   Data Warehouse
          ( 실시간으로 발생하는 데이터)                     과거 데이터 


                     서버관리자, DBA, DW 개발자,  데이터 분석가, 데이터 엔지니어, 딥러닝 개발자

                                                 NOSQL
하둡  ------------------------------->  Hive (벌떼)
노란 코끼리                                  Pig (돼지)
                                               mongo db
                                                Tajo (타조)

* 하둡의 장점 ?

  1. 공짜입니다.
  2. 분산 처리가 가능합니다.

 여러대의 노드(컴퓨터) 를 묶어서 마치 하나의 서버처럼 보이게 하는 기법 
 우리반 컴퓨터(한대의 메모리가 8기가) 30대를 다 묶어서 분산 처리 파일 시스템을 구성
 했으면 마치 30대의 컴퓨터를 하나의 컴퓨터 처럼 사용할 수 있습니다. 
 240기가의 메모리와 30개의 cpu 를 다 사용할 수 있게 됩니다.

 한대의 서버로 1테라 바이트의 데이터를 처리하는데 걸리는 시간이 2시간 반이 걸린다고 
 하면 하둡으로 여러대의 서버를 병렬로 묶어서 작업하면 2분 내에 데이터를 읽을 수 있습니다.

예: 2008년 뉴욕타임즈는 130년 분량의 신문기사 1100만 페이지를 하둡을 이용해서
     하루만에 pdf 로 변환했습니다. 이때 든 비용이 200만원 밖에 안들었습니다. 
     만약에 하둡이 아닌 일반 서버로 처리했다면 14년이 걸렸을것으로 예상했습니다. 

■ 하둡 생태계 시스템 구조     


  빅데이터 분석                   R, python 을 이용해서 데이터 분석 
         ↑
   빅데이터 저장                   mongdb     hbase     cassandra  couchdb
         ↑
  분산 처리 지원                    hive     pig    sqoop   zookeeper
          ↑
   분산 배치 처리                  하둡(hadoop) - MapReduce 
          ↑
   분산 파일 처리                   하둡(hadoop) - HDFS 

 하둡이 너무 느려서 나온게 바로 '스칼라' 입니다. 


 야후의 경우는 약 5만대의 서버(컴퓨터)를 연결해서 하둡을 운영하고 있고
 페이스북은 약 1만대 이상의 하둡 클러스터를 이용하고 있다.

  hive>  select * from emp;                         45분까지 쉬세요 ~~

■ 하둡 구성도

   1.네임노드   :  메타데이터가 위치하는 곳 

      meta data ?  emp.csv 같은 데이터가 데이터 노드들중에 어느 컴퓨터에 있다라는
                        위치정보 데이터                       

   2.보조 네임노드 :  주기적으로 네임노드의 메타 데이터를 백업하면서 혹시 네임노드가 
                            다운되었을때 네임노드 역활을 하는 컴퓨터 

   3. 나머지는 전부 데이터 노드 : emp.csv 같은 데이터를 저장하는 컴퓨터들 
                                           원본 1개에 백업본 2개를 항상 유지합니다. 

 만약 컴퓨터 8대를 하둡파일시스템으로 구성한다면 네임노드 1대, 보조 네임노드 1대,
 6대의 데이터 노드들입니다. 

* 하둡 홈페이지 

http://hadoop.apache.org

cenos 에 하둡 설치파일.zip 압축을 풀면 아래의 3개의 파일 있습니다.

1. hadoop-1.2.1.tar.gz   :   하둡 설치 파일 
2. jdk-7u60-linux-i586.gz  : 자바 설치 파일 (하둡이 자바로 이루어져 있어서 먼저 설치해야함)
3. protobuf-2.5.0.tar.gz :  서버간의 통신을 위한 프로그램 설치파일입니다.

 
■ 하둡 설치의 큰 그림 

1.  java 설치 --->  하둡이 자바로 만들어져 있어서 자바를 설치해야합니다
      ↓
2. keygen 생성  --> 여러 컴퓨터들을 묶어서 마치 하나의 컴퓨터 처럼 보이게 하는게
                           하둡의 목표이므로 컴퓨터들끼리 서로 데이터 전송을 할때 접속을 해야
                           하는데 접속할때 매번 패스워드를 물어보지 않아도 접속할 수 있게
                           해야해서 keygen 을 생성해야합니다.

3. 하둡 설치 --->    하둡설치는 아주 간단한데 그냥 4개의 파일의 내용만 수정하면 됩니다.
 
4개의 파일은 다음과 같습니다.    
                
 1. hadoop-env.sh : 자바 홈디렉토리와 hadoop 홈디렉토리가 어딘지 지정한다. 
 2. core-site.xml : 하둡의 네임노드가 어느 서버인지를 지정한다.
 3. mapred-site.xml : java 로 만들어진 mapreduce 프레임워크와 관련된 정보를 지정하는 파일 
 4. hdfs-site.xml : 하둡 파일 시스템인 HDFS(Hadoop Distributed File System) 와 관련된 정보를
                       저장하는 파일 

먼저 설치파일을 모바텀을 이용해서 리눅스 시스템에 /root 밑에 올립니다. 

리눅스 서버내로 root 로 접속해서 인터넷이 되는지 확인합니다. 


여유공간이 있다면 하둡을 설치한 상태의 리눅스 서버를 복제하세요 ~~~

[오늘의 마지막 문제] 하둡 설치 성공후의 jps 명령어를 수행한 결과를 화면 캡쳐해서
                            올려주세요 ~~


복제하기 전에 서버를 한번 reboot 하고 다시 oracle 로 접속해서 

하둡을 시작 ! 
$start-all.sh

하둡이 정상인지 확인 !
$jps

      <----  6개가 잘 떠있으면 아주 잘 설치한것 입니다.      45분까지 쉬세요 ~~

14시 30분 ~ 15시 15분

14시 30분에 신호를 보낼건데 제가 잊어버리지 않도록 놓치면 알려주세요 ~

출결신호 보냈습니다. 

■ 하둡과 스파크 복습

1. 리눅스 설치
2. 리눅스 기본 명령어
3. vi 편집기
4. 쉘 스크립트 작성법
5. 마리아 디비 설치
6. 아나콘다와 마리아 디비 연동
7. 마리아 디비의 데이터 시각화 
8. 하둡이란 ?    빅데이터를 빠르게 검색하고 분석하기 위하여 여러대의 서버를 하나로 묶어서
                     여러대의 컴퓨터의 자원을 다 이용하는 자바로 만들어진 분산 파일 시스템 소프트웨어

                 하둡의 핵심 엔진 2가지 ?  1. 하둡 파일 시스템(HDFS)
                                                     2. 멥리듀서 (MapReducer)

9. 하둡설치
10. 하둡 파일 시스템 명령어  

▩ 현재 하둡 시스템이 정상인지 확인하는 방법

 oracle 유져로 putty 로 접속하셔서  

(base) [oracle@centos ~]$ jps 

4572 NameNode
4882 SecondaryNameNode
4726 DataNode
5482 Jps
5122 TaskTracker
4972 JobTracker

위와 같이 6개가 안떠있다면 ?  하둡을 시작시킵니다.

(base) [oracle@centos ~]$ start-all.sh    <--- 하둡 시작시키는 명령어 

(base) [oracle@centos ~]$ jps  

 6개가 다 안뜨고 5개만 떠있다라고 한다면  ? 하둡을 내렸다가 다시 올립니다.

(base) [oracle@centos ~]$ stop-all.sh

(base) [oracle@centos ~]$ start-all.sh

(base) [oracle@centos ~]$ jps

▩ 하둡 분산 파일 시스템 명령어 

■ 1. ls 명령어

  " 지정된 디렉토리에 있는 파일의 정보를 출력하는 명령어"

먼저 하둡 분산 파일 시스템에 emp.csv 를 올려야하는데 지금 하둡 시스템이 safe mode 여서
안올라가므로 safe 모드를 꺼야합니다.

(base) [oracle@centos ~]$ hadoop  dfsadmin  -safemode  leave 

하둡 분산 파일 시스템에 올릴 emp.csv 가 있는지 확인하시오 !

(base) [oracle@centos ~]$ ls -l  emp.csv 

하둡 분산 파일 시스템에 emp.csv 를 emp2.csv 라는 이름으로 올리시오 !

(base) [oracle@centos ~]$ hadoop  fs -put  emp.csv   /user/oracle/emp2.csv 

(base) [oracle@centos ~]$ cd /user/oracle
-bash: cd: /user/oracle: 그런 파일이나 디렉터리가 없습니다

/user/oracle 이라는 디렉토리는 현 리눅스에는 없는 디렉토리 입니다. 어디에 있냐면
꿈속(하둡 분산 파일 시스템)에 있습니다. 

하둡 분산 파일 시스템에 emp2.csv 가 잘 있는지 확인해 봅니다.

(base) [oracle@centos ~]$ hadoop  fs  -ls  /user/oracle/emp2.csv 

예제1.  리눅스 시스템에 있는 dept.csv 를  하둡 분산 파일 시스템에 dept2.csv 라는 이름으로 
           올리시오 !

(base) [oracle@centos ~]$ hadoop  fs  -put  dept.csv  /user/oracle/dept2.csv 

(base) [oracle@centos ~]$ hadoop  fs  -ls  /user/oracle/dept2.csv

▩ 2. 꿈속(하둡 분산 파일 시스템)의 구조를 웹브라우져로 편하게 보는 방법 

리눅스 시스템에 oracle 유져로 접속해서 firefox 를 켭니다.

http://localhost:50070

▩ 3. lsr 명령어 

 " 현재 디렉토리 뿐만 아니라 하위 디렉토리까지 조회하는 명령어 "

예제: 

(base) [oracle@centos ~]$ hadoop  fs  -lsr  /

예제1.  /user 밑에 있는 파일뿐만 아니라 하위 디렉토리들까지 조회하시오 !

(base) [oracle@centos ~]$ hadoop  fs  -lsr  /user

▩ 4. du 명령어

 " 파일의 용량을 확인하는 명령어 "

예제: (base) [oracle@centos ~]$ hadoop  fs  -du

102         hdfs://localhost:9000/user/oracle/dept2.csv
655         hdfs://localhost:9000/user/oracle/emp2.csv

▩ 5. cat 명령어

 "지정된 파일의 내용을 화면에 출력하는 명령어"

예제:   (base) [oracle@centos ~]$ hadoop fs  -cat  emp2.csv 

▩ 6. text 명령어

 "지정된 파일의 내용을 화면에 출력하는 명령어 "

예제: (base) [oracle@centos ~]$ hadoop  fs  -text  emp2.csv

예제1. 하둡 파일 시스템에 있는 dept2.csv 의 내용을 확인하시오 !

(base) [oracle@centos ~]$ hadoop  fs  -text  dept2.csv

▩ 7. dus 명령어

 " 파일의 전체 합계 용량을 확인 "

예제: (base) [oracle@centos ~]$  hadoop  fs  -dus

hdfs://localhost:9000/user/oracle       757

하둡 파일 시스템에 /user/oracle 밑에 있는 파일들의 총 크기의 합이 757 바이트 입니다.

▩ 8. put 명령어 
 
  "파일을 하둡 파일 시스템에 올리는 명령어"

예제: 
(base) [oracle@centos ~]$ hadoop  fs  -put  emp.csv  /user/oracle/test/emp3.csv 

(base) [oracle@centos ~]$ hadoop  fs  -lsr  /user/oracle

test 디렉토리가 자동으로 생성되어졌습니다. 

예제1. dept.csv 를 하둡 파일 시스템에 /user/oracle/test2/dept3.csv 로 올리시오 ! 

(base) [oracle@centos ~]$ hadoop  fs  -put  dept.csv  /user/oracle/test2/dept3.csv

▩ 9. get 명령어 

 " 하둡 파일 시스템에 올린 파일을 리눅스 디렉토리로 내리는 명령어 "

예제:

(base) [oracle@centos ~]$ rm  emp.csv

(base) [oracle@centos ~]$ ls  emp.csv

(base) [oracle@centos ~]$ hadoop  fs  -get  /user/oracle/test/emp3.csv   /home/oracle/emp.csv

▩ 10.  mv 명령어 
  
  "파일을 이동하는 명령어 "

(base) [oracle@centos ~]$ hadoop  fs  -mv  /user/oracle/dept2.csv   /user/oracle/test/dept2.csv 

예제1. 그럼 다시 /user/oracle/test 밑에 있는 dept2.csv 를 /user/oracle 밑으로 이동시키시오 

(base) [oracle@centos ~]$ hadoop fs -mv /user/oracle/test/dept2.csv  /user/oracle/dept2.csv

▩ 11.  rm 명령어 

 "파일을 삭제하는 명령어 "

예제: (base) [oracle@centos ~]$ hadoop  fs  -rm  /user/oracle/emp2.csv 

        (base) [oracle@centos ~]$ hadoop  fs  -lsr  /user/oracle

예제1.  하둡 파일시스템의  /user/oracle/dept2.csv 를 지우시오 !

(base) [oracle@centos ~]$ hadoop  fs -rm  /user/oracle/dept2.csv

▩ 12.  rmr 명령어 

 " 디렉토리를 삭제하는 명령어 "

예제: (base) [oracle@centos ~]$ hadoop fs -rmr  /user/oracle/test 

예제1. /user/oracle/test2 디렉토리를 지우세요 ~

(base) [oracle@centos ~]$ hadoop fs -rmr  /user/oracle/test2

▩ 13.  grep 명령어 

 " 파일에서 특정 문자의 행의 데이터를 검색하는 명령어"

예제: (base) [oracle@centos ~]$ ls  emp.csv
       (base) [oracle@centos ~]$ hadoop  fs  -put  emp.csv  /user/oracle/emp.csv
       (base) [oracle@centos ~]$ hadoop fs -cat  emp.csv  |  grep  -i  'scott' 

예제1. 하둡 파일 시스템의 emp.csv 에서 salesman 을 포함하는 행들을 모두 몇개인지 출력하시오

 hadoop fs -cat emp.csv | grep -i 'salesman' | wc -l

▩ 14. awk 명령어 

 "특정 컬럼의 데이터를 검색하는 명령어 "

예제:
$ hadoop  fs -cat  emp.csv | awk -F ","  '{print $2,$6}' 

예제1.  이름이 SCOTT 인 사원의 이름과 월급을 출력하시오!

태진아 ~

$ hadoop fs -cat emp.csv | awk -F ',' '$2=="SCOTT" {print $2,$6}'

▩ 15. count 명령어 

 " 지정된 디렉토리의 파일의 갯수를 확인하는 명령어"

예제: $ hadoop  fs  -lsr  /user/oracle
       $ hadoop  fs  -count  /user/oracle 

▩ 16. 하둡 파일 시스템의 명령어 메뉴얼 보는 방법 

 $ hadoop  fs  -help 

■ hive 설치 

점심시간 문제:  hive 에서 직업이 SALESMAN 인 사원들의 이름과 월급과 직업을 출력하시오 !

예제1.  hive 에서 직업과 직업별 토탈월급을 출력하시오

hive> select job, sum(sal) from emp group by job;

ANALYST 6000
CLERK   4150
MANAGER 8275
PRESIDENT       5000
SALESMAN        5600

예제2. hive 에서 직업과 직업별 토탈월급을 출력하는데 토탈월급이 높은것부터 출력하시오!

select job, sum(sal)  as sumsal
from emp
group by job
order by sumsal desc;

MANAGER           8275
ANALYST           6000
SALESMAN        5600
PRESIDENT       5000
CLERK             4150

설명:  hive 는 order by 절에 숫자를 쓰게 되면 정렬되지 않습니다.
        hive 는 group 함수를 정렬할때 컬럼별칭을 사용해야 합니다.

예제3. 부서번호, 부서번호별 평균월급을 출력하는데 평균월급을 출력할 때 소수점이하는
         출력되지 않게 반올림을 해서 출력하고 부서번호별 평균월급이 높은것부터
         출력되게하시오 !

select deptno, round(avg(sal)) as avgsal
  from emp
  group by deptno
  order by avgsal desc;

10      2917.0
20      2175.0
30      1567.0

select deptno, round(avg(sal)) as avgsal
  from emp
  group by deptno
  order by avgsal desc;

▦ 오라클  vs  하이브 

       오라클                             vs              하이브 

 to_char(hiredate,'RRRR')                         year( to_date(hiredate) ) 
 to_char(hiredate,'MM')                          month( to_date(hiredate) )
 to_char(hiredate,'DD')                           day( to_date(hiredate)  ) 

예제4.  이름, 입사한 년도(4자리) 를 출력하시오 !  

select ename, year(to_date(hiredate)) 
  from emp;

예제5.  입사한 년도(4자리), 입사한 년도별 토탈월급을 출력하시오 ! 

select year(to_date(hiredate)) as hyear, sum(sal) as sumsal
 from emp
 group by year(to_date(hiredate)) ;

■ 회사의 데이터베이스 운영 서버 크게 2가지 

  OLTP 성 업무용 DB                                   DW 용 DB   
   ↓                                                         ↓
online transaction processing               DataWare house 

 지금 현재 발생하는 주문정보                테라급으로 과거 데이터가 존재  
 고객 데이터                                                ↓
                                                       1. 데이터 분석함수
                                                       2. with 절
                                                       3. rollup, cube, grouping sets 
                                                               ↓
                                                     데이터 분석가, 데이터 엔지니어

■ Hive 에서 데이터 분석함수 사용 
                                                      
 1. rank
 2. dense_rank
 3. ntile
 4. listagg                     ------------>  group_concat (hive)
 5. 누적 데이터 출력
 6. lag, lead 

마리아 디비는 from 절의 서브쿼리가 안되는데 hive 는 가능합니다. 

예제6. 이름, 월급, 월급에 대한 순위를 출력하는데 순위는 월급이 높은 순서데로 
         순위를 부여하시오 !

hive> select ename,sal,rank() over(order by sal desc)
          from emp;


hive> select ename, sal, dense_rank() over(order by sal desc)
          from emp;

예제7. 이름, 월급, ntile 함수를 이용해서 월급의 등급을 4등급으로 나눠서 출력하시오

 0~25% :  1
 25~50% : 2
 50~75% : 3
 75~100% : 4 

select ename, sal, ntile(4) over(order by sal desc) 
  from emp;

예제8. 부서번호, 부서번호별로 속한 사원들의 이름을 가로로 출력하시오 

select  deptno, concat_ws(',' , collect_set(ename))
  from  emp
  group  by deptno; 

예제9. 입사한 년도(4자리), 입사한 년도별로 속한 사원들의 이름을 가로로 출력하시오!

select year(to_date(hiredate)), concat_ws(',', collect_set(ename))
  from emp
  group by year(to_date(hiredate));

1980    SMITH
1981    TURNER,CLARK,BLAKE,JAMES,WARD,JONES,MARTIN,ALLEN,FORD,KING
1982    MILLER,SCOTT
1983    ADAMS

예제10. 월급의 순위가 1등인 사원의  이름과 월급과 순위를 출력하시오 !
          (from  절의 서브쿼리가 hive 는 가능합니다.)

신호 보냈습니다.   45분까지 쉬세요 ~~

 명규는 답을 채팅창에 올려주세요 ~~

select ename, sal, rank() over (order by sal desc)
from emp
limit 1;

select *
 from ( 
             select ename, sal, rank() over (order by sal desc)  as  rnk
                  from emp
         )  tab
 where rnk = 1;

※ 설명:  hive 에서 from 절의 서브쿼리문을 사용할 때는 반드시 테이블 별칭을 사용해야
           합니다.

예제11.  부서번호, 부서번호별 토탈월급을 출력하는데 맨 아래쪽에 전체 토탈월급이
           출력되게하시오 

select deptno, sum(sal)  as  sumsal
  from emp
  group by deptno with rollup
  order by  sumsal  asc;

10      8750
30      9400
20      10875
NULL    29025

-- 부서번호를 10,20,30번 순으로 정렬하고 싶다면 ?

select deptno, sum(sal)
from emp
group by deptno with rollup
order by isnull(deptno);

참고로 30, 20, 10, null 순으로 출력하려면 
order by isnull(deptno), deptno desc 이런식으로 쓰면 돼요! - 황세현 제공

예제12. 위의 결과를 grouping sets 로 출력하시오 !

Oracle> select  deptno, sum(sal)
             from  emp
             group by  grouping  sets( (deptno), () );


hive> select deptno, sum(sal)  as  sumsal
           from  emp
           group  by   deptno  grouping  sets( (deptno), () )
           order  by  sumsal  asc;

예제13.  부서번호, 부서번호별 토탈월급을 가로로 출력하시오 !

Oracle> select  sum( decode( deptno, 10, sal ) )  "10",
                    sum( decode( deptno, 20, sal ) )  "20",
                    sum( decode( deptno, 30, sal ) )  "30"
              from  emp;

hive> set hive.cli.print.header=ture;

hive> select  sum( case  when  deptno=10  then  sal  end )  dept10,
                  sum( case  when  deptno=20  then  sal  end )  dept20,
                  sum( case  when  deptno=30  then  sal  end )  dept30
          from  emp;
                 
hive> exit;

▩ 영화 평점에 대한 큰 데이터를 내려받아 hive 에서 분석하기 

1. 먼저 대용량 텍스트 파일의 압축파일을 다운로드 받습니다.

$ cd
$ wget  http://www.grouplens.org/system/files/ml-1m.zip

2. 위의 압축파일의 압축을 해제합니다.

$ ls -l ml-1m.zip
$ unzip ml-1m.zip
$ cd  ml-1m/ 

3. movies.dat 파일의 위의 10줄만 열어서 보시오(head명령어)

 head -10 movies.dat

4. movies.dat 파일의 총 라인수가 어떻게 되는지 확인하시오 !

 wc -l movies.dat

5. ratings.dat 파일의 총 라인수가 어떻데 되는지 확인하시오 !

(base) [oracle@centos ml-1m]$ head -10 ratings.dat
1::1193::5::978300760

유져id :: 영화id :: 평점 :: 날짜와시간

(base) [oracle@centos ml-1m]$ head -10 movies.dat
1::Toy Story (1995)::Animation|Children's|Comedy

영화id :: 영화명 :: 장르 

6. (데이터 전처리) movies.dat 파일의  구분자 :: 을  , 로 변경하시오 !

$ sed  s/::/,/g  movies.dat  >>  movies_coma.csv 

7. (데이터 전처리) ratings.dat 도 위와 같이 전처리해서 ratings_coma.csv 로 생성하시오!

$ sed  s/::/,/g  ratings.dat >>  ratings_coma.csv 

8. (데이터 전처리) users.dat 도 위와 같이 전처리해서 users_coma.csv 로 생성하시오!

$ sed  s/::/,/g  users.dat >>  users_coma.csv 

9. 지금 생성한 3개의 파일을 전부 하둡 파일 시스템에 올리시오 

$ hadoop  fs  -put  movies_coma.csv  /user/oracle/movies_coma.csv
$ hadoop  fs  -put  ratings_coma.csv  /user/oracle/ratings_coma.csv
$ hadoop  fs  -put  users_coma.csv   /user/oracle/users_coma.csv
$ hadoop  fs  -lsr  /user/oracle

10. 위의 3개의 파일들을 저장할 테이블을 각각 만드시오 !

hive> create table users
         ( userid  int,        
          gender  string,  
          age     int,
          occupation   int,
          zipcode     string )
 ROW FORMAT DELIMITED    
 FIELDS TERMINATED BY ','  
 LINES TERMINATED BY '\n'    
 STORED AS TEXTFILE ;         

hive> create table movies
         ( movieid   int,        
          title  string,  
          genres    string )
 ROW FORMAT DELIMITED    
 FIELDS TERMINATED BY ','  
 LINES TERMINATED BY '\n'    
 STORED AS TEXTFILE ;         

hive> create table ratings 
         ( userid  int,        
          movieid  int,  
          rating   int,
          tstamp   string )
 ROW FORMAT DELIMITED    
 FIELDS TERMINATED BY ','  
 LINES TERMINATED BY '\n'    
 STORED AS TEXTFILE ;      

11. 하둡파일 시스템에 올린 csv 파일 3개를 위의 테이블에 각각 입력하시오

hive> load  data inpath  '/user/oracle/movies_coma.csv'  
         overwrite  into  table  movies;

hive> load  data inpath  '/user/oracle/users_coma.csv'  
         overwrite  into  table  users;

hive> load  data  inpath  '/user/oracle/ratings_coma.csv'  
         overwrite  into  table  ratings;

hive> select count(*) from  movies;

12. movies 데이터의 위의 5건만 출력하시오

select * from  movies  limit  5;

13. ratings 테이블에서 평점, 평점별 건수를 출력하시오 !

hive> describe ratings;
OK
userid                  int                     None
movieid                 int                     None
rating                  int                     None
tstamp                  string                  None
Time taken: 0.045 seconds, Fetched: 4 row(s)

select rating, count(*)
 from ratings
 group by rating;

14.  평점 5점의 영화명들을 출력하는데 중복을 제거해서 출력하시오 !
     (movies 와 ratings 테이블을 조인해야하고 조인조건으로 사용할 컬럼은 movieid)

hive> select distinct m.title    
          from  movies   m  join ratings r 
          on (m.movieid=r.movieid)
          where r.rating=5;

15.  5점 평점을 가장 많이 받은 영화명이 무엇인지 출력하시오 !

select   m.title, count(*)  as  cnt
          from  movies   m  join ratings r 
          on (m.movieid=r.movieid)
          where r.rating=5
         group by m.title
         order  by cnt  desc
         limit  5; 
         
■ LG 데이터 분석가로  지원할 때 가산점을 받을 수 있는 데이터를 다운로드 받으세요~

1. 하이브에서 테이블 작성

create table train_err_data
(user_id int,
time string,
model_nm string,
fwver string,
errtype string,
errcode string)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
tblproperties("skip.header.line.count"="1");

create table train_err_data
(user_id int,
time string,
model_nm string,
fwver string,
errtype string,
errcode string)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
STORED AS TEXTFILE;

2. 하둡 파일 시스템에 위의 데이터를 올립니다. 

$ hadoop fs  -put  /home/oracle/train_err_data.csv   /user/oracle/train_err_data.csv

3. 하이브에서 위의 데이터를 train_err_data 테이블에 입력합니다.

load data inpath '/user/oracle/train_err_data.csv' overwrite into table train_err_data;

4. select count(*) from  train_err_data; 

16554664

[오늘의 마지막 문제] LG 제품중에서 어느 모델이 가장 서비스 요청이 많이 들어왔는지
                          1위 ~ 5위까지 모델명과 순위를 출력하시오 !

 마지막 문제 올리고 나머지 시간은 자유롭게 포트폴리오 또는 자습하세요 ~~~

train_err_data.csv 파일에서 첫번째행 지우고 train_err_data2.csv 생성하는 방법 

(base) [oracle@centos ~]$ sed '1d' train_err_data.csv >> train_err_data2.csv
(base) [oracle@centos ~]$
(base) [oracle@centos ~]$ wc -l train_err_data.csv
16554664 train_err_data.csv
(base) [oracle@centos ~]$
(base) [oracle@centos ~]$ wc -l train_err_data2.csv
16554663 train_err_data2.csv


컬럼설명: 
user_id : 유저번호. 10000번부터 24999번까지 나열된 것을 볼 때,  총 15000명. 특정 번호를 부여한 것이 아니라 접수된 순서대로 인 것 같습니다. 1655만개 데이터로 인당 평균 약, 1100개의 에러 수준을 가집니다.
time : 에러가 발생한 시각(연월일24시분초)
model_nm : 모델명. 0번부터 8번까지 총 9가지 모델이 존재합니다.
    select distinct model_nm from train_err_data; 로 확인했습니다.
fwver : 펌웨어 버전으로 추정. 동일 유저인데 fwver번호가 바뀐 이후 나타나던 에러가 사라지는 것을 발견했습니다.
errtype : 에러타입. 29를 제외하고 1부터 42까지 존재 각 번호가 어떤 에러를 의미하는지 알 수 없습니다.
    select distinct errtype from train_err_data order by cast(errtype as unsigned)
errcode : 세부에러. 2805종류입니다. 숫자와 영문을 혼용하고 있습니다. 0, 1, 2 등의 숫자와, 'connection timeout'. 'NFANDROID2', standby 등이 혼재되어 있습니다. NFANDROID의 경우 검색해본 결과 셋톱박스와 관련이 있는 것으로 보여집니다.

 
■ 하둡과 스파크 수업 복습 

1. 리눅스 설치
2. 리눅스 기본 명령어
3. 마리아 디비 설치 , 마리아 디비에 SQL 검색
4. 아나콘다와 마리아 디비를 연동해서 시각화
5. 하둡설치, 하둡 클러스터 파일 시스템 명령어
6. 하이브 
7. 스파크 

■ 스파크 수업

 하둡 맵리듀스 ?

   매핑(mapping) 함수 ?   검색해야할 데이터를 여러서버에 분배해주는 역활
   리듀싱(reducing) 함수 ? 각 서버(컴퓨터)에서 처리한 데이터를 취합하는 역활 

  hive> select  ename, sal
             from  emp       # 5억건 
             where  job='SALESMAN';   # 5천건

▩ jps 명령어를 수행했을 나오는 프로세서들의 역활 ? 

2912 SecondaryNameNode :  하둡 네임노드의 보조노드에 대한 프로세서로서
                                        네임노드의 메타정보(위치정보)를 주기적으로 보조네임노드로
                                        주기적으로 백업하는 역활 
3022 JobTracker  :  하둡 클러스터에 등록된 전체 job 의 스케즐링을 관리하고 모니터링하는
                          프로세서  

3174 TaskTracker : 사용자가 설정한 멥리듀스 프로그램을 실행하는 역활을 하며 하둡 데이터
                         노드에서 실행되는 프로세서 

2753 DataNode   :  데이터를 저장하는 노드              
3247 Jps            :   JPS 명령어를 수행한 프로세서                  
2600 NameNode  :  데이터의 위치정보를 가지고 있는 노드               

하둡의 핵심엔진 2가지 ?  1.  하둡 파일 시스템(HDFS)
                                  2.  멥리듀싱 

하둡의 장점 ?  1. 무료이다.
                    2. 분산 컴퓨팅 처리가 가능해서 대용량 데이터를 검색하는데 적합하다.

하둡의 단점 ?  무거운 중장비이다 보니까 속도가 느리다. 

그래서 나온게 스파크 입니다.   스파크는 하둡보다 속도가 빠릅니다. 
빠른이유는 하둡은 디스크에서 데이터를 처리하는 반면 스파크는 메모리에서 데이터를 처리
합니다.

1. 스파크만 단독으로만도 사용가능하다.
2. 하둡의 파일시스템의 데이터를 스파크로 불러와서 스칼라 쿼리로 검색도 가능합니다.


▩ 스파크 설치 

 카페의 게시판에 나온 내용데로 설치를 진행


▩ 스칼라 종료하는 방법

 ctl +D  를 누르거나  :quit  를 하면 됩니다. 

▩ 스파크를 내렸다 올리는 명령어 

1. 스파크의 sbin 디렉토리로 이동합니다.

$ cd  /home/oracle/spark/sbin
$ ls 

  start-all.sh 와 stop-all.sh 가 있는지 확인해야 합니다. 

설명:  위의 start-all.sh 와 stop-all.sh 는 하둡의 start-all.sh 와 stop-all.sh 와는 별개의
        파일입니다. 

2.  하둡의 stop-all.sh 가 아니라 스파크의 stop-all.sh 를 수행하려면 위와 같이
     /home/oracle/spark/sbin 디렉토리 이동해서 다음의 명령어를 수행합니다.

$ ./stop-all.sh

3. 스파크의 start-all.sh 를 수행한다. 

$ ./start-all.sh

4. 스파크로 접속하시오 

$ spark-shell 

문제.  위의 스파크를 내리는 명령어를 쉽게 수행할수 있도록 자동화 스크립트에 추가하시오!

$ vi a2.sh

echo "1. 스파크 내리기 
2. 스파크 올리기
3. 스파크에 접속하기
4. 하이브에 접속하기"

echo  -n  "번호를 입력하세요"
read choice
case  $choice  in
      1)
         cd /home/oracle/spark/sbin
         ./stop-all.sh  ;;
      2) 
         cd /home/oracle/spark/sbin
         ./start-all.sh  ;;
      3)
        spark-shell  ;;
      4)
        hive          ;;
esac

▩ 스파크에 데이터 검색하기 

예제0. 테이블 drop 하는 명령어 

scalar> sql("drop  table  emp")

예제1.  hive SQL 을 스파크에서 사용하겠다고 지정합니다. 

scala> val sqlContext = new org.apache.spark.sql.hive.HiveContext(sc)

예제2. emp 테이블을 생성합니다.

scala> sqlContext.sql("create  table  IF  NOT EXISTS  emp( empno int, ename  string, 
         job  string, mgr  int, hiredate string, sal  int,  comm  int,  deptno  int ) 
         row format  delimited  fields  terminated  by  ','  
         lines  terminated  by  '\n' ")

똑같이 작성했는데도 계속 테이블 생성할때 에러가 나면 스파크를 다시 내렸다 올리세요~

예제3. emp 테이블의 /home/oracle/emp.csv 를 입력하시오

scala>sqlContext.sql("LOAD DATA LOCAL INPATH '/home/oracle/emp.txt' INTO TABLE emp") 

민석이가 올린 emp2.txt 로 진행하세요 ~~

안되면 drop 하고 하세요 ~~

scalar> sql("drop  table  emp")

예제4.  사원 테이블의 건수를 확인하시오 !

scalar> sql("select * from  emp").count()

예제5.  부서번호가 30번인 사원들의 이름과 월급과 부서번호를 출력하시오 

scalar> sql("""select ename, sal, deptno 
                    from  emp
                    where  deptno=30""").show()

예제6. 직업이 SALESMAN 인 사원들의 이름과 월급과 직업을 출력하시오 !

scala> sql("""select  ename, sal, job
                    from  emp
                    where  job='SALESMAN'""").show()

예제7. 직업, 직업별 토탈월급을 출력하는데 토탈월급이 높은것부터 
         출력하시오 !

scala> sql("""select job,sum(sal)
                  from emp
                  group by job
                  order by sum(sal)desc""").show()

예제8. 위의 결과를 다시 출력하는데 having 절을 사용해서 직업별 토탈월급이
         5000 이상인것만 출력하시오 !

sql("""select job, sum(sal) ss
          from emp
          group by job
          having ss >= 5000
          order by ss desc""").show()

예제9. 이름, 월급, 월급에 대한 순위를 출력하시오 ! (순위는 월급이 높은순서데로
         순위를 부여하시오!)

sql("""select ename, sal, rank() over(order by sal desc)  as rnk
           from emp""").show()

예제10. (스칼라의 SQL 장점) 직업, 직업별 토탈월급을 출력하는데
           결과로 숫자로 나오는 값들에 대한 통계값을 출력하시오 !

scalar> sql("""select  job, sum(sal)
                    from  emp
                    group  by job""").describe().show()

예제11. (스칼라 SQL 의 장점)  사원 테이블을 출력하는데 위의 3줄만 출력하시오

scalar> sql("""select * from  emp""").head(3)

예제12. dept 테이블을 생성하기 위해서 dept.csv 를 dept.txt 로 카피하시오


예제13. dept 테이블을 생성하시오 !

scalar> sql("drop table dept")

scalar> sql( "CREATE TABLE IF NOT EXISTS dept(deptno int, dname string, loc string) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n'")

scalar> sql("LOAD DATA LOCAL INPATH '/home/oracle/dept.txt' INTO TABLE dept")

scalar> sql("""select * from dept""").show()

예제14. (스파크에서도 조인이 가능한지 확인)  이름, 부서위치를 출력하세요 !
          ( 1999 ansi 조인 문법의 on 절을 사용한 조인문법으로 수행하세요)

scalar> sql(""" select  e.ename, d.loc
                      from  emp  e  join  dept  d
                      on ( e.deptno = d.deptno) """).show()

예제15. (스파크에서 서브쿼리도 가능한지 확인) ALLEN 보다 늦게 입사한 사원들의
           이름과 입사일을 출력하시오 !

scala> sql(""" select ename, hiredate
                      from emp
                      where hiredate > ( select hiredate
                                                  from emp 
                                                  where ename = "ALLEN")""").show()

하둡의 하이브와 스파크에서 결론적으로 뭘 생성해줘야하는가 ?

 빅 데이터에서 원하는 데이터만 검색해서 그 결과를 CSV 로 저장하는 역활을 해줘야합니다.

예제16.  직업과 직업별 토탈월급의 결과를 csv 파일로 저장하시오 !

scalar> sql(""" select job, sum(sal)
                        from  emp
group by  job""").coalesce(1).write.option("header","true").option("sep",",").mode("overwrite").csv("/home/oracle/ff")

coalesce(1) 는 하나의 파일에 모두 담아라 ~  숫자를 2로 쓰게되면 2개의 파일에 나눠서 담아라 ~
write.option("header","true").   # 컬럼명 나오게 해라 ~
option("sep",",").                   # csv 파일 형태로 저장해라 ~ 
mode("overwrite").csv("/home/oracle/dd")  # /home/oracle/dd 라는 폴더를 만들어서 폴더안에 생성해라 ~

▩ 하이브의 파티션 테이블 생성 

     일반 테이블                                               vs    파티션 테이블 
         ↓                                                                     ↓
  하나의 서랍장에 모든 데이터를 다 넣어놓은 테이블     봄,여름,가을,겨울옷을 
                                                                         각각 다른 서랍장에 보관하고 있는
                                                                         테이블 

  파티션 테이블은 전체 테이블을 전부 스캔하지 않고 특정 파티션만 스캔한다.

  select *
     from  옷장
     where  옷='파란 반팔 티셔츠';

예제1. 항공 데이터 1997.csv 를 리눅스 서버에 /home/oracle 밑에 올리세요 ~

  모바텀을 oracle 로 접속해서 올립니다

 미국의 모든 항공사의 1997년 항공 데이터 입니다. 

예제2. 항공 데이터를 저장할 테이블을 하이브에서 생성하시오 !

CREATE TABLE airline_delay(
Year    INT, 
Month    INT, 
DayofMonth    INT, 
DayOfWeek    INT, 
DepTime    INT, 
CRSDepTime    INT, 
ArrTime    INT, 
CRSArrTime    INT, 
UniqueCarrier    STRING, 
FlightNum    INT, 
TailNum    STRING, 
ActualElapsedTime    INT, 
CRSElapsedTime    INT, 
AirTime    INT, 
ArrDelay    INT, 
DepDelay    INT, 
Origin    STRING, 
Dest    STRING, 
Distance    INT, 
TaxiIn    INT, 
TaxiOut    INT, 
Cancelled    INT, 
CancellationCode    STRING COMMENT 'A = carrier, B = weather, C = NAS, D=security' , 
Diverted    INT COMMENT '1 = yes, 0 = no', 
CarrierDelay    STRING, 
WeatherDelay    STRING, 
NASDelay    STRING, 
SecurityDelay    STRING, 
LateAircraftDelay STRING
)
Partitioned by (DelayYear INT)       ---> 파티션 테이블로 구성
ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ','
    LINES TERMINATED BY '\n'
    STORED AS TEXTFILE; 

예제3.  /home/oracle 밑에 있는 1997.csv 를 하둡 파일 시스템에 올리시오 !

$ hadoop  fs  -put  1997.csv  /user/oracle/1997.csv 
$ hadoop fs -lsr  /user/oracle

예제4. 1997.csv  데이터를  airline_delay 테이블 에 입력하시오 !

hive> load  data  inpath  '/user/oracle/1997.csv'
         overwrite  into table  airline_delay
         partition (delayYear='1997') ;

예제5. 다음 카페에서 1994.csv 도 내려받고 리눅스 서버에 올리고 하둡 파일 시스템에 올리고
          airline_delay 테이블에오후 3:13 2021-08-25 입력하시오 !

$ sed '1d' 1994.csv  >> 1994b.csv

$ hadoop fs  -put  1994b.csv   /user/oracle/1994b.csv 

hive> load  data  inpath  '/user/oracle/1994b.csv'
         overwrite  into table  airline_delay
         partition (delayYear='1994') ;

hive> select count(*) from  airline_delay;

10591893                           45분까지 쉬세요 ~~~

예제6.  연도(year), 연도별 건수를 확인하시오 !

 select  year, count(*)
   from  airline_delay
   group by year;

1994    5180048
1997    5411843

예제7. 1994년도의 월(month) , 월별 항공기 도착 지연건수를 출력하시오 !

select  month, count( ArrDelay)
  from  airline_delay
  where  ArrDelay > 0 and  delayYear =1994
  group  by month; 

설명: 1994년 파티션에서만 데이터를 읽어옵니다. 

예제8. 아래의 결과를 윈도우 주피터 노트북에서 라인 그래프로 시각화 하시오! 

1,226490
2,196747
3,204165
4,202271
5,190907
6,216381
7,232786
8,221215
9,186874
10,205037
11,215858
12,231216

import  pandas  as pd
import  matplotlib.pyplot  as  plt

air = pd.read_csv("d:\\data\\air.csv", header=None)
air.columns = ['month','delay_cnt']
plt.plot(air.month, air.delay_cnt)
plt.xlabel('month')
plt.ylabel('delay_cnt') 

예제9.  airline_delay 테이블을 하이브에서 describe 하시오 !


예제10.  1994년도 데이터중 년도(year), 출발지연(depdelay) 을 출력하는데
            위의 10건만 출력하시오 !

select  year,  depdelay
  from   airline_delay
  where  delayYear='1994'
  limit  10;

예제11. 1994년도의 월(month), 월별 출발지연건수를 출력하시오 !

select  month,  count(depdelay)
   from  airline_delay
   where   depdelay > 0  and  delayYear=1994
   group by  month;

예제12. 위의 결과를 파이썬에서 라인 그래프로 시각화 하시오 !
1,215791
2,184811
3,195139
4,181870
5,170538
6,201658
7,222409
8,207187
9,170182
10,190085
11,213819
12,240057

import  pandas  as pd
import  matplotlib.pyplot  as  plt

air = pd.read_csv("d:\\data\\air2.csv", header=None)
air.columns = ['month','delay_cnt']
plt.plot(air.month, air.delay_cnt, color='red')
plt.xlabel('month')
plt.ylabel('delay_cnt') 

설명:  월별로 데이터를 파티션 테이블에 저장하여 관리하게 되면 특정 파티션의 
        데이터만 검색할 수 있게 되므로 더 검색속도가 빨라지게 됩니다. 
        
예제13.  emp 테이블을 deptno 를 기준으로 파티션 테이블로 생성하시오 !

create table emp_partition          
(empno int,  
ename string,
job string,
mgr int,
hiredate string,
sal int,
comm int,
deptno int)
partitioned  by (deptno2  int) 
row format delimited 
fields terminated by ','   
lines terminated by '\n'   
stored as textfile ;

예제14. emp.csv 를 부서번호별 각각 분리해서 아래와 같이 3개의 csv 파일을 생성하시오 !

 10.csv  , 20.csv,   30.csv

awk -F ','  '$8==10 {print $0}'  emp.csv >> 10.csv
awk -F ','  '$8==20 {print $0}'  emp.csv >> 20.csv
awk -F ','  '$8==30 {print $0}'  emp.csv >> 30.csv

예제15.  10.csv 를 emp_partition  테이블에 입력하시오 !

load  data  local  inpath  '/home/oracle/10.csv'
overwrite  into  table  emp_partition
partition (deptno2='10'); 

예제16. 20.csv 를 emp_partition 테이블에 입력하시오 !

load  data  local  inpath  '/home/oracle/20.csv'
overwrite  into  table  emp_partition
partition (deptno2='20'); 

예제17. (오늘의 마지막 문제)  30.csv 를 emp_partition 에 입력하고 emp 테이블 전체를 
            select 한 결과를 캡쳐해서 올리세요 ~~



  리눅스  ---> 마리아 디비 ---> 아나콘다와 연동 ---> 하둡 ----> 스파크 -->    몽고디비

■ 몽고디비 

 NoSQL 언어로 하둡에 있는 빅데이터를 검색하고 분석하는 소프트웨어 
 hive 와 scalar 는 데이터가 update 가 안됩니다. 그러나 몽고디비는 update 가 됩니다.
 그래서 현업에서 몽고디비를 많이 사용합니다. 

 NoSQL ?  hive, pig, mongodb
 
▩ 몽고디비 설치 

1. 하둡 시스템을 올린다.

(base) [oracle@centos ~]$ start-all.sh

2. 하둡 시스템이 정상인지 확인합니다.

(base) [oracle@centos ~]$ jps 

3. 몽고디비를 설치 합니다.

 카페 하둡 목차를 활용합니다.

예제1. 부서번호가 10번인 사원들의 사원번호와 이름과 월급을 조회하시오 !

SQL> select  ename,sal                 mongo> db.emp.find( {deptno: {$eq:10}},
           from  emp                                   {_id:0, empno:1, ename:1, sal:1} )
           where  deptno = 10 ;

▩ 몽고디비에서 사용하는 연산자

 1.  비교연산자 : $eq        ==
                      $gt         >
                      $gte       >=
                      $lt          <
                      $lte         <=
                      $ne         !=
 2.  논리연산자 : $and
                      $not
                      $or
 3.  산술연산자   $add             +
                       $subtract       -
                       $multiply       *
                       $devide         /
                       $mod           %

예제2.  월급이 3000 이하인 사원들의 이름과 월급을 출력하시오 !

SQL>  select  ename, sal              mongo>  db.emp.find( 
            from  emp                                      { sal : {$lte : 3000}  },
            where  sal <= 3000;                          {_id:0, ename:1, sal:1}
                                                                           )

예제3. 직업이 SALESMAN 인 사원들의 이름과 직업을 출력하시오 !

SQL> select  ename, job               mongo>  db.emp.find(
            from  emp                                      { job : {$eq : "SALESMAN"} },
            where  job='SALESMAN';                    {_id:0, ename:1, job:1 }
                                                                            )

예제4. 직업이 SALESMAN 이 아닌 사원들의 이름과 직업을 출력하시오 !

SQL> select  ename, job               mongo>  db.emp.find( 
           from  emp                                       { job : {$ne : "SALESMAN"} },
           where  job !='SALESMAN';                   {_id:0, ename:1, job:1 }
                                                                            )

예제5. 이름과 월급을 출력하는데 월급이 높은 사원부터 출력하시오 !

SQL> select ename, sal               mongo>  db.emp.find( 
           from  emp                                               {},
           order  by  sal  desc ;                                  {_id:0, ename:1, sal:1} 
                                                                          ).sort({sal:-1})

※ 설명:  1 :  asc
           -1 : desc

예제6. 직업이 SALESMAN 인 사원들의 이름과 월급과 직업을 출력하는데 월급이 낮은 사원부터
         출력하시오 !

SQL> select  ename, sal, job              mongo> db.emp.find(
           from  emp                                            { job : {$eq : "SALESMAN" } },
           where job='SALESMAN'                           {_id:0, ename:1, sal:1 }
           order by sal  asc;                                              ).sort({sal:1})

예제7. 월급이 1000 에서 3000 사이인 사원들의 이름과 월급을 출력하시오 !

SQL> select  ename, sal                              mongo>   db.emp.find(
           from  emp                                                   { sal :{$gte:1000, $lte:3000} },
          where  sal >= 1000  and  sal <= 3000;               {_id:0, ename:1, sal:1}
                                                                                          )

예제8. 월급이 1000 에서 3000 사이가 아닌 사원들의 이름과 월급을 출력하시오 !

SQL> select  ename, sal                          
            from  emp                                               
            where sal < 1000   or   sal > 3000;                  
                                                                                          
mongo> db.emp.find(
                {$or : [ {sal : {$lt:1000} }, { sal : { $gt:3000 } } ] },
                {_id:0,ename:1,sal:1}
                  )

예제9. 예제7번을 예제8번처럼 수행하는데 $and 를 사용해서 수행하시오 !

mongo> db.emp.find(
                {$and : [ {sal : {$gte:1000} }, { sal : { $lte:3000 } } ] },
                {_id:0,ename:1,sal:1}
                  )

예제10. 위의 결과를 다시 출력하는데 월급이 높은 사원부터 출력하시오 !

mongo> db.emp.find(
                {$and : [ {sal : {$gte:1000} }, { sal : { $lte:3000 } } ] },
                {_id:0,ename:1,sal:1}
                  ).sort({sal:-1})

예제11.  직업이 SALESMAN, ANALYST 인 사원들의 이름과 월급과 직업을 
            출력하는데 월급이 높은 사원부터 출력하시오 !

SQL> select  ename, sal, job
            from emp
            where  job='SALESMAN'  or  job='ANALYST'
            order by  sal  desc; 

mongo> db.emp.find(
                {$or : [ {job : {$eq:"SALESMAN"} }, { job : { $eq:"ANALYST" } } ] },
                {_id:0,ename:1,sal:1, job:1}
                  ).sort({sal:-1})

mongo>  db.emp.find(
                 {job:{$in:['SALESMAN','ANALYST']}},
                    {_id:0, ename:1, sal:1, job:1}
                     ).sort({sal:-1})

예제12.  직업이 SALESMAN, ANALYST 가 아닌 사원들의 이름과 월급과 직업을 출력하는데
            월급이 높은 사원부터 출력하시오 !

mongo>  db.emp.find(
                 {job:{$nin:['SALESMAN','ANALYST']}},
                    {_id:0, ename:1, sal:1, job:1}
                     ).sort({sal:-1})

예제13. 부서번호를 출력하는데 중복을 제거해서 출력하시오 !

SQL> select  distinct  deptno
             from  emp;

mongo>  db.emp.distinct("deptno")

예제14. 직업을 출력하는 중복을 제거해서 출력하시오 !

SQL> select  distinct  job
             from  emp;

mongo>  db.emp.distinct("job")

예제15. 사원 테이블의 전체 건수를 출력하시오 !

SQL> select  count(*)
           from  emp;

mongo>  db.emp.count()

예제16. 직업이 SALESMAN 인 사원들의 인원수를 출력하시오 !

SQL> select count(*)
           from emp
          where  job='SALESMAN';

mongo>  db.emp.count( { job : {$eq: "SALESMAN"}} )
mongo>  db.emp.count( { job : "SALESMAN"} )

■ csv 파일을 mongodb 로 로드하는 방법 

예제1. dept.csv 를 mongodb 로 로드하는 방법

# ls -l /home/oracle/dept.csv

예제2. dept.csv 를 cat 으로 열어서 위에 컬럼명이 있는지 확인하시오 !

[root@centos ~]# cat /home/oracle/dept.csv
deptno,dname,loc
10,ACCOUNTING,NEW YORK
20,RESEARCH,DALLAS
30,SALES,CHICAGO
40,OPERATIONS,BOSTON

예제3. dept.csv 로 몽고디비에 dept 테이블을 생성하시오 !

[root@centos ~]# mongoimport  --type  csv  -c  dept --headerline --drop  /home/oracle/dept.csv

예제4. 몽고디비에 접속해서 dept 테이블 전체를 조회하시오 !

mongo> db.dept.find( 
                               {},
                               {_id:0 }
                             )

예제5. emp.csv 를 몽고디비에 넣기 위해서 emp.csv 를 열어서 \N 을 다 지우시오 !

[root@centos ~]# cp /home/oracle/emp.csv /root/
cp: overwrite `/root/emp.csv'? y
[root@centos ~]#
[root@centos ~]# vi emp.csv

:%s/\\N//g

예제6. /root/emp.csv 를 열어서 위에 컬럼명을 다 입력하고 저장하고 나오세요 !


예제7.  몽고디비로 접속해서 기존 emp 테이블을 drop 하시오

# mongo

>  db.emp.drop()

예제8.  다시 exit 로 os 로 나가서 emp.csv 로 emp 테이블을 생성하시오 !

# mongoimport  --type  csv  -c  emp  --headerline  --drop  /root/emp.csv

> db.emp.count()
14

예제9. 항공 데이터(1994.csv) 를 몽고디비에 테이블로 생성하시오 !

 mongoimport --type csv  -c air --headerline --drop /home/oracle/1994.csv


예제10. (점심시간 문제)  항공 테이블 air 가 전체 몇건인지 count 하고 결과를 캡쳐해서 검사받으세요


■ 하둡 파일 시스템에 올린 emp.csv 를  몽고디비로 임폴트하는 방법 

몽고디비는 root 에서 설치했고 하둡은 oracle 에서 설치를 했습니다.

하둡과 몽고디비를 같이 사용하려면 oracle 로 접속해서 몽고디비로 접속해야합니다.

[root@centos ~]# su - oracle

(base) [oracle@centos ~]$ mongo

예제1.  root 로 다시접속해서 /root/emp.csv 의 권한을 777 로 올리고   /home/oracle/emp700.csv 
          로 복사하시오 !

[root@centos ~]# chmod 777 emp.csv

[root@centos ~]# ls -l emp.csv
-rwxrwxrwx. 1 root root 679  8월 26 12:02 emp.csv

[root@centos ~]# cp /root/emp.csv /home/oracle/emp700.csv

예제2. oracle 유져로 접속해서 emp700.csv 를 하둡파일 시스템에 /user/oracle/emp700.csv 로 
         올리시오 ~

(base) [oracle@centos ~]$ hadoop  fs  -put emp700.csv  /user/oracle/emp700.csv
(base) [oracle@centos ~]$
(base) [oracle@centos ~]$ hadoop fs  -lsr  /user/oracle

예제3. 하둡 파일 시스템에 올린 /user/oracle/emp700.csv 를 mongodb 에 emp700 으로 
         생성하시오 !

$ hadoop  fs -text /user/oracle/emp700.csv |  mongoimport  --type  csv  -c  emp700 --headerline  --drop  

예제4.  지금 만든 emp700 이 몽고디비에 잘 생성되어졌는지 확인하시오 !

$ mongo

> db.getCollectionNames()
[ "air", "dept", "dept2", "emp", "emp2", "emp200", "emp3", "emp700" ]

예제5.  /home/oracle/dept.csv 를  열어서 컬럼명이 있는지 확인해보고  dept.csv 를 하둡 파일 시스템에
          /user/oracle/dept700.csv 로 올린후에 몽고디비의 테이블로 생성하시오 !

$ hadoop fs -put dept.csv /user/oracle/dept700.csv

$ hadoop  fs -text /user/oracle/dept700.csv |  mongoimport  --type  csv  -c  dept700 --headerline  --drop  

$mongo 

> db.getCollectionNames()

▩ 몽고디비에서 쿼리한 결과를 csv 파일로 내리기 

예제1.  월급이 3000 이하인 사원들의 이름과 월급을 조회하시오 (emp700 으로 조회하세요)

mongo>  db.emp700.find( 
                                     { sal : { $lte : 3000 } },
                                     { _id:0, ename:1, sal:1 }
                                   )

예제2.  위의 결과를 result700.csv 로 내리시오 !

> exit:

$ mongoexport  --db=test --collection=emp700  --type=csv  --query '{ sal : { $lte : 3000 } }'  
        --fields=ename,sal  --out=result700.csv

예제3.  부서번호가 20번인 사원들의 데이터를 dept20.csv 로 생성하시오 !

$ mongoexport  --db=test --collection=emp700  --type=csv  --query '{ deptno : { $eq : 20 } }'  
        --fields=empno,ename,sal,mgr,hiredate,comm,job,deptno  --out=dept20.csv

 빅데이터에서 데이터를 검색하려면 시간이 상당히 오래걸리므로 수백대의 컴퓨터를 묶어서
 하둡으로 구성한 하둡 파일 시스템을 활용해서 데이터를 검색하고 그 결과를 파이썬이나 R 에서
 시각화하고 분석하려고 이 작업을 했습니다.

▩ 몽고디비에서 group 함수 사용하기 

예제1.  사원 테이블의 토탈월급을 출력하시오 !

SQL> select  sum(sal)  from  emp; 

mongo>  db.emp.aggregate( [ { $group:
                            {_id:0, total:{$sum:'$sal'} } }
                                        ]
                                      )

예제2.  사원 테이블의 최소월급을 출력하시오 !

SQL> select  min(sal)  from  emp; 

mongo>  db.emp.aggregate( [ { $group:
                            {_id:0, minsal:{$min:'$sal'} } }
                                        ]
                                      )

예제3. 사원 테이블의 최대월급을 출력하시오 !

SQL> select  max(sal)  from  emp; 

mongo>  db.emp.aggregate( [ { $group:
                            {_id:0, maxsal:{$max:'$sal'} } }
                                        ]
                                      )

예제4. 직업이 SALESMAN 인 사원들의 최대월급을 출력하시오 !

SQL> select  max(sal) from  emp  where job='SALESMAN';

mongo>  db.emp.aggregate( [  
                             { $match: { job : 'SALESMAN'} },
                             { $group: {_id:0, maxsal:{$max:'$sal'} } }
                                        ]
                                      )

예제5. 부서번호가 30번인 사원들의 최소월급을 출력하시오 !

SQL> select  min(sal) from  emp  where deptno=30;

mongo>  db.emp.aggregate( [  
                             { $match: { deptno : 30} },
                             { $group: {_id:0, minsal:{$min:'$sal'} } }
                                        ]
                                      )

예제6. 부서번호, 부서번호별 토탈월급을 출력하시오 !

SQL> select deptno, sum(sal)
            from emp
            group  by deptno; 

mongo> db.emp.aggregate( [
                     { $group: {_id:'$deptno' , total:{$sum:'$sal'} } }
                                       ] )

예제7. 직업, 직업별 토탈월급을 출력하시오 !

SQL> select  job, sum(sal)
            from  emp
            group  by  job;

mongo>  db.emp700.aggregate( [
                     { $group: {_id:'$job' , total:{$sum:'$sal'} } }
                                       ] )

예제8.  위의 결과를 출력하는데 토탈월급이 높은것 부터 출력하시오 !

SQL> select  job, sum(sal)
            from  emp
            group  by  job
            order  by sum(sal) desc; 

mongo>  db.emp700.aggregate( [
                     { $group: {_id:'$job' , total:{$sum:'$sal'} } },
                     { $sort : {"total" : -1 } } 
                                       ] )

예제9. 부서번호, 부서번호별 평균월급을 출력하는데 평균월급이 낮은것부터 높은순으로 출력하시오

SQL> select  deptno, avg(sal)
         from  emp
         group  by  deptno
         order by  avg(sal) asc; 

mongo>  db.emp.aggregate( [
                     { $group: {_id:'$deptno' , mean:{$avg:'$sal'} } },
                     { $sort : {"mean" : 1 } } 
                                       ] )

예제10. 위의 결과를 다시 출력하는데 20번 부서번호는 제외하고 출력하시오 !

SQL> select  deptno, avg(sal)
         from  emp
         where  deptno != 20
         group  by  deptno
         order by  avg(sal) asc; 

mongo>  db.emp.aggregate( [
                     { $match: { deptno: {$ne : 20 } }  } ,
                     { $group: {_id:'$deptno' , mean:{$avg:'$sal'} } },
                     { $sort : {"mean" : 1 } } 
                                       ] )

예제11. 직업, 직업별 토탈월급을 출력하는데 직업이 SALESMAN 은 제외하고 출력하고
           직업별 토탈월급이 높은것부터 출력하시오 !

SQL> select   job, sum(sal)
            from  emp
            where  job !='SALESMAN'
            group  by  job
            order  by   sum(sal)  desc; 

mongo> db.emp700.aggregate([
                          { $match: { job: {$ne:'SALESMAN'} } },
                          { $group: { _id: "$job", totalsal: { $sum: "$sal" } } },
                          { $sort:{"totalsal":-1} }
                                          ])

예제12. 직업, 직업별 토탈월급을 출력하는데 직업이 SAELSMAN 은 제외하고 출력하고
          직업별 토탈월급이 6000 이상인것만 출력하고 직업별 토탈월급이 높은것부터 출력하시오!

SQL> select   job, sum(sal)
            from  emp
            where  job !='SALESMAN'
            group  by  job
            having  sum(sal) >= 6000
            order  by   sum(sal)  desc; 

mongo> db.emp.aggregate([
                          { $match: { job: {$ne:'SALESMAN'} } },
                          { $group: { _id: "$job", totalsal: { $sum: "$sal" } } },
                          { $match: { totalsal : { $gte : 6000 }  }  }, 
                          { $sort:{"totalsal":-1} }
                                          ])

예제13.  직업, 직업별 인원수를 출력하시오 !

SQL> select  job, count(*)
            from  emp
            group  by  job; 

mongo> db.emp.aggregate([
                      { $group: { _id: "$job", count: { $sum: 1 } } }
                                           ])

예제14.  아래의 쿼리문을 몽고디비로 작성하시오 ! 
            (즉 1994년도 미국 항공기의 출발 지연이 월별로 얼마나 발생했는지 출력하시오 )

SQL> select  month,  count(depdelay)
            from  air
           where   depdelay > 0 
           group by  month;


mongo> db.air.aggregate([
                      { $match: {DepDelay: {$gt : 0 } } } ,
                      { $group: { _id: "$Month", count: { $sum: 1 } } }
                                           ])

※ 몽고디비에서 컬럼명 확인

db.air.findOne()

몽고디비에서는 컬럼명 작성할때 대소문자가 구분이 됩니다. 

예제15. 위의 결과를 다시 출력하는데 월을 1월 달부터 12월달 순으로 정렬해서 출력되게하시오 !

SQL> select  Month,  count(DepDelay)
            from  air
           where   DepDelay > 0 
           group by  Month
           order  by  Month  asc; 

mongo> db.air.aggregate([
                      { $match: {DepDelay: {$gt : 0 } } } ,
                      { $group: { _id: "$Month", count: { $sum: 1 } } },
                      { $sort : { "_id" : 1 } }
                                           ])

예제15.  위의 결과를 csv 파일로 내리시오 ( csv 파일 이름은 air_result.csv )

참고코드: 
$ mongoexport  --db=test --collection=emp700  --type=csv  --query '{ deptno : { $eq : 20 } }'  
        --fields=empno,ename,sal,mgr,hiredate,comm,job,deptno  --out=dept20.csv

mongo> db.air.aggregate([
                      { $match: {DepDelay: {$gt : 0 } } } ,
                      { $group: { _id: "$Month", count: { $sum: 1 } } },
                      { $sort : { "_id" : 1 } },
                      { $out : "results" }
                                           ])

mongo> db.results.find()

mongo> exit;

$ mongoexport -d test -c results  -f  _id,count  --csv  >> air_result.csv 

$ mongo

mongo> db.results.drop()

예제16.  위에서 내려받은 air_result.csv 를  윈도우의 주피터 노트북에서 라인 그래프로 시각화
            하시오!

import  pandas  as pd
import  matplotlib.pyplot  as  plt

air = pd.read_csv("air_result.csv")
air.columns = ['month','delay_cnt']
plt.plot(air.month, air.delay_cnt, color='red')
plt.xlabel('month')
plt.ylabel('delay_cnt') 

■ mongo db 에서 DML 문 작성하기 

mongo 가 앞에서 배운 hive 와 scalar 와 다른점은 DML 이 가능하다는 것입니다.
hive 와 scalar 는 데이터 하나를 변경하려면 다시 처음부터 csv의 데이터를 직접 변경해서
리눅스에 올리고 하둡에 올리고 hive 에 입력하고 쿼리를 해야합니다.

1. insert
db.emp.save({empno:7499,ename:"SMITH",job:"CLERK",mgr:7902,hiredate:"1980-12-17",sal:1800,comm:800,deptno:20})

2. update

SQL> update  emp
             set  sal = 5600
            where ename='SCOTT';

mongo> db.emp.update( 
                    { ename : 'SCOTT' },
                    { $set : { sal : 5600} },
                    { multi : true }
                                )

mongo> db.emp.find()

예제1. MARTIN 의 직업을 ANALYST 로 변경하시오 !

mongo> db.emp.update( 
                    { ename : 'MARTIN' },
                    { $set : { job : 'ANALYST'} },
                    { multi : true }
                                )

mongo> db.emp.find()

3. delete  

SQL> delete from  emp  where depnto = 30;

mongo> db.emp.remove( {deptno:30} ) 
mongo> db.emp.find()

[오늘의 마지막 문제]  아래의 SQL의 결과를 몽고디비에서 csv 파일로 생성해서
                             파이썬에서 원형 그래프로 시각화 하시오 !

SQL> select  job, sum(sal)
            from  emp
            group by  job
            having  sum(sal) >= 4000 ;


마지막 문제 올리시고 자유롭게 포트폴리오 또는 자습하세요 ~~










































         



















































































      
























































































































































































   


























































































































































































































































                








































































































































































































































































































































































































































































































































     



















































































































































































































































































































































































































































































































































































  


































































































































































































































































































 











































































































































































































































































































































  






















































































































 









































































































































































































































