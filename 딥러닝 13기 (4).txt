■ 딥러닝 수업 13기 

딥러닝책 예제 소스 다운로드 받기 

https://www.hanbit.co.kr/support/supplement_list.html

밑바닥부터 시작하는 딥러닝1권

equations_and_figures  


■ 머신러닝과 딥러닝의 차이

머신러닝으로 기계학습을 하려면 정형화된 데이터가 있어야 했습니다. 
표형태의 정형화된 데이터를 만들려고 판다스를 이용했습니다.
이런 정형화된 데이터를 만드는것이 상당한 노력이 들어가는일입니다.
그래서 딥러닝은 그냥 이미지를 신경망에 넣기만 하면 알아서 데이터를
숫자로 변경해서 정형화된 데이터로 만들어서 학습합니다.

그래서 신경망이 스스로 학습해서 그 이미지를 신경망이 알아볼 수 있는 상태까지
되는것입니다.

그림 : 머신러닝과 딥러닝의 차이

■ 딥러닝 기술을 이용해서 현업에서 하고 있는 일들 ?

 1. 인천공항 컨테이너 검색대에 물건을 올리면 cnn 으로 판별하여 위반되는 물품이
    있는지 검사하는 신경망을 개발 
 2. 의료쪽에서는 x-ray 사진과 의료영상 사진의 질병여부를 컴퓨터가 판별
 3. 물품(의류)의 불량품을 판별하는 신경망 개발
 4. 주가 예측 신경망 개발
 5. 외국어를 번역하는 신경망
 6. 인공지능 변호사(법률책 ---> 신경망-->판결)
 7. 음악 작곡 신경망(Gan)
 8. 인공지능 오목 
 
■ 딥러닝 책 목차

1장. 파이썬, 넘파이, matplotlib
2장. 퍼셉튼론
3장. 3층 신경망 생성
4장. 신경망 학습
5장. 오차역전파
6장. 신경망의 성능을 높이는 방법들
7장. 합성곱 신경망(cnn)

CNN --> 인공지능의 눈
RNN --> 인공지능의 입과 귀 

8장. 딥러닝으로 할 수 있는것들을 구현

 신경망활용하는 홈페이지(R Shiny)

건강보험 심사 평가원의 딥러닝 시스템 구조 

                리눅스 서버    ---------------------- 신경망  -------------- 홈페이지 
                    ↓                                          ↓                          ↓
                 몽고디비                                  파이썬                 신경망 활용
 (이미지데이터를 csv 변환해서  저장)                                              ↓
                                                                                           R shiny

                 오라클 
 (이미지데이터를 csv 변환해서 저장)
                   ↓
                 SQL 

 45분까지 쉬세요 ~~



■ 1장. 넘파이(numpy)

 numpy 란 ? python 언어에서 기본적으로 지원하지 않는 배열(array) 혹은 행렬(matrix)
                 의 계산을 쉽게 해주는 라이브러리

                 머신러닝에 많이 사용하는 선형대수학에 관련된 수식들을 python 에서
                 쉽게 프로그래밍 할 수 있게 해줍니다.

문제1.  아래의 행렬을 numpy 로 만드시오 !

  1    2
  3    4 

import  numpy  as  np
a = np.array([[1,2],[3,4]])
a

문제2. 위의 a 행렬의 각 요소에 숫자 5을 더하시오 !

import  numpy  as  np
a = np.array([[1,2],[3,4]])
a+5

※ 위의 기능이 바로 numpy의 유용한 기능중 하나인 브로드 캐스트(broadcast) 입니다. (p39)

 넘파이에서는 형상이 다른 배열끼리도 계산을 할 수 있습니다. 
 아래의 경우(그림1-1) 처럼 2x2 행렬과 숫자10을 연산하기 위해서 숫자 10이 2x2 행렬로
 확대된후 연산이 이루어지는것을 브로드 캐스트라고 합니다.

문제3.  아래의 브로드 캐스트 기능을 numpy 로 구현하시오 !

 그림 1-1

답:

import  numpy  as  np
a=np.array([[1,2],[3,4]])
a*10

문제4. 아래의 브로드 캐스트 기능을 numpy 로 구현하시오 !

그림 1-2 (책40 페이지)

답:
import numpy  as  np
a=np.array([[1,2],[3,4]])
b=np.array([[10,20]])
a*b

문제5. 아래의 행렬 내적을 numpy 로  구현하시오 !

답:

c = np.array([1,2]).reshape(1,2)   
d = np.array([1,3,5,4,3,2]).reshape(2,3)
np.dot(c,d)

문제6. 위의 행렬 내적을 신경망으로 그려보시오 !




문제7.  아래 그림의 신경망을 numpy 로 구현하시오 !


답:
import numpy as np
a = np.array([3,7])
b = np.array([[4,9,1],[3,7,2]])
np.dot(a,b)

문제8. 아래 그림의 신경망을 numpy 로 구현하시오 !

a = np.array([7,3,9]).reshape(1,3)
b =  np.array([1,5,7,3,5,4]).reshape(3,2)

print( np.dot(a,b) )

문제9. 아래의 그림의 신경망을 numpy 로 구현하시오 !

답:                                                            
a=np.array([2,7])
b=np.array([2,3,8,9,1,9]).reshape(2,3)
c=np.array([7,1,3,4,9,7]).reshape(3,2)
a@b@c

■ 넘파이의 N차원 배열(p38)     

 넘파이는 1차원 배열(1줄로 늘어선 배열)뿐만 아니라 다차원 배열로도 작성할 수 있습니다.

예제:

x = np.array([ [1,2,3,4,5], [2,4,3,2,4], [3,1,4,3,1], [2,7,3,5,4], [1,5,6,3,1] ] )
print( x.shape)  # (5, 5)

※ 넘파이 배열(np.array) 은 N차원 배열을 작성할 수 있습니다.
    1차원 배열, 2차원 배열, 3차원 배열 처럼 원하는 차수의 배열을 만들 수 있습니다.
    수학에서는 1차원 배열을 벡터(vector) 라고 하고 2차원 배열을 행렬(matrix) 라고 하고
    백터와 행렬을 일반화 한것을 텐서(tensor) 라고 합니다. 
 
 tensor   flow      --------------->  행렬이 계산되면서 흘러간다. 
   ↓        ↓
  다차원  흐름

구글에서 만든 텐써 플로우는 다차원 배열의 연산(계산)을 빠르게 할 수 있겠금 구현이 
되어져 있습니다.

* 텐서플로우의 장점

1.  신경망을 구현하기 편하게 코드가 간결합니다.
2.  신경망에 필요한 모든 함수들이 다 내장되어있습니다.
3.  속도가 아주 빠릅니다.
4.  GPU 를 사용할 수 있습니다.

* 텐써플로우 설치

1. 아나콘다 프롬프트창을 열고 가상환경을 만듭니다.

python  --version  # 파이썬 버전 확인

conda  create -n  snowdeer_env1  python=3.8.3 

# 설명:  snowdeer_env1 이라는 이름으로 파이썬3.8.3의 아나콘다 가상환경을 만듭니다.

2. snowdeer_env1 가상환경을 활성화 시킵니다.

activate  snowdeer_env1

3.  snowdeer_env1 가상환경에 tensorflow 설치

pip install  tensorflow 

4. snowdeer_env1 가상환경에 jupyter notebook 설치

conda  install  jupyter notebook

5. 시작 버튼 누르고 Anaconda 에 가서 보면 snowdeer_env1 으로 생성된 새로운
    주피터 노트북을 실행하세요 ~

문제10. (점심시간 문제)  아래의 텐써플로우 코드를 실행해서 실행이 잘되는지 화면 캡쳐해서
           올리세요 ~~
                                              즐거운 점심시간 되세요 ~~
import  tensorflow  as   tf

tf.random.set_seed(777)  # 시드를 설정한다.
import  numpy  as  np
from  tensorflow.keras.models  import  Sequential   # 신경망 모델 구성
from  tensorflow.keras.layers  import  Dense  # 완전 연결계층 
from  tensorflow.keras.optimizers  import   SGD  # 경사감소법 
from  tensorflow.keras.losses   import   mse    #  오차함수 


# 데이터 준비
x = np.array( [ [0, 0], [1, 0], [0, 1], [1, 1] ] )
y = np.array( [ [0], [0], [0], [1] ] )

#모델 구성하기 

model = Sequential()

#단층 퍼셉트론 구현하기

model.add( Dense( 1, input_shape =( 2,  ), activation ='linear')  ) 

# 모델 준비하기

model.compile( optimizer= SGD(), 
                     loss= mse, 
                     metrics = ['acc'] ) # list 형태로 평가지표를 전달한다.  


# 학습 시키기 

model.fit(x, y, epochs = 500) 


■ 넘파이(Numpy) 원소 접근(p40)

 numpy 배열안에 요소들에 대한 접근은 numpy를 이용하지 않았을때 보다 
 훨씬 간단하게 구현할 수 있습니다.

문제11. 아래의 리스트에서 숫자 55를 출력하시오 !

a = [ 51, 55, 14, 19, 0, 4 ]

답:  a[1]

문제12. 아래의 리스트에서 숫자 15이상인 숫자들만 출력하시오 !

a = [ 51, 55, 14, 19, 0, 4 ]

답:
result=[]
for  i  in  a:
    if  i >= 15:
        result.append(i)

print(result)

문제13. 위의 결과를 numpy 로 구현하시오 !

a = [ 51, 55, 14, 19, 0, 4 ]
a2 = np.array(a)
list(a2[a2>=15])

설명: numpy 를 이용하면 loop 문을 최소화 할 수 있습니다. 

문제14. 아래의 행렬식을 만들고 아래의 행렬의 요소에서 15이상인것만 출력하시오 !
           ( numpy 이용하지 말고 수행하세요)


  51   55
  14   19
   0     4 

a = [ [51, 55], [14, 19], [0, 4 ] ]

결과:  [ 51, 55, 19 ] 

답: 
a=[[51,55],[14,19],[0,4]]
result=[]
for i in a:
    for j in i:
            if j >=15:
                result.append(j)
result

문제15. 위의 결과를 numpy 로 간단하게 수행하시오 !

a=[[51,55],[14,19],[0,4]]
b = np.array(a)
list(b[b >=15])

※ numpy 를 이용하면 코딩을 어렵게 안해도 됩니다. 쉽고 빠르게 원하는것을 구현할 수 있습니다.

문제16. 아래의 행렬을 만들고 아래의 행렬에서 3이상인것만 출력하시오 ! (numpy 이용해서)

    5.1   3.5    1.4   0.2
    4.9   3.0    1.4   0.2
    4.7   3.2    1.3   0.2
    4.6   3.1    1.5   0.2

답:
a = [5.1,3.5,1.4,0.2,4.9,3.0,1.4,0.2,4.7,3.2,1.3,0.2,4.6,3.1,1.5,0.2]
a2 = np.array(a).reshape(4,4)
a2[a2>=3]

■ Matplotlib 로 그래프 그리기 (p41)

딥러닝 실험에서는 그래프 그리기와 데이터 시각화 중요합니다. 
matplotlib 는 그래프를 그리기위한 라이브러리 입니다.
matplotlib 를 이용하면 그래프 그리기가 쉬워집니다.

신경망에서 사용하는 그래프는 주로 라인 그래프입니다.
정확도가 점점 올라가는지 아니면 에러(오차)가 점점 떨어지는지 확인할 때 유용합니다. 

예제1. 파이썬으로 산포도 그래프 그리는 방법

import  numpy  as  np
import  matplotlib.pyplot  as  plt

x = np.array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ] )
y = np.array([ 9, 8, 7, 9, 8, 3, 2, 4, 3, 4 ] )

plt.scatter( x, y, color='red', s=80 )  # s 는 점사이즈 입니다.
plt.show()

예제2. 위의 그래프에 제목을 '신경망 오차 그래프' 라고 하시오 !

import  numpy  as  np
import  matplotlib.pyplot  as  plt
from  matplotlib  import   font_manager, rc

font_path='d:\\data\\malgun.ttf'
font_name=font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)

x = np.array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ] )
y = np.array([ 9, 8, 7, 9, 8, 3, 2, 4, 3, 4 ] )

plt.scatter( x, y, color='red', s=80 )  # s 는 점사이즈 입니다.
plt.title('신경망 오차 그래프')
plt.show()

▩ 1장 복습 (p45)

자주 나오는 딥러닝 면접 문제

1. 딥러닝이 무엇인가 ?   신경망이 다층이상으로 깊어진 신경망을 딥러닝이라고 합니다. 
                                 깊은신경망으로 분류와 수치예측을 좀더 정확하게 할 수 있게 되었습니다.

2. 신경망을 구현할 때 왜 numpy 를 사용하는 것인가 ?

  행렬 연산을 빠르게 할 수 있는 기능이 numpy 에 내장되어있어서 입니다.
  신경망에 데이터를 입력하면 행렬연산이 일어나고 맨 마지막으로 출력층에서 확률이 출력이
  됩니다. 신경망에 입력된 사진이 얼룩말인지 제규어인지를 분류한다면 확률이 마지막에 출력
  되기 위해서는 다차원 행렬계산을 해야합니다. 

3. numpy 의 주요 기능중에서 brodcast 는 무엇입니까 ?

형상이 다른 배열끼리 계산을 스마트하게 할 수 있게 해주는 numpy 의 기능입니다.  

■ 2장. 퍼셉트론 (p47)

▩ 퍼셉트(perceptron)론 ?

 - 인간의 뇌세포 하나를 컴퓨터로 흉내낸것
 - 1957년에 프랑크 로젠블라트가 퍼셉트론을 고안했다.
 - 사람의 뇌의 동작을 전기 스위치 온/오프로 흉내낼 수 있는다는 이론을 증명했다. 

 퍼셉트론을 간단히 애기하면 인간의 신경세포 하나를 흉내를 냈는데

 고등학교 생물시간에 배운 3가지 용어 

  1. 자극 (stimulus)
  2. 반응 ( response)
  3. 역치 ( threshold)

  " 특정 자극이 있다면 그 자극이 어느 역치 이상이어야 세포가 반응한다 "

예: 짜게 먹는 사람은 자기가 평소에 먹는 만큼 음식이 짜지 않으면 싱겁다고 느낀다.
     (역치이하의 자극은 무시)


▩ 단순한 논리회로(p49)

  1. AND 게이트
  2. OR  게이트
  3. NAND 게이트
  4. XOR 게이트

▩ AND 게이트

 그림 2-2

문제17. 위의 AND 게이트를 위한 데이터 행렬을 numpy  array 로 구현하시오 !

X = np.array( [ [0,0], [1,0], [0,1], [1,1] ] )
y = np.array( [ [0], [0], [0], [1] ] )

print( X.shape )  # (4 , 2)
print( y.shape )  # (4,  1 )

※설명: 왜 numpy array 로 생성해야하냐면 신경망에서 행렬이 연산이 일어나므로 입력되는
          데이터를 numpy array 로 생성해야 행렬연산을 쉽고 빠르게 할 수 있습니다. 

문제18. 책 51페이지에 나오는 AND 게이트 퍼셉트론 함수를 생성하시오 !

def  AND(x1, x2):
    w1, w2, theta = 0.5, 0.5, 0.7
    tmp = x1*w1 + x2*w2
    if  tmp <= theta:
        return  0
    elif  tmp >theta:
        return  1 

print ( AND(0,0) )  # 0
print ( AND(1,0) )  # 0
print ( AND(0,1) )  # 0
print ( AND(1,1) )  # 1

문제19. 그림 2-4의 OR 게이트 진리표를 보고 데이터셋 X 와 y 를 구현하시오 !

X = np.array( [ [0,0], [1,0], [0,1], [1,1] ] )
y = np.array( [ [0], [1], [1], [1] ] )

print( X.shape )  # (4 , 2)
print( y.shape )  # (4,  1 )

문제20. OR 게이트 퍼셉트론 함수를 생성하고 다음과 같이 실행하세요!

print(OR(0,0))  # 0
print(OR(1,0))  # 1
print(OR(0,1))  # 1
print(OR(1,1))  # 1 

def  OR(x1, x2):
    w1, w2, theta = 0.5, 0.5, 0.3
    tmp = x1*w1 + x2*w2
    if  tmp <= theta:
        return  0
    elif  tmp >theta:
        return  1 

설명: 책에 나온데로 만든 퍼셉트론 함수는 가중치와 임계치를 그냥 사용자가 결과가 나올수 있도록
       함수 개발자가 직접 정해준것이고 그게 아니라 데이터를 학습을 해서 직접 가중치를 알아내겠금
       하려면 단층 신경망을 생성해야합니다.

■ 텐써플로우 2.0 를 이용해서 AND 퍼셉트론 구현하기

import  tensorflow  as   tf

tf.random.set_seed(777)  # 시드를 설정한다. 가중치를 랜덤으로 생성되는데 어느 자리에서든
import  numpy  as  np   # 일치된 값으로 생성되게 하기 위해서 777로 설정합니다. 
from  tensorflow.keras.models  import  Sequential   # 신경망 모델 구성
from  tensorflow.keras.layers  import  Dense  # 신경망 층을 구성하기 위한 모듈
from  tensorflow.keras.optimizers  import   SGD  # 경사감소법 (오차가 가장 작은 지점으로 경사하강)
from  tensorflow.keras.losses   import   mse    #  오차함수 

# 데이터 준비                                                         
x = np.array( [ [0, 0], [1, 0], [0, 1], [1, 1] ] )
y = np.array( [ [0], [0], [0], [1] ] )   # AND 게이트 데이터 준비

#모델 구성하기 
model = Sequential()

#단층 퍼셉트론 신경망 만들기
model.add( Dense( 1, input_shape =( 2,  ), activation ='linear')  ) 

# 모델 준비하기
model.compile( optimizer= SGD(),  # 경사하강법 종류를 기술
                      loss= mse,           # 오차함수 지정
                      metrics = ['acc'] ) # list 형태로 평가지표를 전달한다.  

# 학습 시키기 
model.fit(x, y, epochs = 300) 

# 입력데이터를 모델에 넣어서 어떤값으로 예상하는지 확인하기
result = model.predict(x)
print(result)

[[-0.02485755]
 [ 0.4471579 ]
 [ 0.1234483 ]
 [ 0.59546375]]

문제21. 위에서 출력된 결과를 반올림하시오 ~

result = model.predict(x)
print(result.round())

문제22. AND 게이트 퍼셉트론으로 구현한 위의 신경망에서 만들어낸 최종 가중치를 출력하시오

print( model.get_weights() )

0.47201544
0.14830585

문제23. AND 게이트 퍼셉트론 신경망의 오차와 정확도를 출력하시오 !

print( model.evaluate(x,y) ) 

[0.09486427903175354, 1.0] 
         ↑                     ↑
       오차                정확도 

문제24. OR 게이트 퍼셉트론을 텐써플로우 신경망으로 구현하시오 !  

# 데이터 준비
x = np.array( [ [0, 0], [1, 0], [0, 1], [1, 1] ] )
y = np.array( [ [0], [1], [1], [1] ] )

※ 설명 :  신경망을 구성하기 위해서 model.add 를 했으며
            학습과정을 설정하기 위해서 model.compile 을 했습니다. 
            compile 할때 경사하강법의 종류를 지정해야하는데 SGD(), RMSprop(), Adam() 등이 있습니다.
            compile 할때 오차함수의 종류를 지정해야하는데 mse(mean squared error) 와
            binary_corossentropy, categorical_cross_entropy 등이 있습니다. 

문제25. (오늘의 마지막 문제) NOT AND Gate 데이터를 학습하는 신경망을 텐써 플로우로 구현하시오 

그림 2-3


마지막 문제 올리시고 나머지 시간은 자유롭게 자습하시고 포트폴리오 올리세요 ~~

내일 수업을 위해서 2장 뒷부분(51페이지 ~ 62까지 읽어오세요 )


▩ 딥러닝으로 할 수 있는 재밌는 것들

 1.  외국어 번역
 2.  질병 폐사진과 정상 폐사진 분류
 3.  주가 예측 신경망
 4.  인공지능 오목
 5.  음악 작곡, 작사 신경망
 6.  인공지능 변호사(법률책 ---> 신경망 ---> 판결)
 7.  일반 사진 ---> 에니메이션으로 변환 
 8.  일반 사진 ----> 고흐풍의 미술작품으로 변환
 9.  기타

 밑바닥부터 시작하는 딥러닝1 (cnn)  ----> 파이썬 날코딩 ---> 텐써플로우로 코딩 
 밑바닥부터 시작하는 딥러닝2 (rnn)   ----> 파이썬 날코딩 ---> 텐써플로우로 코딩 

■ 퍼셉트론 

 " 뇌세포 하나를 컴퓨터로 흉내낸것 "

* 논리회로 4가지

1. AND 게이트
2. OR 게이트
3. NAND 게이트
-----------------------------------------------------------------------------------------------------------
4. XOR 게이트 

▩ XOR 게이트 

 eXclusive  OR 게이트 

 exclusive ? 배타적(자기외에는 다 거부한다는 뜻)       그림 2-5

 - 1957 년 로젠블래트 퍼셉트론 
 - 1959 년 민스키님이 퍼셉튼론의 문제점을 지적했는데 xor 게이트는 분류를 못한다는 문제점을
   지적을 했다.

   AND, OR, NAND 는 단층신경망으로 구현이 되는데 XOR 게이트는 단층으로는 구현이 안된다. 

  그림2-6

 설명:  OR 게이트는 직선으로 분류할 수 있습니다. 단층신경망으로 분류가 가능한 데이터 입니다.

  그림2-7

 설명:  XOR 게이트는 직선으로는 분류할 수 없습니다. 

  그림 2-8(P57)


 설명: XOR 게이트는 위의 그림과 같이 비선형으로만 분류할 수 있습니다. 
        위와 같이 분류하는 신경망은 단층으로 구현할 수 없고 다층 신경망으로 구현해야합니다.

                                            20년후에 
    1957년 ------> 1959년 ---------------------> 1979년  ---------------> 1990년  (딥러닝)
      ↓                    ↓                                  ↓
 퍼셉트론 탄생     XOR 게이트 문제 제기        다층퍼셉트론으로 비선형 영역을 분류했음 

▩ XOR 게이트 함수 구현 

그림 2-9  AND, NAND, OR 게이트의 기호 설명(P58)

문제26. AND, NAND, OR 게이트를 하나씩 아래의 ? 에 대입해서 XOR 를 완성하시오 !

 그림 2-10                                                               그림 2-12



문제27. 문제26번의 그림을 참고해서 아래와 같이 결과가 출력되는 XOR 게이트 함수를 생성하시오

결과:   print(XOR(0,0))  #  0
         print(XOR(1,0))  #  1
         print(XOR(0,1))  #  1
         print(XOR(1,1))  #  0
         
답:

def  AND(x1, x2):
    w1, w2, theta = 0.5, 0.5, 0.7
    tmp = x1*w1 + x2*w2
    if  tmp <= theta:
        return  0
    elif  tmp >theta:
        return  1 

def  NAND(x1, x2):
    w1, w2, theta = 0.5, 0.5, 0.7
    tmp = x1*w1 + x2*w2
    if  tmp <= theta:
        return  1
    elif  tmp >theta:
        return  0 

def  OR(x1, x2):
    w1, w2, theta = 0.5, 0.5, 0.3
    tmp = x1*w1 + x2*w2
    if  tmp <= theta:
        return  0
    elif  tmp >theta:
        return  1 

def  XOR(x1,x2):
    s1 = NAND(x1,x2)
    s2 = OR(x1,x2)
    y = AND(s1,s2)
    return  y

print(XOR(0,0))  #  0
print(XOR(1,0))  #  1
print(XOR(0,1))  #  1
print(XOR(1,1))  #  0

■ 가중치와 편향 구현하기 (p52)

1. 신경망에서의 파라미터 ?  가중치, 편향
2. 신경망에서의 하이퍼 파라미터 ? 러닝레이트, 층수와 뉴런의 갯수 

가중치?  입력신호가 결과에 주는 영향력(중요도)를 조절하는 매개변수입니다.
편향 ?   뉴런이 얼마나 쉽게 활성화(결과를 1로 출력)하느냐를 조정하는 매개변수 입니다. 

편향이 필요한 이유 ?   아래의 or 게이트 처럼 입력신호가 x1 과 x2 값을 받는 경우에 편향(b)이 없다면
                                target 을 분류하는 직선은 무조건 원점을 통과해야하만 하기 때문에
                               제대로 분류를 할 수 없게 됩니다. 

문제28.  편향을 도입해서 퍼셉트론에 AND 게이트 함수를 생성하시오 ! (P53)

답:
def  AND(x1,x2):
    x = np.array([x1,x2])         # 입력값을 받아서 numpy array 로 변환
    w = np.array([0.5, 0.5])     # 가중치 매개변수를 각각 0.5 로 생성 
    b = -0.7
    tmp = np.sum(w*x) + b
    if  tmp <= 0:
        return  0
    else:
        return  1

문제29.  편향을 도입한 퍼셉트론에 NAND 게이트 함수를 생성하시오 ! (P53)

답:
def  NAND(x1,x2):
    x = np.array([x1,x2])         # 입력값을 받아서 numpy array 로 변환
    w = np.array([-0.5,-0.5])     # 가중치 매개변수를 각각 0.5 로 생성 
    b = 0.7
    tmp = np.sum(w*x) + b
    if  tmp <= 0:
        return  0
    else:
        return  1

문제30. 편향을 도입한 퍼셉트론에 OR 게이트 함수를 생성하시오 (P54)

답:
def  OR(x1,x2):
    x = np.array([x1,x2])         # 입력값을 받아서 numpy array 로 변환
    w = np.array([0.5, 0.5])     # 가중치 매개변수를 각각 0.5 로 생성 
    b = -0.2
    tmp = np.sum(w*x) + b
    if  tmp <= 0:
        return  0
    else:
        return  1

문제31. 편향을 도입한 퍼셉트론에 XOR 게이트 함수를 생성하시오 !

print ( XOR(0,0) )  #  0
print ( XOR(1,0) )  #  1
print ( XOR(0,1) )  #  1 
print ( XOR(1,1) )  #  0 

답:
def  XOR(x1,x2):
    s1=NAND(x1,x2)
    s2=OR(x1,x2)
    y=AND(s1,s2)
    return  y

▩ 텐써플로우 2.x 으로 XOR 게이트 구현하기 

#■ 텐써플로우 2.0 를 이용해서 AND 퍼셉트론 구현하기

import  tensorflow  as   tf

tf.random.set_seed(777)  # 시드를 설정한다.
import  numpy  as  np
from  tensorflow.keras.models  import  Sequential   # 신경망 모델 구성
from  tensorflow.keras.layers  import  Dense  # 완전 연결계층 
from  tensorflow.keras.optimizers  import   SGD  # 경사감소법 
from  tensorflow.keras.losses   import   mse    #  오차함수 

# 데이터 준비
x = np.array( [ [0, 0], [1, 0], [0, 1], [1, 1] ] )
y = np.array( [ [0], [0], [0], [1] ] )

#모델 구성하기 
model = Sequential()

#단층 퍼셉트론 구현하기
model.add( Dense( 1, input_shape =( 2,  ), activation ='linear')  ) 

# 모델 준비하기
model.compile( optimizer= SGD(), 
                     loss= mse, 
                     metrics = ['acc'] ) # list 형태로 평가지표를 전달한다.  

# 학습 시키기 
model.fit(x, y, epochs = 500, verbose=0) 


문제32.  XOR 게이트용 데이터셋을 생성하시오 !

# 데이터 준비
x = np.array( [ [0, 0], [1, 0], [0, 1], [1, 1] ] )
y = np.array( [ [0], [1], [1], [0] ] )

문제33. AND 게이트용 단층 신경망에 XOR 게이트 데이터를 넣어서 학습 시키면 학습이 되는지
           확인하시오 !

답: 
Epoch 500/500
1/1 [==============================] - 0s 2ms/step - loss: 0.2519 - acc: 0.5000

위와 같이 500 에폭까지 학습해도 전혀 학습이 되고 있지 않습니다. 

문제34. AND 게이트용 단층 신경망을 다층 신경망으로 변경해서 다시 학습 시키시오 

# 데이터 준비
x = np.array( [ [0, 0], [1, 0], [0, 1], [1, 1] ] )
y = np.array( [ [0], [1], [1], [0] ] )   # XOR 게이트용 데이터

#모델 구성하기 
model = Sequential()

#다층 퍼셉트론 구현하기
model.add( Dense( 3, input_shape =( 2,  ), activation='relu') ) # 1층 구현
model.add( Dense( 1 , activation ='sigmoid')  )  # 2층 출력층, 0~1사이의 실수를 출력하는 sigmoid 함수를
                                                                # 사용합니다.

# 모델 준비하기
model.compile( optimizer= SGD(), 
                     loss= mse, 
                     metrics = ['acc'] ) # list 형태로 평가지표를 전달한다.  

# 학습 시키기 
model.fit(x, y, epochs = 500, verbose=1) 


문제35. (점심시간 문제)  위의 XOR 게이트 데이터를 학습하는 다층 신경망의 정확도가 100% 가
           나올 수 있도록 하이퍼 파라미터를 조정하시오 !

1. 은닉층의 뉴런의 갯수를 조정 
2. 경사하강법의 종류를 변경 ( SGD(), Adam(), RMSprop()  ) 

100% 나온 결과를 캡쳐해서 답글로 올려주세요 ~~~~

■ 밑바닥 딥러닝 1권 책 복습

1장:  numpy 사용법 --> 신경망 학습시 사용되는 행렬 연산에 최적화된 모듈

2장. 퍼셉트론 --->  인간의 뇌의 뉴런 세포를 컴퓨터로 흉내낸것 
                 
           * 퍼셉트론의 종류 2가지 ?  1. 단층 퍼셉트론 : and, or, nand 게이트
                                               2. 다층 퍼셉트론 : xor 게이트

    "인공신경망이 최종적으로 산출해야하는 값 ?  

                         공부할 데이터에 대한 파라미터(가중치와 바이어스) "

3장. 필기체를 분류하는 3층 신경망 구현 (저자가 만들어온 가중치와 바이어스를 이용해서 구현)

■ 3장. 3층 신경망

  "저자가 만들어온 가중치를 신경망에 셋팅해서 필기체 데이터를 인식하는 3층 신경망을
   생성하는 단원" 

 3장에서는 신경망에 뉴런에 들어가는 함수(기능)들 소개하고 있습니다.

 1. 활성화 함수
                  - 계단함수
                  - 시그모이드 함수
                  - 렐루 함수
                  - 하이퍼볼릭 탄젠트 
 2. 출력층 함수
                  - 항등함수  (회귀분석)
                  - 소프트맥스 함수 (분류)
 3. 오차함수 
                  - 평균제곱오차 함수 (회귀분석)
                  - 크로스 엔트로피(cross entropy) 오차함수 (분류)
              

▩ 계단함수 p69

 "숫자 0과 1을 리턴하는 함수"

 입력값 x <= 0  ---------------> 0을 리턴 
 입력값 x >0   -----------------> 1을 리턴 

예제:
def  step_function(x):
    if  x > 0 :
        return  1 
    else:
        return  0

x_data = np.array([-1, 0, 1] )
print ( step_function(x_data) ) # 이거는 에러납니다.
print ( step_function(3.0) )  # 이거는 에러 안납니다.

설명: 위에서 만든 step_function 함수는 배열을 넣을 수 없습니다. 

문제36.  numpy 배열을 넣을 수 있도록 step_function 함수를 다시 생성하시오 ! (p69)

답:
def  step_function(x):
    y = x > 0
    return  y.astype(np.int) 

step_function(np.array(3.0)) 

설명: true 를 np.int 로 변환하면 1이 출력되고 false 를 np.int로 변환하면 0 이 출력됩니다.

설명:  신경망에서 흘러가는 모든 데이터는 numpy array 형태의 다차원 배열이므로
         신경망내에서 쓰여질 활성화 함수도 numpy array 형태의 데이터를 받아서 
         처리할 수 있도록 생성되어져야 합니다. 

문제37. 위에서 만든 step_function 함수를 책 71페이지의 나온것처럼 시각화 하시오 

 그림 3-6

답:
import  matplotlib.pylab  as  plt
import  numpy  as  np

def  step_function(x):
    y = x > 0
    return   y.astype(np.int) 

x = np.arange(-5, 5, 0.1)  # -5부터 5까지 0.1 간력으로 숫자를 출력해라 
y = step_function(x)
plt.plot(x,y)
plt.ylim(-0.1, 1.1)
plt.show()

문제38. 시그모이드 함수를 파이썬으로 구현하시오 !  (p72) 

 시그모이드 함수 공식:  



답:
import   numpy   as   np 

def  sigmoid(x):
    return  1 / ( 1 + np.exp(-x) ) 


문제39. 시그모이드 함수를 시각화 하시오 (p73)

답:

import   numpy   as   np 

def  sigmoid(x):
    return  1 / ( 1 + np.exp(-x) )

x = np.arange(-5.0, 5.0, 0.1)
y = sigmoid(x)
plt.plot(x,y)
plt.ylim(-0.1, 1.1)
plt.show()

문제40. 활성화 함수인 하이퍼블릭 탄젠트 함수를 생성하시오 !

답:
import  math 

def  tanh(x):
    return  list( map( lambda  x : math.tanh(x), x) ) 

x = np.arange(-5.0, 5.0, 0.1)
y = tanh(x)
plt.plot(x,y)
plt.ylim(-1.1, 1.1)
plt.show()

설명: sigmoid 함수는 0~1사이의 실수를 출력하는것이고 탄젠트 함수는 -1에서 1사이의 실수를
       출력합니다. 

▩ Relu 함수 (Rectified  Linear  Unit )  p76
                     ↓
                  정류된 

정류는 전기회로 쪽 용어입니다. 그림 3-9 처럼 x 가 0 이하일때는 차단하여 아무것도
출력하지 않고 0보다 큰값은 그 값을 그대로 출력합니다.


문제41. relu 함수를 파이썬으로 생성하시오 (p77)

답: 
import  numpy  as   np

def  relu(x):
    return  np.maximum(0,x)  # 0 과 x 값 중에서 큰값을 출력한다. 

print ( relu(-2) )
print ( relu(0.3) )

문제42. relu 함수를 그래프로 시각화 하시오 ! 

답: 

x = np.arange(-5, 5, 0.1)
y = relu(x)
plt.plot(x,y, color='red')
plt.show()

■ 다차원 배열 (p77)

 신경망에 들어가는 데이터를 다차원 배열입니다.
 다차원 배열이 신경망에 들어가서 행렬 계산을 하기 때문에 다차원 배열에 대한 이해가 
  있어야합니다.  사진도 다차원 배열, 동영상도 다차원 배열로 입력이 됩니다. 

예제1. 1차원 배열 만들기

import  numpy  as  np
a = np.array([1, 2, 3, 4] )
print( np.ndim(a) )   # 차원을 확인할 수 있습니다. 

문제43. 위의 a 1차원 배열에서  숫자 4를 출력하시오 !

import  numpy  as  np
a = np.array([1, 2, 3, 4] )
print(a[3])

문제44. 아래의 그림 3x2 행렬을 만들고 차원을 확인하시오 (그림3-10)

답:
b = np.array([ [1,2], [3,4], [5,6] ])
print( np.ndim(b) )
또는
b = np.array([ 1, 2, 3, 4, 5, 6 ]).reshape(3,2)
print (np.ndim(b))

문제45. 아래의 3차원 배열을 생성하시오 !

c = np.array( [ [ [1,2], [3,4] ], [ [5,6], [7,8] ] ] )
print(c)
print( np.ndim(c) )

문제46. 위의 3차원 배열을 그냥 reshape 를 이용해서 편하게 만드시오 ~

d = np.array([ 1, 2, 3, 4, 5, 6, 7, 8 ] ).reshape(2,2,2)
print(d)
print( np.ndim(d) )

문제47. 위의 3차원 배열에서 숫자 5를 출력하시오 

[[[1 2]
  [3 4]]

 [[5 6]
  [7 8]]]

print( d[1][0][0] )

▩ 행렬의 내적(행렬곱)  p79

 그림 3-11

1. 첫번째 방법
import  numpy  as  np

x = np.array([ 1, 2, 3, 4]).reshape(2,2)
y = np.array([ 5, 6, 7, 8]).reshape(2,2)
print( np.dot(x,y) )

2. 두번째 방법
import  numpy  as  np

x = np.array([ 1, 2, 3, 4]).reshape(2,2)
y = np.array([ 5, 6, 7, 8]).reshape(2,2)
print( x @ y )

3. 세번째 방법 

x = np.matrix( [ [1, 2], [3, 4] ])
y = np.matrix( [ [5, 6], [7, 8] ])
print (x * y)

※ array 와 matrix 의 기능 차이 ?

  array 는 다차원으로 나타낼 수 있는데 matrix 는 2차원 밖에 안됩니다. 

※ 행렬곱(내적) 시 주의 사항 !

 그림 3-12

다차원 배열을 곱하려면 두 행렬의 대응하는 차원의 원소수를 일치 시켜야 합니다. 

문제48. 아래 그림 3-14의 결과값 y 행렬을 출력하시오 ! 답글로 달아주세요 ~~


▩ 3층 신경망 구현하기(p83)

 그림 3-15

답:
import  numpy  as  np

def  sigmoid(x):
    return  1 / (1+np.exp(-x) )

#입력층(0층)
x = np.array([1,2])

#은닉층(1층)
w1 = np.array([1,3,5,2,4,6]).reshape(2,3)
y = np.dot(x,w1)
y_hat = sigmoid(y)
print(y_hat)

문제49. 입력층 ---> 은닉1층 --->은닉2층 까지 구현하세요 ~

def sigmoid(x):
    return 1/(1+np.exp(-x))

# 입력값 (0층)
x = np.array([1,2]).reshape(1,2)

# 은닉층 (1층)
w1 = np.array([1,3,5,2,4,6]).reshape(2,3) # 가중치
y = np.dot(x,w1)
y_hat = sigmoid(y)

# 은닉층 (2층)
w2 = np.array([3,4,5,6,7,8]).reshape(3,2)
z1 = np.dot(y_hat,w2)
z_hat = sigmoid(z1)

z_hat

 
문제50.  입력층 --->은닉1층 --->은닉2층 ---> 출력층 까지 구현하시오 !

def sigmoid(x):
    return 1/(1+np.exp(-x))

# 입력값 (0층)
x = np.array([1,2]).reshape(1,2)

# 은닉층 (1층)
w1 = np.array([1,3,5,2,4,6]).reshape(2,3) # 가중치
y = np.dot(x,w1)
y_hat = sigmoid(y)

# 은닉층 (2층)
w2 = np.array([3,4,5,6,7,8]).reshape(3,2)
z1 = np.dot(y_hat,w2)
z_hat = sigmoid(z1)

# 출력층(3층)
w3 = np.array( [4, 5, 6, 7 ]).reshape(2,2)
k= np.dot(z_hat, w3)
print(k)

[[ 9.99999866 11.99999833]]

문제51. (오늘의 마지막 문제) 3층 신경망의 활성화 함수를 relu 로 변경하고 결과를 출력하시오 !


▩ 딥러닝으로 할 수 있는 일들 ?

 1. 정상품과 불량품을 분류 --->  품질관리사  ---> 밑바닥부터 시작하는 딥러닝1 (cnn)
 2. 인공지능 상담원(자연어처리) ---> 콜센터 상담원 --> 밑바닥부터 시작하는 딥러닝2(rnn)
 3. 인공지능 오목(CNN)

  신경망 + 컴퓨터가 스스로 학습하는 기술 --> 강화학습  ---> 알파고

복습:
1장:  numpy 
2장:  퍼셉트론
3장:  3층신경망 

 그림 3-15

■ 출력층 설계하기 (p90)

 "출력층의 함수는 그동안 흘러왔던 확률들의 숫자를 취합해서 결론을 내줘야하는 함수"

신경망으로 구현하고자하는것?

 1. 주가예측(회귀) ?         출력층의 함수를 항등함수를 써야합니다. 
                                                            ↓
                                      입력값을 받아서 그대로 출력하는 함수 

항등함수의 예:   def  identity_func(x):
                          return  x

 2. 정상품과 불량품 분류 (분류) ? 출력층의 함수를 소프트맥스 함수를 사용해야합니다.
                                                                       ↓
                                             입력값을 받아서 확률백터로 출력하는 함수 

                                                [ 0.8, 0.2 ]
                                                   0    1

▩ 출력층 함수인 소프트 맥스 함수 생성(p91)

 식 3-10


위의 식을 파이썬으로 구현해볼건데 위의 식을 그대로 파이썬 코드로 그대로 만들면
에러가 나서 구현이 안됩니다.  왜냐하면 지수함수는 쉽게 아주 큰 값을 출력하기 때문에
컴퓨터는 큰 값을 출력하게 되면 overflow 가 출력되면서 에러가 납니다.
그래서 위의 수학식을 컴퓨터로 구현할 수 있게 할 수 있도록 아래와 같이 전개해줘야합니다.

식 3-11

소프트맥스 함수의 자연상수의 지수함수는 아주 큰값을 출력합니다.
자연상수 e 의 10승은 20000 이 넘고 e 의 100 승은 숫자40개가 넘고 
자연상수 e 의 1000 승은 무한대를 뜻하는 inf 가 출력이 됩니다. 그래서 컴퓨터로 계산을 할 수가
없는것입니다.

예:
import  numpy   as  np
print ( np.exp(10) )   # 22026.465794806718
print ( np.exp(100) )  # 2.6881171418161356e+43
print ( np.exp(1000) )  # inf  

식 3-11 에 나온데로 구현해봅니다.

import  numpy  as  np
a = np.array([1010, 1000, 990])  
print( np.exp(a) )  # [inf inf inf]


import  numpy  as  np
a = np.array([1010, 1000, 990])  
C = np.max(a) 
minus = a - C
print( np.exp(minus) )

소프트 맥스 함수 만들기 

a = np.array([1010, 1000, 990])  

def  softmax(a):
    C = np.max(a)
    minus = a - C
    np_exp = np.exp(minus)
    return  np_exp

print(softmax(a))  # [1.00000000e+00 4.53999298e-05 2.06115362e-09]

분모까지 포함해서 구현하면?

def  softmax(a):
    C = np.max(a)
    minus = a - C
    exp_a = np.exp(minus)  # 분자 수학식
    sum_exp_a = np.sum(exp_a) # 분모 수학식
    y = exp_a / sum_exp_a
    return  y 

print (softmax(a) )  # [9.99954600e-01    4.53978686e-05    2.06106005e-09]
                                   아이린               설현                      수지 

문제52. 위에서 출력된 결과 리스트의 요소를 다 더하면 숫자 1이 맞는지 확인하시오 !

def  softmax(a):
    C = np.max(a)
    minus = a - C
    exp_a = np.exp(minus)  # 분자 수학식
    sum_exp_a = np.sum(exp_a) # 분모 수학식
    y = exp_a / sum_exp_a
    return  y 

result = softmax(a)
print ( np.sum(result) ) 

문제53. 위의 결과가 신경망이 예측한 연애인이 아이린,설현,수지 중 누구인지 확인하시오
           (아래의 3개의 요소중에 가장 큰 값이 무엇인가?)   

  [9.99954600e-01    4.53978686e-05    2.06106005e-09]
      아이린               설현                      수지 


result = softmax(a)
print( np.argmax(result) )  # 아이린으로 예측함 

※ np.argmax 함수는?  numpy 리스트의 요소중 가장 큰값의 인덱스 번호를 출력하는 함수 

문제54. 어제 마지막 문제로 만들었던 3층 신경망 코드의 출력층에 지금 만든 소프트맥스 함수
           를 넣어서 결과를 출력하는데 출력 변수명은 k_hat 으로 하세요 !

import numpy as np

def relu(x):
    return np.maximum(0,x)  # 0과 x 값 중에서 큰 값을 출력한다.

# 입력층 (0층)
x = np.array([1,2])

# 은닉층 (1층)
w1 = np.array([1,3,5,2,4,6]).reshape(2,3)
y = np.dot(x,w1)
# [ 5 11 17]
y_hat = relu(y)
print(y_hat)
# [ 5 11 17]

# 은닉층 (2층)
w2 = np.array([3,4,5,6,7,8]).reshape(3,2)
z = np.dot(y_hat,w2)
z_hat = relu(z)
print(z_hat)
# [189 222]

# 출력층 (3층)
w3 = np.array([4,5,6,7]).reshape(2,2)
k = np.dot(z_hat,w3)
k_hat = softmax(k)
print ( k_hat )

문제55. 위에서 출력된 k_hat 요소중 가장 큰 값의 인덱스 번호가 몇번인가 ? 

# 출력층 (3층)
w3 = np.array([4,5,6,7]).reshape(2,2)
k = np.dot(z_hat,w3)
k_hat = softmax(k)
result = np.argmax(k_hat)
print(result)  # 1 

아이린과 설현 사진을 분류하는 신경망을 만든다고 하면 신경망 학습을 해서 
최종적으로 얻어내야하는 것은 ?   가중치와 바이어스 

가중치와 바이어스를 나중에 쉽게 신경망에서 추출하려면 가중치를 딕셔너리로 관리하면
편합니다.

* 파이썬 자료형 5가지

1. 문자형
2. 숫자형
3. 리스트형
4. 딕셔너리형
5. 튜플형 

3층 신경망의 가중치 (w1, w2, w3) 행렬을 딕셔너리 형태로 생성합니다.

import  numpy  as  np

def  init_network():
    network = {}  # 비어있는 딕셔너리 생성 
    network['W1'] = np.array([ [1,3,5], [2,4,6] ])
    network['W2'] = np.array([ [3,4], [5,6], [7,8] ])
    network['W3'] = np.array([ [4,5], [6,7] ] )
    return  network 

#가중치값 불러오기
network = init_network()
w1, w2, w3 = network['W1'], network['W2'], network['W3']
print(w1)
print(w2)
print(w3)

문제56.  소프트맥스 함수까지 포함시킨 3층 신경망의 위에서 만든 가중치를 불러오는 
               init_network 를 추가해서 3층 신경망을 구현하시오 !

import  numpy  as  np                           45분 까지 쉬세요 ~~

def  init_network():
    network = {}  # 비어있는 딕셔너리 생성 
    network['W1'] = np.array([ [1,3,5], [2,4,6] ])
    network['W2'] = np.array([ [3,4], [5,6], [7,8] ])
    network['W3'] = np.array([ [4,5], [6,7] ] )
    return  network 

#가중치값 불러오기
network = init_network()
w1, w2, w3 = network['W1'], network['W2'], network['W3']

def relu(x):
    return np.maximum(0,x)  # 0과 x 값 중에서 큰 값을 출력한다.

# 입력층 (0층)
x = np.array([1,2])

# 은닉층 (1층)
y = np.dot(x,w1)
y_hat = relu(y)

# 은닉층 (2층)
z = np.dot(y_hat,w2)
z_hat = relu(z)

# 출력층 (3층)
k = np.dot(z_hat,w3)
k_hat = softmax(k)
print ( k_hat )  # [3.19865896e-179 1.00000000e+000]

■ 손글씨 숫자를 인식하는 신경망 만들기 p96

 그림3-24
 
데이터 설명: mnist 데이터는 숫자 0~9까지의 숫자 이미지로 구성되어있고 
                 훈련 데이터가 6만장, 테스트 데이터가 1만장으로 구성되어 있습니다.
                 28x28 크기의 회색조 이미지(1채널) 이며 각 픽셀은 0~255 까지의 값을
                 취합니다. 

* 데이터를 주피터 노트북으로 로드하는 방법

1. 실습 폴더안에 dataset 이라는 폴더를 복사해서 주피터 노트북의 작업디렉토리에
   가져다 둡니다.

C:\Users\YYS

2. 주피터 노트북에서 아래와 같이 코드를 작성합니다. 

import   sys, os  
sys.path.append(os.pardir)  # 현재 윈도우 os의 폴더를 인식하기 위해서 지정
from  dataset.mnist  import   load_mnist  # 필기체 데이터 불러오는 함수

(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)
   ↓            ↓        ↓     ↓
 훈련데이터 , 정답 ,  테스트 데이터, 정답

설명: flatten : 입력 이미지를 1차원 배열로 만들지를 정하는 매개변수
       normalize : 이미지의 픽셀값이 현재 0~255 사이로 되어져있는데 이 값을
                      0 ~ 1사이의 값으로 정규화 할지를 정한다. 

 28x28 = 784

print(x_train.shape)  # (60000, 784)

문제57. 테스트 데이터는 전체 몇장인지 출력하시오 !

print(x_test.shape)  #(10000, 784)

문제58. mnist 데이터를 flatten 시키지 말고 훈련 데이터의 shape 를 출력하시오

import   sys, os  
sys.path.append(os.pardir)  # 현재 윈도우 os의 폴더를 인식하기 위해서 지정
from  dataset.mnist  import   load_mnist  # 필기체 데이터 불러오는 함수

(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False, normalize=False)

print(x_train.shape)  # (60000, 1, 28, 28)
                              
                            ( 전체장수, 색조, 가로 사이즈, 세로 사이즈)

문제59. 훈련 데이터 6만장중에 첫번째 필기체가 숫자가 무엇인지 출력하시오!

import   sys, os  
sys.path.append(os.pardir)  # 현재 윈도우 os의 폴더를 인식하기 위해서 지정
from  dataset.mnist  import   load_mnist  # 필기체 데이터 불러오는 함수

(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False, normalize=False)
print( t_train[0])  # 5 

문제60. 훈련 데이터 6만장중에 첫번째 필기체 숫자가 5가 맞는지 확인하시오 !

import   sys, os  
sys.path.append(os.pardir)  # 현재 윈도우 os의 폴더를 인식하기 위해서 지정
from  dataset.mnist  import   load_mnist  # 필기체 데이터 불러오는 함수

(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False, normalize=False)
print( x_train[0]) 

[[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0   0   0   0   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0   0   0   0   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0   0   0   0   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0   0   0   0   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0   0   0   0   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0]
  [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253  253 225 172 253 242 195  64   0   0   0   0]
  [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253  251  93  82  82  56  39   0   0   0   0   0]
  [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247  241   0   0   0   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43  154   0   0   0   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0     0   0   0   0   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0     0   0   0   0   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0     0   0   0   0   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1   0   0   0   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253  119  25   0   0   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253  253 150  27   0   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93  252 253 187   0   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  249 253 249  64   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183   253 253 207   2   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253   253 250 182   0   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253   201  78   0   0   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81     2   0   0   0   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0    0   0   0   0   0   0   0   0   0   0   0]
  [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0    0   0   0   0   0   0   0   0   0   0   0]
  [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0    0   0   0   0   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0    0   0   0   0   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0     0   0   0   0   0   0   0   0   0   0   0]
  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0     0   0   0   0   0   0   0   0   0   0   0]]]

문제61.  텐써플로우를 이용해서 mnist 데이터를 가져오시오 !
            ( 구글의 텐써 플로우는 이미 mnist 데이터를 내장하고 있습니다.)

답:
from   tensorflow.keras.datasets.mnist  import  load_data
(x_train2, y_train2), (x_test2, y_test2) = load_data('mnist.npz')
print (x_train2.shape) # (60000, 28, 28)

문제62. mnist 의 첫번째 훈련 데이터를 시각화 하시오 (텐써플로우)

import  matplotlib.pyplot  as  plt

img = x_train2[0]
#print(img.shape)  # (28, 28)
plt.figure()
plt.imshow(img)

문제63. 밑바닥 딥러닝 책의 mnist 데이터의 첫번째 훈련데이터를 시각화 하시오

x_train[0].shape  # (1, 28, 28)  # 3차원
a = x_train[0].reshape(28,28)   # 2차원
plt.figure
plt.imshow(a)

문제64. 밑바닥 딥러닝 책의 mnist 데이터의 10번째 훈련 데이터를 시각화 하시오 !

x_train[9].shape  # (1, 28, 28)  # 3차원
a = x_train[9].reshape(28,28)   # 2차원
plt.figure
plt.imshow(a)

■ 저자가 만들어온 가중치 피클(pickle) 파일을 불러오는 방법 

 저자가 이미 힘들게 mnist 데이터로 신경망을 생성시켜서 만들어온 가중치와 바이어스
 를 불러오기

예제1. pickle 파일을 생성하는 예제

import  pickle
a=[0.7, 1.4, 3.5]  # 학습 시켜서 만든 가중치 값이라고 하겠습니다.
with  open("d:\\a.pkl", "wb")  as  f:
    pickle.dump( a, f ) 

예제2.  피클 파일 a.pkl 을 파이썬으로 불러오는 예제

with  open("d:\\a.pkl", "rb")  as  f:
    data = pickle.load(f)

print(data)

예제3. 저자가 만든 피클파일을 파이썬으로 불러오는 예제 (ch03 폴더안에)

   sample_weight.pkl 를 복사해서 주피터노트북 작업 디렉토리에 가져다두세요

with  open("sample_weight.pkl", "rb")  as  f:
    data = pickle.load(f)

print(data)

위의 2가지 파일(mnist데이터, pickle 파일) 로 3층 신경망을 구성하겠습니다. 

예제4. 저자가 만들어온 pickle 파일을 우리가 만들 신경망에 쉽게 불러올 수 있도록
         함수를 생성하기 

import  pickle

def  init_network():
    with   open("sample_weight.pkl", "rb")  as  f:
        network = pickle.load(f)
    return  network

network = init_network()   # 함수를 실행해서 결과를 network 변수에 담는다.
print( type(network) )  # <class 'dict'>

딕셔너리는 '키' 와 '값' 으로 구성된 자료형 입니다. 

문제65. 위에서 결과로 출력된 network 딕셔너리의 키값들이 뭐가 있는지 출력하시오 !

print( network.keys() )

dict_keys(['b2', 'W1', 'b1', 'W2', 'W3', 'b3'])

문제66.  가중치 행렬의 shape 가 각각 어떻게 되는지 확인하시오 !

print(  network['W1'].shape)  # (784, 50)  은닉1층
print(  network['W2'].shape)  # (50, 100)  은닉2층
print(  network['W3'].shape)  # (100, 10)  출력층 

문제67. 위의 가중치 행렬을 보고 저자가 만들어온 신경망의 구조를 그리시오 !

(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)

      입력층 ---------------> 은닉1층 -------------> 은닉2층 ---------------------> 출력층 
 (60000, 784)  ⊙  (784, 50)  --> (60000,50) ⊙ (50, 100) ---> (60000,100) ⊙ (100, 10)  

문제68. 저자가 만들어온 가중치 행렬을 셋팅해서 3층 신경망중에 1층까지 구현하시오

# 0. 필요한 함수를 불러옵니다.

def sigmoid(x):
    return  1/(1+np.exp(x))

# 1. 신경망에 필요한 가중치와 바이어스를 가져옵니다. 
import  pickle

def  init_network():
    with   open("sample_weight.pkl", "rb")  as  f:
        network = pickle.load(f)
    return  network

network = init_network() 
w1, w2, w3 = network['W1'], network['W2'], network['W3']  
b1, b2, b3  = network['b1'], network['b2'], network['b3']

#2. mnist 데이터를 불러옵니다.
from  dataset.mnist  import  load_mnist
(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=True)

#3. 3층 신경망을 구성합니다. 

#0층 (입력층)
x = x_train[0:10]  # 일단 10개의 필기체 데이터를 가져옵니다. 

#1층 (은닉층)
y = np.dot(x,w1) + b1
y_hat = sigmoid(y)
print(y_hat)

#2층 (은닉층)
#3층 (출력층)

문제69. 은닉2층 코드를 구현하세요 !

# 0. 필요한 함수를 불러옵니다.

def sigmoid(x):
    return  1/(1+np.exp(x))

# 1. 신경망에 필요한 가중치와 바이어스를 가져옵니다. 
import  pickle

def  init_network():
    with   open("sample_weight.pkl", "rb")  as  f:
        network = pickle.load(f)
    return  network

network = init_network() 
w1, w2, w3 = network['W1'], network['W2'], network['W3']  
b1, b2, b3  = network['b1'], network['b2'], network['b3']

#2. mnist 데이터를 불러옵니다.
from  dataset.mnist  import  load_mnist
(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=True)

#3. 3층 신경망을 구성합니다. 

#0층 (입력층)
x = x_train[0:10]  # 일단 10개의 필기체 데이터를 가져옵니다. 

#1층 (은닉층)
y = np.dot(x,w1) + b1
y_hat = sigmoid(y)

#2층 (은닉층)
z = np.dot(y_hat, w2) + b2
z_hat = sigmoid(z)
print(z_hat.shape) # (10,100)

#3층 (출력층)

  입력층 -------> 은닉1층 -------------> 은닉2층 ---------------------> 출력층 
 (10, 784)  ⊙  (784, 50)  --> (10,50) ⊙ (50, 100) ---> (10,100) ⊙ (100, 10)  ---> (10,10)  

문제70.  마지막 출력층(3층) 을 구현하시오 !

 출력층의 함수 ?    1. 회귀 : 항등함수
                          2. 분류 : 소프트 맥스 함수

# 0. 필요한 함수를 불러옵니다.

def sigmoid(x):
    return  1/(1+np.exp(-x))

def  softmax(a):
    C = np.max(a)
    minus = a - C
    exp_a = np.exp(minus)  # 분자 수학식
    sum_exp_a = np.sum(exp_a) # 분모 수학식
    y = exp_a / sum_exp_a
    return  y 

# 1. 신경망에 필요한 가중치와 바이어스를 가져옵니다. 
import  pickle

def  init_network():
    with   open("sample_weight.pkl", "rb")  as  f:
        network = pickle.load(f)
    return  network

network = init_network() 
w1, w2, w3 = network['W1'], network['W2'], network['W3']  
b1, b2, b3  = network['b1'], network['b2'], network['b3']

#2. mnist 데이터를 불러옵니다.
from  dataset.mnist  import  load_mnist
(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=True)

#3. 3층 신경망을 구성합니다. 

#0층 (입력층)
x = x_train[0:10]  # 일단 10개의 필기체 데이터를 가져옵니다. 

#1층 (은닉층)
y = np.dot(x,w1) + b1
y_hat = sigmoid(y)

#2층 (은닉층)
z = np.dot(y_hat, w2) + b2
z_hat = sigmoid(z)
#print(z_hat.shape) # (10,100)

#3층(출력층)
k = np.dot(z_hat, w3) + b3
k_hat = softmax(k)
a = np.argmax(k_hat, axis=1)  
print(a) # [5 0 4 1 9 2 1 3 1 4] # 예측값
b = t_train[0:10]  # 정답 10개
print(b)  # [5 0 4 1 9 2 1 3 1 4]

문제71.  100개의 필기체 데이터를 3층 신경망에 넣고 정확도를 확인하시오 !

# 0. 필요한 함수를 불러옵니다.

def sigmoid(x):
    return  1/(1+np.exp(-x))

def  softmax(a):
    C = np.max(a)
    minus = a - C
    exp_a = np.exp(minus)  # 분자 수학식
    sum_exp_a = np.sum(exp_a) # 분모 수학식
    y = exp_a / sum_exp_a
    return  y 

# 1. 신경망에 필요한 가중치와 바이어스를 가져옵니다. 
import  pickle

def  init_network():
    with   open("sample_weight.pkl", "rb")  as  f:
        network = pickle.load(f)
    return  network

network = init_network() 
w1, w2, w3 = network['W1'], network['W2'], network['W3']  
b1, b2, b3  = network['b1'], network['b2'], network['b3']

#2. mnist 데이터를 불러옵니다.
from  dataset.mnist  import  load_mnist
(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=True)

#3. 3층 신경망을 구성합니다. 

#0층 (입력층)
x = x_train[0:100]  # 일단 100개의 필기체 데이터를 가져옵니다. 

#1층 (은닉층)
y = np.dot(x,w1) + b1
y_hat = sigmoid(y)

#2층 (은닉층)
z = np.dot(y_hat, w2) + b2
z_hat = sigmoid(z)
#print(z_hat.shape) # (10,100)

#3층(출력층)
k = np.dot(z_hat, w3) + b3
k_hat = softmax(k)
a = np.argmax(k_hat, axis=1)  
b = t_train[0:100]  # 정답 100개

print( sum(a==b) )

■ 배치처리 p102

  훈련 데이터가 6만장이나 되므로 6만장을 한번에 신경망에 넣고 학습 시키게 되면
  컴퓨터도 메모리 사용량이 초과해서 수행되지 않는다고 하면서 수행이 되지 않습니다.

  사람이 책을 볼때도 한번에 책 한권(60000 페이지)을 동시에 볼 수 없고 한번에 한페이지씩
  보듯이 컴퓨터도 마찬가지로 메모리가 허용하는내에서 페이지를 학습할 수 있습니다.

 한번에 100페이지씩 보면서 학습하겠금 배치단위로 학습시키는것을 배치처리라고 합니다. 

  입력값               w1  
(60000, 784) ⊙ ( 784, 50 ) 

 학습을 시킬려고 하면 메모리 초과가 나오면서 학습되지 않습니다.  그래서 100개씩 학습시키는것을
 배치단위 학습이라고 합니다. 

▩ 신경망이 이해하는 사진이란 ?

문제72. 아이린 사진을 파이썬에서 시각화 하시오 !

from  PIL  import  Image   #  사진을 파이썬으로 불러오기 위한 모듈 임폴트
import  numpy  as  np
import  matplotlib.pyplot  as  plt 

img = Image.open('d:\\data\\아이린.jpg')  # 아이린 사진을 파이썬으로 불러옵니다.
img_pixel = np.array(img)  # 불러온 숫자값을 numpy array 로 변환합니다. 
plt.imshow(img_pixel)       # 이미지 시각화
print( img_pixel.shape)     # (500,  500,  3)
                                        ↑   ↑    ↑
                                       가로 세로  색조(Red, Green, Blue)

문제73. 아이린 사진에서 red 부분 행렬만 시각화 하시오 !

from  PIL  import  Image    #  사진을 파이썬으로 불러오기 위한 모듈 임폴트
import  numpy  as  np
import  matplotlib.pyplot  as  plt 

img = Image.open('d:\\data\\아이린.jpg')  # 아이린 사진을 파이썬으로 불러옵니다.
img_pixel = np.array(img)  # 불러온 숫자값을 numpy array 로 변환합니다. 
img_pixel[ : , : , 1 ] = 0    # green 행렬을 전부 0으로 변경 (검정색으로 변경해라)
img_pixel[ : , : , 2 ] = 0    # blue  행렬을 전부 0 으로 변경 (검정색으로 변경해라)
plt.imshow(img_pixel)       # 이미지 시각화

문제74.  아이린 사진에서 green 부분 행렬만 시각화 하시오 !

from  PIL  import  Image    #  사진을 파이썬으로 불러오기 위한 모듈 임폴트
import  numpy  as  np
import  matplotlib.pyplot  as  plt 

img = Image.open('d:\\data\\아이린.jpg')  # 아이린 사진을 파이썬으로 불러옵니다.
img_pixel = np.array(img)  # 불러온 숫자값을 numpy array 로 변환합니다. 
img_pixel[ : , : , 0 ] = 0    # red 행렬을 전부 0으로 변경 (검정색으로 변경해라)
img_pixel[ : , : , 2 ] = 0    # blue  행렬을 전부 0 으로 변경 (검정색으로 변경해라)
plt.imshow(img_pixel)       # 이미지 시각화

문제75. 아이린 사진에서 blue 부분의 행렬만 시각화 하시오 !

from  PIL  import  Image    #  사진을 파이썬으로 불러오기 위한 모듈 임폴트
import  numpy  as  np
import  matplotlib.pyplot  as  plt 

img = Image.open('d:\\data\\아이린.jpg')  # 아이린 사진을 파이썬으로 불러옵니다.
img_pixel = np.array(img)  # 불러온 숫자값을 numpy array 로 변환합니다. 
img_pixel[ : , : , 0 ] = 0    # red 행렬을 전부 0으로 변경 (검정색으로 변경해라)
img_pixel[ : , : , 1 ] = 0    # green  행렬을 전부 0 으로 변경 (검정색으로 변경해라)
plt.imshow(img_pixel)       # 이미지 시각화

문제76.  아이린 사진을 흑백 사진으로 변경하시오 !

j= 'd:\\data\\아이린.jpg'

import numpy as np  #  신경망에 사진을 입력할때 숫자행렬로 입력해야하기 때문에 필요
import matplotlib.pyplot as plt # 사진을 파이썬에서 시각화하기 위해 필요
import matplotlib.image as mpimg #  사진을 불러와서 숫자로 변환해주기 위해 필요

def rgb2gray(rgb):  # 흑백으로 색깔을 변경하기 위한 함수 
    return np.dot(rgb[ :, :, : ], [0.299, 0.587, 0.114])
                       
img = mpimg.imread(j)  #  사진을 숫자로 변경 

gray = rgb2gray(img)  # 컬러를 흑백으로 변환 

plt.imshow(gray, cmap = plt.get_cmap('gray'))  # 시각화 합니다. 
plt.show()

문제77. (오늘의 마지막 문제)  인터넷에서 흑백으로 변경하고 싶은 컬러 사진을 내려받아
           흑백으로 사진 변경하고 이미지 첨부하세요 ~~

어제까지 배운 내용 복습 (신경망 그림)

설현사진을 신경망에 입력하는 원리 ?


문제78. 위의 그림을  mnist 필기체 데이터로 설명하시오 !

 5분동안 직접 그림으로 그려보세요 ~~




문제79. 아래의 신경망 그림을 텐써플로우로  구현하시오 !

#그림: https://cafe.daum.net/oracleoracle/Shyl/182

# 1. mnist 데이터를 불러옵니다.
import  tensorflow  as  tf
from  tensorflow.keras.datasets.mnist  import  load_data

(x_train, y_train), (x_test, y_test) = load_data(path='mnist.npz') 

print ( x_train.shape) # (60000, 28, 28)  , (데이터갯수, 가로 픽셀수, 세로 픽셀수)
print ( y_train.shape) # (60000,)
print ( x_test.shape)  # (10000, 28, 28)
print ( y_test.shape)  # (10000,)

# 2.1  28x28 의 shape 를 1 x 784 로 변경합니다.

x_train = x_train.reshape(60000,28*28)
x_test  = x_test.reshape(10000, 28*28)                                45분까지 쉬세요 ~~

# 2.2 정답 데이터를 준비합니다. (p98 원핫인코딩을 해야합니다.)
 
from  tensorflow.keras.utils import  to_categorical

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)
print ( y_train.shape)  # (60000, 10)

"""
원핫인코딩이란 (onehot encoding) ?  

숫자 7을  다음과 같이 [ 0, 0, 0, 0, 0, 0, 0, 1, 0, 0 ] 만드는 것을 뜻합니다.
즉 리스트의 7번째 인덱스만 1이고 나머지는 0으로 구성하는것을 말합니다.  
예:
from  tensorflow.keras.utils  import  to_categorical

print( to_categorical(7,num_classes=10) ) 

[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]

print( to_categorical([7,4,3,1,9], num_classes=10 ) ) 

[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]
"""

# 3. 모델을 구성합니다.

#그림: https://cafe.daum.net/oracleoracle/Shyl/183

from  tensorflow.keras.models  import  Sequential
from  tensorflow.keras.layers    import  Dense

model = Sequential()
model.add(Dense(128, activation='sigmoid', input_shape=(784, ) ) ) # 은닉1층
model.add(Dense( 10, activation='softmax') ) 

# 4. 모델을 설정합니다. (경사하강법과 오차함수를 정의해줍니다. 4장에서 배웁니다)

model.compile(optimizer='adam',  # 경사하강법 
                     loss='categorical_crossentropy',  #오차함수
                     metrics=['acc'] )  # 학습과정에서 정확도를 보려고 지정

# 5. 모델을 훈련 시킵니다.

model.fit( x_train, y_train, epochs=30, batch_size=100)

#model.fit( 훈련데이터, 정답, 에폭수, 배치사이즈) 
# 에폭수 :  학습횟수 (책을 몇번 볼건지)
# 배치사이즈:  한번에 학습할 양 ( 사람은 책을 한번에 한페이지 밖에 못보지만 컴퓨터는 한번에
#                  여러 페이지를 볼 수 있다)

# 6. 모델을 평가합니다. (시험을 봅니다.)

model.evaluate(x_test, y_test) 

[0.16237662732601166,  0.949999988079071]

문제80.  위의 2층 신경망의 정확도를 더 올리기위해서 minmax 정규화를 수행하세요
            (0~1 사이의 숫자로 픽셀값을 변경하는 것입니다.)

 하나의 픽셀이 0~255 사이의 숫자로 되어있습니다.

x_train = x_train/255.0
x_test = x_test/255.0

[0.16237662732601166,  0.949999988079071]  → 정규화 안했을 때 
                             ↓
[0.07464929670095444, 0.9775999784469604] → 정규화 했을 때 

문제81.  활성화 함수를 relu 로 변경하면 정확도가 더 좋아지는지 실험하시오 !

[0.16237662732601166,  0.949999988079071]  → 정규화 안했을 때 
                             ↓
[0.07464929670095444, 0.9775999784469604] → 정규화 했을 때 
                             ↓
[0.0889417752623558,   0.9811999797821045] → 렐루로 변경했을 때  

문제82. 현재 2층 신경망을 3층 신경망으로 변경하면 정확도가 더 좋아지는 실험하시오 !

현재상태:  입력층(784개)---> 은닉1층(128개) ---> 출력층(10개)
변경후  :   입력층(784개)---> 은닉1층(128개) ---> 은닉2층(128개) ---> 출력층(10개)

답:
model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(784, ) ) ) # 은닉1층
model.add(Dense(128, activation='relu') )  # 은닉2층
model.add(Dense( 10, activation='softmax') ) 

[0.12092561274766922, 0.9787999987602234]

오히려 정확도가 더 떨어졌습니다.  층이 깊다고 더 정확도가 높은것은 아닙니다.
사공이 많으면 배가 산으로 가기때문에 뉴런이 많다고 더 좋은 결과가 나오는것은 아닙니다.

현재까지는 2층신경망이 제일 좋은 정확도 였습니다. 

그럼 다시 2층으로 돌려놓으세요 ~~

문제83. (점심시간 문제) 위의 2층 신경망의 loss 와 정확도를 x 축을 에폭수로 두어서 시각화 하시오 !

 시각화된 그림을 첨부해서 올리세요 ~~   즐거운 점심시간 되세요 ~~

# 5. 모델을 훈련 시킵니다.

history=model.fit( x_train, y_train, epochs=30, batch_size=100)

모델이 훈련하는 과정을 history 변수에 담습니다. 

참고 코드:


# 시각화
import matplotlib.pyplot as plt   


# history=model.fit( x_train, y_train, epochs=30, batch_size=100)

his_dict = history.history    #  모델 훈련과정에서 쌓은 오차와 정확도 데이터를 불러온다.
loss = his_dict['loss']  #  훈련과정에서 기록한 30개의 오차를 loss 변수에 담습니다. 

epochs = range(1, len(loss) + 1)  # 1 부터 30 까지의 숫자를 epochs 에 담는다.
fig = plt.figure(figsize = (10, 5))  # 그래프 전체 사이즈를 설정합니다. 

# 훈련 및 검증 손실 그리기
ax1 = fig.add_subplot(1, 2, 1)  #  하나의 화면에 2개의 그래프를 그리는데 첫번째 그래프
ax1.plot(epochs, loss, color = 'blue', label = 'train_loss') # x축 에폭수,y축 loss 로 라인그래프 그림
ax1.set_title('train  loss')  # 그래프 제목
ax1.set_xlabel('epochs')   # 그래프의 x 축 제목
ax1.set_ylabel('loss')    # 그래프의 y 축 제목
ax1.legend() 

acc = his_dict['acc']  #  30개의 정확도 데이터를 acc 변수에 담습니다. 

# 훈련 및 검증 정확도 그리기
ax2 = fig.add_subplot(1, 2, 2)
ax2.plot(epochs, acc, color = 'blue', label = 'train_acc')
ax2.set_title('train acc')
ax2.set_xlabel('epochs')
ax2.set_ylabel('acc')
ax2.legend()

plt.show()

문제84. 오전에 만든 2층 신경망의 테스트 데이터(10000개) 입력해서 예측값 10000 개를
           출력하시오!

# 1. mnist 데이터를 불러옵니다.
import  tensorflow  as  tf
from  tensorflow.keras.datasets.mnist  import  load_data

(x_train, y_train), (x_test, y_test) = load_data(path='mnist.npz') 

# 2.1  28x28 의 shape 를 1 x 784 로 변경합니다.

x_train = x_train.reshape(60000,28*28)
x_test  = x_test.reshape(10000, 28*28)

x_train = x_train/255.0
x_test = x_test/255.0

# 2.2 정답 데이터를 준비합니다. (p98 원핫인코딩을 해야합니다.)
 
from  tensorflow.keras.utils import  to_categorical

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)
print ( y_train.shape)  # (60000, 10)

# 3. 모델을 구성합니다.

#그림: https://cafe.daum.net/oracleoracle/Shyl/183

from  tensorflow.keras.models  import  Sequential
from  tensorflow.keras.layers    import  Dense

model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(784, ) ) ) # 은닉1층
model.add(Dense( 10, activation='softmax') ) 

# 4. 모델을 설정합니다. (경사하강법과 오차함수를 정의해줍니다. 4장에서 배웁니다)

model.compile(optimizer='adam',  # 경사하강법 
                     loss='categorical_crossentropy',  #오차함수
                     metrics=['acc'] )  # 학습과정에서 정확도를 보려고 지정

# 5. 모델을 훈련 시킵니다.

model.fit( x_train, y_train, epochs=30, batch_size=100)

#model.fit( 훈련데이터, 정답, 에폭수, 배치사이즈) 
# 에폭수 :  학습횟수 (책을 몇번 볼건지)
# 배치사이즈:  한번에 학습할 양 ( 사람은 책을 한번에 한페이지 밖에 못보지만 컴퓨터는 한번에
#                  여러 페이지를 볼 수 있다)

# 6. 모델을 평가합니다. (시험을 봅니다.)

model.eval‎uate(x_test, y_test) 

[0.09304942190647125, 0.9794999957084656]

# 7. 모델에 테스트 데이터 10000장을 입력하고 예측합니다. 

result= model.predict(x_test)
print(result.shape)

문제85. 위에서 출력된 확률벡터 10000 개에서 가장 큰 원소의 인덱스 번호가 출력되게
           하여 10000개의 숫자로 출력되게하시오 !

result= model.predict(x_test)
print( np.argmax(result, axis=1).shape )  # (10000,)

문제86.  진짜 정답인 y_test 와 위에 예측값과 비교해서 정확도를 출력하시오 

result= model.predict(x_test)
result2 = np.argmax(result, axis=1)

y_test2 = np.argmax(y_test, axis=1)

sum(y_test2==result2) / 10000   # 0.9795

[0.09304942190647125, 0.9794999957084656]

설명:  model.evaluate 로 출력한 결과와 똑같은 정확도가 출력이 되었습니다. 

문제87.  테스트 데이터 10000장중에 첫번째 테스트 데이터 1개를 신경망에 입력하고 
            예측 숫자를 출력하시오 !

print(x_test.shape)   # (10000, 784)
print(x_test[0].shape)  # (784,)  ----> ( 1, 784)  이렇게 변경해야합니다.

print( x_test[0].reshape(1,784).shape )  # (1, 784)

# 숫자하나만 예측
result= model.predict(x_test[0].reshape(1,784) )
result2 = np.argmax(result, axis=1)
print(result2)  # [7]

# 위의 숫자의 정답을 확인 
y_test2 = np.argmax(y_test[0])  # 1개만 볼때는 axis=1 사용안해도 됩니다. 
print(y_test2)  # 7

문제88.  테스트 데이터 10000장중에 10000번째 숫자를 예측하고 정답과 비교하시오 !

print(x_test.shape)   # (10000, 784)
print(x_test[9999].shape)  # (784,)  ----> ( 1, 784)  이렇게 변경해야합니다.

print( x_test[9999].reshape(1,784).shape )  # (1, 784)

# 숫자하나만 예측
result= model.predict(x_test[9999].reshape(1,784) )
result2 = np.argmax(result, axis=1)
print(result2)  # [7]

# 위의 숫자의 정답을 확인 
y_test2 = np.argmax(y_test[9999])  # 1개만 볼때는 axis=1 사용안해도 됩니다. 
print(y_test2)  # 7

문제89. 필기체 숫자를 하나 직접 만드시오 ! (바탕이 검정색, 글씨는 하얀색)
 
 답글로 올려주세요 ~~

 신호 보냈습니다. ~~   47분까지 쉬세요 ~~


■ 오전에 만든 필기체 분류 신경망 모델을 저장하는 방법 

 우리가 어제는 가중치와 바이어스를 pickle 파일로 저장을 했는데
 텐써플로우는 모델을 통채로 저장을 할 수가 있습니다.

오전에 만들었던 2층 신경망 코드를 가져옵니다. (딥러닝 목차 13번)

# 1. mnist 데이터를 불러옵니다.
import  tensorflow  as  tf
from  tensorflow.keras.datasets.mnist  import  load_data

(x_train, y_train), (x_test, y_test) = load_data(path='mnist.npz') 

# 2.1  28x28 의 shape 를 1 x 784 로 변경합니다.

x_train = x_train.reshape(60000,28*28)
x_test  = x_test.reshape(10000, 28*28)

x_train = x_train/255.0
x_test = x_test/255.0

# 2.2 정답 데이터를 준비합니다. (p98 원핫인코딩을 해야합니다.)
 
from  tensorflow.keras.utils import  to_categorical

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)
print ( y_train.shape)  # (60000, 10)

# 3. 모델을 구성합니다.

#그림: https://cafe.daum.net/oracleoracle/Shyl/183

from  tensorflow.keras.models  import  Sequential
from  tensorflow.keras.layers    import  Dense

model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(784, ) ) ) # 은닉1층
model.add(Dense( 10, activation='softmax') ) 

# 4. 모델을 설정합니다. (경사하강법과 오차함수를 정의해줍니다. 4장에서 배웁니다)

model.compile(optimizer='adam',  # 경사하강법 
                     loss='categorical_crossentropy',  #오차함수
                     metrics=['acc'] )  # 학습과정에서 정확도를 보려고 지정

# 5. 모델을 훈련 시킵니다.

model.fit( x_train, y_train, epochs=30, batch_size=100)

#model.fit( 훈련데이터, 정답, 에폭수, 배치사이즈) 
# 에폭수 :  학습횟수 (책을 몇번 볼건지)
# 배치사이즈:  한번에 학습할 양 ( 사람은 책을 한번에 한페이지 밖에 못보지만 컴퓨터는 한번에
#                  여러 페이지를 볼 수 있다)

# 6. 모델을 평가합니다. (시험을 봅니다.)

model.eval‎uate(x_test, y_test) 

# 7. 모델을 저장합니다.

model.save('d:\\data\\my_model.h5')

▩ 모델 불러오기 

문법:
from  tensorflow.keras.models  import  load_model

new_model = load_model('d:\\data\\my_model.h5')

new_model.evaluate( x_test, y_test )

[0.08754049986600876 ,   0.9811999797821045]

문제90.  지금 불러온 모델에 테스트 이미지 한장을 입력하고 예측값을 출력하시오!

result = new_model.predict(x_test[0].reshape(1,784) )
print( np.argmax(result) )

print(np.argmax(y_test[0]))   # 7

▩ 설현사진 한장을 필기체 인식 신경망에 입력하면 뭐가 출력되는지 실험하기

 1. 설현 사진을 숫자로 변경해야 합니다.
 2. 설현 사진을 28x28 사이즈로 변경해야 합니다.
 3. 설현 사진을 흑백처리해야합니다. 
 4. 흑백처리한 사진 28x28 을 1x784 로 변경합니다. 

실험순서:
 1. 설현 사진을 숫자로 변경해야 합니다.

  아나콘다 프롬프트창으로 열고  snowdeer_env1 환경을 actviate 시킵니다.

(base) C:\Users\YYS>conda activate snowdeer_env1

  opencv-python 을 설치합니다. 

(snowdeer_env1) C:\Users\YYS>pip install opencv-python
 
 d 드라이브 밑에 data100 폴더를 만들고 거기에 설현사진(a.jpg) 를 넣습니다.

 snowdeer_env1 의 주피터 노트북에서 아래의 코딩으로 설현사진을 숫자로 변경합니다.

import  cv2   #  이미지 데이터 전처리하는 모듈
import  os    #   os 의 파일들을 인식하기 위해서 필요한 모듈

path="d:\\data100"      # 설현사진이 있는 위치를 path 변수에 넣습니다. 
file_list = os.listdir(path)  # d\\data100 폴더 안에 있는 파일 리스트를 file_list 변수에 입력
for  k  in  file_list:          # 여러개의 파일이 있을거라 가정하고 for loop문으로 구현
    img = cv2.imread(path +  '\\' + k)  #  이미지를 숫자로 변경합니다.
print(img)  
print(img.shape) # (165, 201, 3)  ,  ( 가로 픽셀사이즈, 세로 픽셀 사이즈, 색조)

2. 설현 사진을 28x28 사이즈로 변경해야 합니다.

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

for k in file_list:                      # data100 폴더의 파일을 하나씩 불러옵니다. 
    img = cv2.imread(path + '\\' + k)  # 그 파일을 숫자로 변경합니다. 
    resize_img = cv2.resize(img, (28 , 28), interpolation=cv2.INTER_CUBIC)  # 가로 28, 세로 28로 사이즈 변경
    cv2.imwrite('d:\\resize100\\' + k, resize_img)    # d 드라이브 밑에 resize100 폴더에 저장합니다.
    
plt.imshow(resize_img)
plt.show()    


 3. 설현 사진을 흑백처리해야합니다. 

j= 'd:\\resize100\\a.jpg'

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

def rgb2gray(rgb):   # 어떤 컬러 사진이든 제대로 흑백 사진으로 나오게 하기 위해 사용하는 함수
    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])

img = mpimg.imread(j)  # 이미지를 불러와서 숫자로 변경합니다. 
gray = rgb2gray(img)

plt.imshow(gray, cmap = plt.get_cmap('gray'))  # 진짜 흑백 사진으로 변경하는 코드
plt.show()

4. 위에서 출력된 흑백사진을 b.jpb 로 저장합니다.

cv2.imwrite('d:\\data100\\b.jpg',gray)

5. b.jpg 흑백처리한 사진을 불러와서 사이즈 28x28 을 1x784 로 변경합니다. 

import  matplotlib.image  as  mpimg

k="d:\\data100\\b.jpg"

img2 = mpimg.imread(k)
img2.shape  # (28, 28)

x = img2.reshape(1,784)
print(x.shape)  # (1, 784)

6. 오전에 만든 필기체 분류 신경망에 위의 설현사진(x) 을 입력하고 예측하시오

from  tensorflow.keras.models  import  load_model
new_model = load_model('d:\\data\\my_model.h5')
result = new_model.predict(x)
print( np.argmax(result) )  # 2

문제91.  우리가 직접 쓴 필기체 숫자이미지를 다음과 같이 흑백 처리하고 1x784 로 변경합니다. 

 1. 필기체 사진을 숫자로 변경해야 합니다.
 2. 필기체 사진을 28x28 사이즈로 변경해야 합니다.
 3. 필기체 사진을 흑백처리해야합니다. 
 4. 흑백처리한 사진 28x28 을 1x784 로 변경합니다. 

답:
import  cv2   #  이미지 데이터 전처리하는 모듈
import  os    #   os 의 파일들을 인식하기 위해서 필요한 모듈

path="d:\\data100"      # 설현사진이 있는 위치를 path 변수에 넣습니다. 
file_list = os.listdir(path)  # d\\data100 폴더 안에 있는 파일 리스트를 file_list 변수에 입력
for  k  in  file_list:          # 여러개의 파일이 있을거라 가정하고 for loop문으로 구현
    img = cv2.imread(path +  '\\' + k)  #  이미지를 숫자로 변경합니다.
print(img)  
print(img.shape) # (112, 113, 3)  ,  ( 가로 픽셀사이즈, 세로 픽셀 사이즈, 색조)

2. 필기체 사진을 28x28 사이즈로 변경해야 합니다.

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

for k in file_list:                      # data100 폴더의 파일을 하나씩 불러옵니다. 
    img = cv2.imread(path + '\\' + k)  # 그 파일을 숫자로 변경합니다. 
    resize_img = cv2.resize(img, (28 , 28), interpolation=cv2.INTER_CUBIC)  # 가로 28, 세로 28로 사이즈 변경
    cv2.imwrite('d:\\resize100\\' + k, resize_img)    # d 드라이브 밑에 resize100 폴더에 저장합니다.
    
plt.imshow(resize_img)
plt.show()    


 3. 필기체 사진을 흑백처리해야합니다. 

j= 'd:\\resize100\\seven.jpg'

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

def rgb2gray(rgb):   # 어떤 컬러 사진이든 제대로 흑백 사진으로 나오게 하기 위해 사용하는 함수
    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])

img = mpimg.imread(j)  # 이미지를 불러와서 숫자로 변경합니다. 
gray = rgb2gray(img)

plt.imshow(gray, cmap = plt.get_cmap('gray'))  # 진짜 흑백 사진으로 변경하는 코드
plt.show()

4. 위에서 출력된 흑백사진을 b.jpb 로 저장합니다.

cv2.imwrite('d:\\data100\\seven.jpg',gray)

5. b.jpg 흑백처리한 사진을 불러와서 사이즈 28x28 을 1x784 로 변경합니다. 

import  matplotlib.image  as  mpimg

k="d:\\data100\\seven.jpg"

img2 = mpimg.imread(k)
img2.shape  # (28, 28)

x = img2.reshape(1,784)
print(x.shape)  # (1, 784)

6. 오전에 만든 필기체 분류 신경망에 위의 설현사진(x) 을 입력하고 예측하시오

from  tensorflow.keras.models  import  load_model
new_model = load_model('d:\\data\\my_model.h5')
result = new_model.predict(x)
print( np.argmax(result) )                                                                            

문제92.( 오늘의 마지막 문제 ) 동민, 태진, 명규, 석영, 세현, 민석이가 올린 필기체 데이터를 
           내려받아  흑백처리하고 1x784로 사이즈를 변경한후 예측한 결과를 코드와 함께 
            올리시오 ~~  

공지: 1. 머신러닝 ppt 제출은 다음주 수요일에 ncs 사이트에 제출
        2. 하둡과 스파크 ncs 시험 다음주 목요일 4시 ( 몽고디비(10문제), 리눅스 기본 명령어(10문제) )

■ 어제 배웠던 복습 

1장:  numpy 사용법
2장: 퍼셉트론 ( 신경망의 뉴런 세포 하나를 구현 )
3장: 2층 신경망 구현 

   밑바닥부터 시작하는 딥러닝(이론) ------------> 텐써플로우 2.0 (실습)
 
4장.  오차함수 (오늘 배울 내용)

                    입력층 ------------->  은닉1층 --------------> 출력층(2층)
                    (784개)                     (50개)

                                                   w1              output         w2  
한장씩 학습:           ( 1, 784 ) ◎  ( 784, 50 ) ---> ( 1, 50)  ◎  (50,10) ---> (1, 10) 


배치단위 학습:        (100,784)  ◎ ( 784, 50 ) ---> ( 100, 50 ) ◎ ( 50, 10) ---> ( 100 , 10 )

         np.argmax(result, axis=1)


문제93.  다음의 신경망의 그림을 아래와 같이 식으로 쓰시오

식 예:  (100,784)  ◎ ( 784, 50 ) ---> ( 100, 50 ) ◎ ( 50, 10) ---> ( 100 , 10 )

        입력층   ------>  은닉1층 -----> 은닉2층 ------> 출력층
        (784개)               (100개)           (50개)             (10개)

  배치단위는 100개씩 처리합니다.

답:
 입력층          w1              output1      w2              output2     w3             output3
(100,784) @ (784,100) ---> (100,100) @(100,50) ---> (100,50) @(50,10) ---> (100,10)





배치처리로 신경망을 학습 시키는 이유?  

 신경망이 학습 할때는 데이터 전체를 한번에 다 학습을 할 수는 없고 조금씩 학습해서
 전체를 다 학습해야하는데 이것을 배치처리라고 합니다.
 이미지를 한장씩 학습하지 않고 여러장씩을 한번에 학습하는것이 더 학습 속도가 빠르기 때문에
 배치 처리를 합니다.


예:  model.fit( x_train, y_train, epochs=30, batch_size=100) 

배치처리의 이점은 ?  p103 아래쪽

■ 4장.  신경망 학습 (p107)

 4장의 주요 내용 ?  신경망을 학습 시키기 위해서 알아야하는 내용 3가지 

  1. 오차함수 :  신경망이 뭘 잘못하고 있는지 깨닫게 해주는 함수 
  2. 미니배치 :  학습할 때 데이터를 한꺼번에 신경망에 넣는게 아니라 몇백장씩 조금씩
                     신경망에 넣고 학습 시키는것을 말합니다. 
  3. 수치미분 :  오차함수의 기울기를 구해서 기울기만큼 가중치를 갱신 할때 필요

▩ 오차함수   p111

 앞에서 배웠던 신경망에 들어가는 함수?   시그모이드 함수, 렐루함수, 소프트맥스 함수 

 오차함수란?  예상값과 실제값과의 오차를 신경망에 역전파 시켜주기 위해서 필요한 함수

 신경망이 뭘 잘못하고 있는지 깨닫게 해주는 함수 

 오차함수의 종류 2가지 ?

  1. 평균 제곱 오차함수(mean squared error)   :  회귀분석할 때 사용
  2. 교차 엔트로피 오차함수(cross entropy error)   : 분류문제를 풀때 사용 

그림:  https://cafe.daum.net/oracleoracle/Shyl/262

문제94. 아래의 단층 신경망의  행렬의 내적을 구현해서 k 행렬을 출력하시오 !

그림:  https://cafe.daum.net/oracleoracle/Shyl/262

답:
import numpy as np

a = np.array([0.6, 0.9]).reshape(1,2)
b = np.array([0.4, 0.7, 0.9, 0.2, 0.3, 0.1]).reshape(2,3)
k = np.dot(a,b)
print(k)  # [[0.42 0.69 0.63]]

문제95. 위의 k 행렬의 값을 softmax 함수에 통과 시켜서 결과를 y 에 담고 출력하시오 !

def  softmax(a):
    C = np.max(a)
    minus = a - C 
    exp_a = np.exp(minus) 
    sum_exp_a = np.sum(exp_a)
    y = exp_a / sum_exp_a
    return   y

답:  정승재

import numpy as np

x = np.array([0.6,0.9]).reshape(1,2)
w1 = np.array([0.4,0.7,0.9,0.2,0.3,0.1]).reshape(2,3)

k = np.dot(x,w1)

def softmax(a):
    C = np.max(a)
    minus = a - C
    np_exp = np.exp(minus) # 분자 수학식
    sum_exp = np.sum(np_exp) # 분모 수학식
    y = np_exp / sum_exp
    return y

y = softmax(k)
print(y)  # [[0.28219551 0.36966608 0.34813841]]
                 설현            수지            아이린 

설명:  실제 정답은 아이린 [ 0,  0, 1 ]  인데 수지로 예측하고 있는 결과가 출력되고 있으므로
         오차를 신경망에 전달(오차 역전파)해 줘야합니다. 

문제96.  책 115페이지 맨위에 나오는 교차엔트로피 함수를 생성하시오 ! 식4.2

답:
def  cross_entropy_error(y, t):
    delta = 1e-7  # 0.00000001   # 0 에 가까운 아주 작은수 
    return  -np.sum(t*np.log(y+delta) )   #  아주 작은수를 더한 이유는? 
                                                     #   y 가 0 이되면 마이너스 무한대가 되기 때문에
                                                     # 마이너스 무한대 값이 출력되지 않도록 아주 작은값을
                                                     # 더했습니다. 

문제97.  아래의 정답 행렬인 t 와  문제95번에서 출력된 확률백터 y 와 의 오차를 출력하시오 !

t = np.array([ 0, 0, 1]).reshape(1,3)

답:
def cross_entropy_error(y,t):
    delta = 1e-7     
    return -np.sum(t*np.log(y+delta))


t = np.array([0,0,1]).reshape(1,3)
cross_entropy_error(y,t)  # 1.0551548687114343

문제98. 위의 오차함수를 텐써 플로우 2.0 에서는 어떻게 사용하고 있는가?

# 3. 모델을 구성합니다.
from  tensorflow.keras.models  import  Sequential
from  tensorflow.keras.layers    import  Dense

model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(784, ) ) ) # 은닉1층
model.add(Dense( 10, activation='softmax') ) 

# 4. 모델을 설정합니다. (경사하강법과 오차함수를 정의해줍니다. 4장에서 배웁니다)

model.compile(optimizer='adam',  # 경사하강법 
                     loss='categorical_crossentropy',  #오차함수
                     metrics=['acc'] )  # 학습과정에서 정확도를 보려고 지정

설명:  이진분류: binary_crossentropy  , 다중분류: categorical_corssentropy

※ 신경망으로 풀고자 하는 문제  

 1. 분류 --->  교차엔트로피 함수
 2. 회귀 --->  평균제곱오차 함수 

▩ 평균제곱 오차 함수  p112

  식 4.1 

문제99.  식 4.1 을 보고 평균제곱오차함수를 생성하시오 ( p 113 )

답:
def  mean_squared_error(y,t):
    return   0.5 * np.sum((y-t)**2) 

y = np.array( [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0] )  # 예측 숫자  2 
t = np.array( [ 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 ] )        # 정답숫자 2

print ( mean_squared_error( y, t )  )  # 0.09

문제100. 숫자 7로 예측한 결과와 정답 숫자 2와의 오차를 구하시오 !

y2 = np.array( [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0] )  # 예측 숫자  7
t = np.array( [ 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 ] )        # 정답숫자 2

print ( mean_squared_error( y2, t )  )  # 0.5975

문제101. 위의 평균제곱 오차함수를 텐써 플로우에서는 어떻게 사용하는가?

model.compile(optimizer='adam',  # 경사하강법 
                     loss='mse',  #오차함수
                     metrics=['acc'] )  # 학습과정에서 정확도를 보려고 지정

정리하면 우리가 신경망을 통해서 예측하고자 하는 문제에 따라서 오차함수를 다르게 사용해야합니다

1. 분류 :   loss='categorical_crossentropy'
2. 수치예측 :   loss='mse'

▩  보스톤 하우징 집값을 예측하는 신경망 만들기 (수치예측)

1. 보스톤 하우징 데이터를 불러옵니다.

from  tensorflow.keras.datasets.boston_housing  import  load_data

(x_train, y_train), (x_test, y_test) = load_data(path='boston_housing.npz',
                                                          test_split=0.2, seed=777 ) 
print(x_train.shape) # (404, 13)
print(y_train.shape) # (404. 3 ) 
print(x_test.shape)  # (102, 13)
print(y_test.shape)  # (102,)

#2. 모델 생성하기 
from  tensorflow.keras.models  import  Sequential
from  tensorflow.keras.layers  import  Dense

model = Sequential()
model.add( Dense( 64, activation='relu', input_shape=(13, ) ) ) 
model.add( Dense( 32, activation='relu')  )
model.add( Dense(1) )  # 출력층에는 분류가 아니라 softmax 함수가 필요없습니다. 
                                # 예측되는 집값이 그대로 출력되면 됩니다. 

#3. 모델 설정하기

model.compile(optimizer='adam', loss='mse', metrics=['mae'] ) # mae 는 오차입니다. 

#4. 모델 훈련하기 

model.fit( x_train, y_train, epochs=300 )

#5. 모델 평가하기 

model.evaluate( x_test, y_test) 

[15.31570053100586,   2.927138090133667]
     ↑                                 ↑
  loss                             mae  (평균절대오차)

설명: mse 는 평균제곱 오차이고 mae 는 평균절대오차입니다.
        mse 는 제곱을 해주는것이고 mae 는 절대값을 구하는것입니다. 

 평균제곱오차는 회귀에서 자주 사용되는 손실함수입니다.
  일반적인 회귀지표는 평균절대오차(mae) 입니다. 

문제102.(점심시간 문제)  위의 신경망의 성능을 높이시오 !

 데이터 표준화를 하면 성능이 더 좋아지는지 확인하시오 !

표준화 코드 :

mean = np.mean( x_train, axis=0)
std  = np.std( x_train, axis=0)

x_train = (x_train - mean) / std
x_test  = (x_test - mean) / std

결과를 올려주세요 ~~

 
표준화 전 : [18.505050659179688, 3.267110586166382]
표준화 후 : [7.479121208190918, 1.9675555229187012]

※ 설명 :  분류를 할때는 minmax 정규화를 사용하고 수치예측을 할때는 표준화를 해서 성능을 
             높입니다. 

※ 수치를 예측하는 신경망의 성능을 높이는 방법 

  1. 표준화
  2. K-폴드 교차검정

▩ k-폴드 교차검정으로 성능 높이기 

#1. 보스톤 하우징 데이터를 불러온다.
from tensorflow.keras.datasets.boston_housing import load_data
(x_train,y_train),(x_test,y_test) = load_data(path='boston_housing.npz', test_split=0.2, seed=777)

mean = np.mean(x_train, axis=0)
std = np.std(x_train, axis=0)

x_train=(x_train-mean)/std
x_test=(x_test-mean)/std

# 2. K-폴드 교차검정 진행 

from  sklearn.model_selection  import  KFold
k=3
kfold = KFold( n_splits=k,  random_state=777, shuffle=True)

#2. 모델생성하기
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

def  get_model():
    model=Sequential(random_state=777)
    model.add(Dense(64, activation='relu', input_shape=(13,)))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(1)) # 출력층에는 분류가 아니라 softmax 함수가 필요없다. 예측되는 집값이 그대로 출력되면 된다.
    #3. 모델 설정하기
    model.compile(optimizer='adam', loss='mse', metrics=['mae']) # mae는 오차이다.
    return  model 

#4. 모델 훈련하기
mae_list =[]  # k개의 mae 값을 담을 비어있는 리스트를 생성한다. 

for  train_index,  val_index  in  kfold.split(x_train): # 훈련데이터와 검정 데이터를 위한 행번호를 
                                                                  # 각각 train_index 와 val_index 에 담는다.
   
    x_train_fold, x_val_fold = x_train[ train_index ],  x_train[ val_index ]  #  훈련 데이터와 검정 데이터
    y_train_fold, y_val_fold = y_train[ train_index ],  y_train[ val_index ]  #  훈련 정답과 검정 정답

    model = get_model()  # 모델을 불러옵니다. 

    model.fit(x_train_fold, y_train_fold, epochs=300,  validation_data = ( x_val_fold, y_val_fold) )   

    #5. 모델 평가하기
    _ , test_mae = model.eval‎uate(x_test, y_test)
    mae_list.append(test_mae)

print(mae_list) # [2.306687116622925, 2.10488224029541, 2.3299472332000732]

2.1938517093658447

 [2.306687116622925, 2.10488224029541, 2.3299472332000732]

위의 3개의 mae 값이 서로 다른 이유는 학습 및 검증 데이터가 서로 다르기 때문입니다.
그리고 k-hold 교차검정으로 얻어낸 최종 mae 값을 출력하려면 위의 3개의 값의 평균값을 출력하면
됩니다. 

표준화 전 : 
[20.877195358276367, 3.5586750507354736]

표준화 후 :
[9.673251152038574, 2.1938517093658447]

k 값을 3으로 했을때의 mae 값 :
print( np.mean(mae_list)  )  # 2.247172196706136

k 값을 10으로 했을때의 mae 값:
print( np.mean(mae_list)  )  # 2.0674376487731934

설명: 검증 데이터 사용이 위와 같이 수치예측할 때만 필요하고 분류할 때는 필요하지 않는가?

  답 :   분류할 때도 필요합니다. 

분류할 때는 뭘 위해서 필요한건가 ?

   " 오버피팅이 과도하게 발생하는지 확인하기 위해 필요합니다. "

아래와 같이 신경망의 층과 뉴런의 갯수를 너무 많이 주게 되면 훈련 데이터에 대한 정확도는
높아질 수 있으나 오버피팅이 발생할 수 있습니다. 

model=Sequential()
model.add(Dense(64, activation='relu', input_shape=(13,)))
model.add(Dense(32, activation='relu')

▩ 분류하는 신경망에서 검정 데이터 사용하기 

코드: https://cafe.daum.net/oracleoracle/Shyl/210 (목차 13번)

# 1. mnist 데이터를 불러옵니다.
import  tensorflow  as  tf
from  tensorflow.keras.datasets.mnist  import  load_data

(x_train, y_train), (x_test, y_test) = load_data(path='mnist.npz') 

# 2.1  28x28 의 shape 를 1 x 784 로 변경합니다.

x_train = x_train.reshape(60000,28*28)
x_test  = x_test.reshape(10000, 28*28)

x_train = x_train/255.0
x_test = x_test/255.0

# 2.2 정답 데이터를 준비합니다. (p98 원핫인코딩을 해야합니다.)
 
from  tensorflow.keras.utils import  to_categorical

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)
print ( y_train.shape)  # (60000, 10)

# 2.3  검증 데이터를 생성합니다. (60000개의 훈련 데이터를 7:3대으로 나눠서 7은 훈련 데이터
# 3은 검증 데이터로 만듭니다. 

from  sklearn.model_selection   import  train_test_split

x_train, x_val, y_train, y_val  = train_test_split( x_train, y_train, test_size=0.3, random_state=777)
#print(x_train.shape)  # (42000, 784)
#print(x_val.shape)    # (18000, 784)
#print(y_train.shape)  # (42000, 10)
#print(y_val.shape)    # (18000, 10)

# 3. 모델을 구성합니다.

from  tensorflow.keras.models  import  Sequential
from  tensorflow.keras.layers    import  Dense

model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(784, ) ) ) # 은닉1층
model.add(Dense( 10, activation='softmax') ) 

# 4. 모델을 설정합니다. (경사하강법과 오차함수를 정의해줍니다. 4장에서 배웁니다)

model.compile(optimizer='adam',  # 경사하강법 
                     loss='categorical_crossentropy',  #오차함수
                     metrics=['acc'] )  # 학습과정에서 정확도를 보려고 지정

# 5. 모델을 훈련 시킵니다.

model.fit( x_train, y_train, epochs=30, batch_size=100, validation_data=(x_val, y_val) )

#model.fit( 훈련데이터, 정답, 에폭수, 배치사이즈) 
# 에폭수 :  학습횟수 (책을 몇번 볼건지)
# 배치사이즈:  한번에 학습할 양 ( 사람은 책을 한번에 한페이지 밖에 못보지만 컴퓨터는 한번에
#                  여러 페이지를 볼 수 있다)

# 6. 모델을 평가합니다. (시험을 봅니다.)

model.evaluate(x_test, y_test) 

▩ 위에서 출력된 훈련 데이터의 정확도와 검증 데이터의 정확도를 같이 시각화하기 

history = model.fit( x_train, y_train, epochs=30, batch_size=100, validation_data=(x_val, y_val) )

 훈련 데이터의 오차와  정확도 출력
 검증 데이터의 오차와 정확도 출력 

https://cafe.daum.net/oracleoracle/Shyl/295  <-- 검정 데이터와 같이 시각화 코드 


# 시각화
import matplotlib.pyplot as plt

his_dict = history.history  # historoy 에 정확도와 오차에 대한 값들이 저장되어있습니다. 
loss = his_dict['loss']
val_loss = his_dict['val_loss'] # 검증 데이터가 있는 경우 ‘val_’ 수식어가 붙습니다.

epochs = range(1, len(loss) + 1)
fig = plt.figure(figsize = (10, 5))

# 훈련 및 검증 손실 그리기
ax1 = fig.add_subplot(1, 2, 1)
ax1.plot(epochs, loss, color = 'blue', label = 'train_loss')
ax1.plot(epochs, val_loss, color = 'orange', label = 'val_loss')
ax1.set_title('train and val loss')
ax1.set_xlabel('epochs')
ax1.set_ylabel('loss')
ax1.legend()

acc = his_dict['acc']
val_acc = his_dict['val_acc']

# 훈련 및 검증 정확도 그리기
ax2 = fig.add_subplot(1, 2, 2)
ax2.plot(epochs, acc, color = 'blue', label = 'train_accuracy')
ax2.plot(epochs, val_acc, color = 'orange', label = 'val_accuracy')
ax2.set_title('train and val accuracy')
ax2.set_xlabel('epochs')
ax2.set_ylabel('accuracy')
ax2.legend()

plt.show()

문제103. 기존층보다 층과 뉴런의 갯수를 늘려서 훈련을 시키면 정확도가 몇 에폭만에 100%로 
            나오는지 확인하고 그리고 오버피팅 더 많이 발생했는지 실험하시오 !

-- 기존층 (2층)
model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(784, ) ) ) # 은닉1층
model.add(Dense( 10, activation='softmax') )  # 출력층(2층)

[0.1008242517709732, 0.9782000184059143]

-- 변경된 층(4층)
model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(784, ) ) ) # 은닉1층
model.add(Dense(128, activation='relu') )  # 2층
model.add(Dense(128, activation='relu') )  # 3층 
model.add(Dense(32, activation='relu') )  # 4층 
model.add(Dense( 10, activation='softmax') )  # 출력층(5층)

[0.13875405490398407, 0.9757999777793884]

실험결과:  기존층 3층과 변경된층 5층간의 오차와 정확도의 큰 차이는 보이지 않습니다.
               변경된층이 오버피팅이 더 일어났다고 말하기도 어렵습니다.
               이런 결과가 나온 이유는 mnist 가 자체가 좋은 데이터여서 큰 차이가 보이지 
               않는것으로 보입니다.  다른 데이터로 다시 테스트 하겠습니다. 

▩ fashion  mnist 데이터셋 소개 

from tensorflow.keras.datasets.fashion_mnist import load_data

(x_train, y_train), (x_test, y_test) = load_data()

target_dict = {
 0: 'T-shirt/top',
 1: 'Trouser',
 2: 'Pullover',
 3: 'Dress',
 4: 'Coat',
 5: 'Sandal',
 6: 'Shirt',
 7: 'Sneaker',
 8: 'Bag',
 9: 'Ankle boot',
}

plt.figure(figsize=(10,10))

for i in range(0,20):
    plt.subplot(5,5, i+1)
    plt.imshow(x_train[i] )
    plt.title( target_dict[(y_train[i]) ])
    plt.xticks([])
    plt.yticks([])

훈련데이터 60000개, 테스트 데이터 10000 개, shape 로 28x28 로 mnist 와 같습니다. 
mnist 와 차이가 있다면 mnist 는 필기체 숫자 10개인데 
fashion mnist 는 옷과 신발같은 의류 이미지입니다.

■  실험제목:  "층이 깊어지면 오버피팅이 더 발생하는가? "

첫번째 모델 :  3층 신경망
두번째 모델:   4층 신경망

▩  두개의 모델을 생성하기 위한 공통 코드 부분

# 1. 데이터를 불러옵니다. 
from tensorflow.keras.datasets.fashion_mnist import load_data
(x_train, y_train), (x_test, y_test) = load_data()

# 2. 정규화를 합니다.
x_train = x_train / 255
x_test  = x_test / 255 

# 3. 정답 데이터를 구성합니다.
from tensorflow.keras.utils  import  to_categorical

y_train = to_categorical(y_train) # 원핫 인코딩
y_test  = to_categorical(y_test)  # 원핫 인코딩

# 4. 훈련 데이터를 훈련데이터와 검정 데이터로 나눕니다. 
from  sklearn.model_selection  import  train_test_split 

x_train, x_val,  y_train, y_val  =  train_test_split( x_train, y_train, test_size=0.3,  random_state=777) 

#▩ 첫번째 모델 구성하기 (3층 신경망)
from  tensorflow.keras.models  import  Sequential
from  tensorflow.keras.layers    import  Dense, Flatten

model1 = Sequential()

model1.add(Flatten(input_shape=(28,28) ) )   # (28, 28) ---> (1, 28*28)  로 변환하는 코드, 0층
model1.add(Dense(64, activation='relu') )  #  64개의 뉴런을 가지는 은닉1층 
model1.add(Dense(32, activation='relu') )  #  32개의 뉴런을 가지는 은닉2층 
model1.add(Dense(10, activation='softmax') )   # 10개의 뉴런을 가지는 출력층 

#▩ 첫번째 모델에 대한 학습과정을 설정하고 학습 시키기 

model1.compile( optimizer='adam',        #  옵티마이져 : adam
                       loss='categorical_crossentropy',  # 오차함수 다중분류이므로 categorical_crossentropy
                        metrics=['acc'] )  # 모니터링팔 평가지표: 정확도 

model1_history = model1.fit( x_train, y_train, 
                                        epochs=30,
                                        batch_size = 128,
                                        validation_data=(x_val, y_val) ) 

#설명: model1_history 에 훈련 데이터의 정확도값과 오차값과 검증 데이터의 정확도값과 오차값이
#       쌓입니다. 

#▩ 두번째 모델 구성하기 (4층 신경망)
from  tensorflow.keras.models  import  Sequential
from  tensorflow.keras.layers    import  Dense, Flatten

model2 = Sequential()

model2.add(Flatten(input_shape=(28,28) ) )   # (28, 28) ---> (1, 28*28)  로 변환하는 코드, 0층
model2.add(Dense(128, activation='relu') )  #  128개의 뉴런을 가지는 은닉1층 
model2.add(Dense(64, activation='relu') )  #  64개의 뉴런을 가지는 은닉2층 
model2.add(Dense(32, activation='relu') )  #  32개의 뉴런을 가지는 은닉3층 
model2.add(Dense(10, activation='softmax') )   # 10개의 뉴런을 가지는 출력층(4층) 

#▩ 두번째 모델의 학습과정을 설정하고 학습 시키기 

model2.compile( optimizer='adam',        #  옵티마이져 : adam
                       loss='categorical_crossentropy',  # 오차함수 다중분류이므로 categorical_crossentropy
                        metrics=['acc'] )  # 모니터링할 평가지표: 정확도 

model2_history = model2.fit( x_train, y_train, 
                                        epochs=30,
                                        batch_size = 128,
                                        validation_data=(x_val, y_val) ) 

#▩  두개의 모델의 학습과정을 같이 시각화 하시오

게시번호 296번호.  두 모델을 같이 시각화하는 함수 

import numpy as np
import matplotlib.pyplot as plt

def draw_loss_acc(history_1, history_2, epochs):
    his_dict_1 = history_1.history
    his_dict_2 = history_2.history
    keys = list(his_dict_1.keys())
    
    epochs = range(1, epochs)
    fig = plt.figure(figsize = (10, 10))
    ax = fig.add_subplot(1, 1, 1)
    # axis 선과 ax의 축 레이블을 제거합니다.
    ax.spines['top'].set_color('none')
    ax.spines['bottom'].set_color('none')
    ax.spines['left'].set_color('none')
    ax.spines['right'].set_color('none')
    ax.tick_params(labelcolor='w', top=False, bottom=False, left=False, right=False)
    
    for i in range(len(his_dict_1)):
        temp_ax = fig.add_subplot(2, 2, i + 1)
        temp = keys[i%2]
        val_temp = keys[(i + 2)%2 + 2]
        temp_history = his_dict_1 if i < 2 else his_dict_2
        temp_ax.plot(epochs, temp_history[temp][1:], color = 'blue', label = 'train_' + temp)
        temp_ax.plot(epochs, temp_history[val_temp][1:], color = 'orange', label = val_temp)
        if(i == 1 or i == 3):
            start, end = temp_ax.get_ylim()
            temp_ax.yaxis.set_ticks(np.arange(np.round(start, 2), end, 0.01))
        temp_ax.legend()
    ax.set_ylabel('loss', size = 20)
    ax.set_xlabel('Epochs', size = 20)
    plt.tight_layout()
    plt.show()
    
draw_loss_acc( model1_history, model2_history, 30)

문제104. (오늘의 마지막 문제)  위와 같이 두개의 모델의 성능을 같이 시각화하는 구현을
             mnist 데이터(필기체) 로 구현하고 시각화된 결과를 첨부하세요 ~~~

119페이지  ~ 136 페이지까지 미리 읽어오세요 ~~  

■ 저번주에 배웠던 딥러닝 수업 내용

1장: numpy 
2장: 퍼셉트론
3장: 3층 신경망 구현 
4장: 오차함수

          - 평균제곱 오차함수 ( 수치예측 ) --> 보스톤 하우징 데이터의 집값 예측(텐써 플로우)
          - 교차엔트로피 오차함수 (분류)  -->  패션 mnist 데이터를 분류(텐써 플로우)

            신경망의 층수를 더 깊게 했을때의 장점과 단점을 실험 

               1.  장점 ?  더 빨리 수렴했습니다.  
               2.  단점 ?  오버피팅 발생했습니다. 

  위의 내용을 확인하기 위해서 검증 데이터를 만들어서 같이 훈련 시키고 훈련 데이터와
  검증 데이터간의 정확도와 오차를 확인 했습니다. 

  두 모델을 같이 시각화하는 함수를 이용해서 시각화를 수행 <-- 마지막 문제

4장의 주요내용 3가지

1. 오차함수 
2. 미니배치
3. 수치미분 

■ 미니배치 p115

 " 훈련 데이터중에 일부만 골라서 학습하는 방법"

 "표본을 뽑아서 학습 시킨다"

 3장에서 저자가 만들어온 가중치를 인공신경망에 셋팅해서 필기체 분류 신경망을 구현을
 했다면 4장은 우리가 직접 신경망을 학습 시킬 것입니다.

 6만장 ------------------------------------> 신경망 (컴퓨터 메모리가 초과되면서 터집니다)

 6만장중에 1장씩 입력 --------------------------->  신경망(시간이 너무 많이 걸림)

* 배치단위 처리 안했을때 ( 6만장을 다 학습하려면 6만번 신경망에 데이터 입력), 한톨씩 먹는다
  입력층  ----> 은닉1층(뉴런의 갯수50개) ---> 은닉2층(뉴런의 갯수100개)  ---> 출력층(10개)
 (1, 784)  ◎  (784, 50) ---> ( 1, 50)   ◎ ( 50, 100 ) ---> ( 1, 100) ◎ ( 100, 10)  ---> ( 1, 10)
    ↑               ↑
 입력행렬      W1 가중치행렬

* 배치단위로 처리했을때 (6만장을 학습할때 100개 씩 학습)  한수저씩 밥을 먹는다.
 6만장중에 100장씩 입력 ------------------------->  신경망( 학습 시간이 빨라집니다.)

  입력층 -----> 은닉1층(뉴런의 갯수50개) ---> 은닉2층(뉴런의 갯수100개) ---> 출력층(10개)
 (100, 784) ◎ ( 785, 50)  ---->(100, 50) ◎ ( 50, 100 ) ---> (100, 100) ◎ ( 100, 10)---> (100,10)
   ↑               ↑
 입력행렬      W1 가중치행렬


100장씩 학습 시킬건데 100장씩 600번을 학습시키면 그게 바로 1 epoch 입니다. 

 60000장 : 100장 x 600번 

문제105.  숫자 1 ~ 60000  까지의 숫자들중에서 무작위로 10개를 추출하시오 !

답:
import   numpy  as  np
print ( np.random.choice( np.arange(1, 60001), 10) )

[30048 46337 15521 37915 40268  6468 30339 55085 17348  4420]

문제106. 숫자 1 ~ 60000 까지의 숫자들중에서 무작위로 100개를 추출하시오 !

import   numpy  as  np
print ( np.random.choice( np.arange(1, 60001), 100) )

문제107. 신경망에서는 배치 처리를 어떻게 하는가 ?

목차 18번 코드: https://cafe.daum.net/oracleoracle/Shyl/263

history = model.fit(x_train, y_train, 
                        epochs = 30, 
                        batch_size = 128,   <--------- 배치 사이즈 지정하는 부분 
                        validation_data = (x_val, y_val))

문제108. 구글 코렙의 GPU 를 이용해서 문제107 번 코드를 수행하시오 !


▩ CPU 와 GPU 의 차이 ?

 GUP 는 그래픽 카드의 CPU 역활을 하는 하드웨어 입니다 
 GPU 는 그래픽 처리 장치로 그래픽 연산에 특화된 부품입니다.
 원리 자체로만 놓고보면 CPU 와 같지만 CPU 가 복잡한 연산을 처리하기 위해
 연산 속도에 집중하는 반면, GPU 는 '쉬운 작업을 대량' 으로 처리한다는것이 차이점입니다.

 집에서 편하게 2000만원 짜리 GPU 컴퓨터를 사용하려면 구글 코렙을 이용하면 됩니다.

코렙의 GPU 를 사용하려면? 런타임 ---> 런타임 유형변경에서 GPU 를 선택 


▩ 배치사이즈가 클때와 작을때의 장단점 

 "배치 사이즈도 하이퍼 파라미터라 이미지 데이터에 맞는 배치사이즈를 신경망 개발자가
  직접 알아내야 합니다."

1. 배치 사이즈가 작을때 :  장점: 어려운 문제(local minimum) 을 만나도 배치 사이즈가 
                                          클때보다는 학습이 잘 진행됩니다. 
                                   단점:  학습 시간이 오래 걸림

2. 배치 사이즈가 클때 :  장점:  학습 시간이 빨라집니다. 
                                단점:  어려운 문제(local minimum 이나 안장점) 을 만나면
                                         학습이 잘 진행되지 않습니다. 

배치 사이즈에 따라서 학습시간이 오래걸리거나 빠르게 수행되는 경우

그림: https://cafe.daum.net/oracleoracle/Shyl/328

학습 시간으로만 보면 배치 사이즈가 클수록 학습 시간이 단축 됩니다. 


문제109.  배치 사이즈가 1일때와 배치 사이즈가 100일때와 배치 사이즈가 500일때의
             학습 속도를 확인하시오 !

1. 배치사이즈 1일때 :  너무 오래 걸려서 끊어버림

 입력층  ----> 은닉1층(뉴런의 갯수50개) ---> 은닉2층(뉴런의 갯수100개)  ---> 출력층(10개)
 (1, 784)  ◎  (784, 50) ---> ( 1, 50)   ◎ ( 50, 100 ) ---> ( 1, 100) ◎ ( 100, 10)  ---> ( 1, 10)

history = model.fit(x_train, y_train, 
                        epochs = 30, 
                        batch_size = 1, 
                        validation_data = (x_val, y_val))

2. 배치사이즈가 100 일때 : 50초

  입력층 -----> 은닉1층(뉴런의 갯수50개) ---> 은닉2층(뉴런의 갯수100개) ---> 출력층(10개)
 (100, 784) ◎ ( 785, 50)  ---->(100, 50) ◎ ( 50, 100 ) ---> (100, 100) ◎ ( 100, 10)---> (100,10)

history = model.fit(x_train, y_train, 
                        epochs = 30, 
                        batch_size = 100, 
                        validation_data = (x_val, y_val))

3. 배치사이즈가 500일 때 : 15초 

  입력층 -----> 은닉1층(뉴런의 갯수50개) ---> 은닉2층(뉴런의 갯수100개) ---> 출력층(10개)
 (500, 784) ◎ ( 785, 50)  ---->(500, 50) ◎ ( 50, 100 ) ---> (500, 100) ◎ ( 100, 10)---> (500,10)

history = model.fit(x_train, y_train, 
                        epochs = 30, 
                        batch_size = 500, 
                        validation_data = (x_val, y_val))


실험결과:  위의 3개의 모델중에 가장 학습을 빠르게 수행한 모델은 배치 사이즈 500 입니다. 
               배치 사이즈가 크다고 무조건 좋은것은 아닙니다.  

              위의 3개의 모델중에 배치 사이즈가 가장 큰 모델은 수행 속도는 빠르지만 
              작은 어려움(local minimum) 을 만나면 그 어려움을 혼자 스스로 해결하지 못하는
              자존감이 떨어지는 양상을 보입니다.

문제110.  중간중간 작은 어려움들이 있는 패션 mnist 데이터를 배치 사이즈 100 으로 했을때와
             배치 사이즈 500으로 했을때의 각각 두 모델의 정확도와 오차를 시각화 하시오 !

딥러닝 목차 22번 : https://cafe.daum.net/oracleoracle/Shyl/324

# 3. 모델을 구성합니다.

from  tensorflow.keras.models  import  Sequential
from  tensorflow.keras.layers    import  Dense

model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(784, ) ) ) # 은닉1층
model.add(Dense( 10, activation='softmax') ) 

# 4. 모델을 설정합니다. (경사하강법과 오차함수를 정의해줍니다. 4장에서 배웁니다)

model.compile(optimizer='adam',  # 경사하강법 
                     loss='categorical_crossentropy',  #오차함수
                     metrics=['acc'] )  # 학습과정에서 정확도를 보려고 지정

# 5. 모델을 훈련 시킵니다.

history1 = model.fit(x_train, y_train, 
                          epochs = 30, 
                           batch_size = 100,   
                         validation_data = (x_val, y_val))

# 설명: 배치 사이즈 100으로 학습하는 학습과정에서 쌓이는 오차와 정확도를 history1 에 저장합니다. 


#model.fit( 훈련데이터, 정답, 에폭수, 배치사이즈) 
# 에폭수 :  학습횟수 (책을 몇번 볼건지)
# 배치사이즈:  한번에 학습할 양 ( 사람은 책을 한번에 한페이지 밖에 못보지만 컴퓨터는 한번에
#                  여러 페이지를 볼 수 있다)

# 6. 모델을 평가합니다. (시험을 봅니다.)

model.eval‎uate(x_test, y_test)  # [0.3571239709854126, 0.8883000016212463]

# 설명: 훈련을 할때는 항상  훈련 데이터와 검증 데이터의 정확도를 같이 볼 수 있게 해줘야 합니다
# 그래야 나중에 진짜 real 테스트 데이터의 정확도를 어느정도 가늠할 수 있게 됩니다. 

2. 배치 사이즈 500일때의 모델 훈련시키기 


# 3. 모델을 구성합니다.


from  tensorflow.keras.models  import  Sequential
from  tensorflow.keras.layers    import  Dense

model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(784, ) ) ) # 은닉1층
model.add(Dense( 10, activation='softmax') ) 

# 4. 모델을 설정합니다. (경사하강법과 오차함수를 정의해줍니다. 4장에서 배웁니다)

model.compile(optimizer='adam',  # 경사하강법 
                     loss='categorical_crossentropy',  #오차함수
                     metrics=['acc'] )  # 학습과정에서 정확도를 보려고 지정

# 5. 모델을 훈련 시킵니다.

history2 = model.fit(x_train, y_train, 
                        epochs = 30, 
                        batch_size = 500, 
                        validation_data = (x_val, y_val))

#model.fit( 훈련데이터, 정답, 에폭수, 배치사이즈) 
# 에폭수 :  학습횟수 (책을 몇번 볼건지)
# 배치사이즈:  한번에 학습할 양 ( 사람은 책을 한번에 한페이지 밖에 못보지만 컴퓨터는 한번에
#                  여러 페이지를 볼 수 있다)

# 6. 모델을 평가합니다. (시험을 봅니다.)

model.eval‎uate(x_test, y_test) # [0.35104069113731384, 0.876800000667572]

1. 배치 사이즈 100일때 : [0.3571239709854126, 0.8883000016212463]

2. 배치 사이즈 500일때 : [0.35104069113731384, 0.876800000667572]

설명:  둘다 똑같이 30 에폭을 사는동안 배치 사이즈 100보다 배치 사이즈 500의 정확도가 
         더 떨어진 이유는 아마도 배치 사이즈 500이 배치 사이즈 100보다 local minimum 에 
         빠졌을때 헤어 나오느라 시간이 더 걸렸기 때문입니다.

 두 모델의 정확도를 같이 시각화 해보면 쉽게 알 수 있습니다.

문제111.   이번에는 배치 사이즈 100 과 배치 사이즈 1000과의 차이를 비교하시오 !


문제112.  (점심시간 문제)  배치 사이즈를 더 늘리면 어떤 결과가 나오는지 실험하시오 !

history1 은 배치사이즈 100 으로 하세요
history2 는 배치사이즈 2000 으로 하세요 

시각화된 결과를 올리고 식사하러 가시면 됩니다.

■ 4장의 주요내용  3가지

1. 오차함수
2. 미니배치
3. 수치미분 

▦ 수치미분  p121

 "신경망을 학습 시킬때 미분이 필요합니다. "

 신경망을 학습 시킬 때 왜 미분이 필요한가 ?

  답:  가중치를 갱신해주기 위해서 미분이 필요합니다.

     가중치 = 가중치 - 기울기 


 기울기가 0 이 될때까지 계속해서 학습을 합니다. 그리고 기울기가 0 이 되는 그 지점의
  가중치가 바로 오차가 최소화되는 global minimum 이 되는 것입니다. 

▩ 미분 공식과 기울기 구하는 방법 

딥러닝 목차 23번 : https://cafe.daum.net/oracleoracle/Shyl/325

문제113. 진정한 미분을 그나마 컴퓨터로 구현하고자 수식 4.4 (미분공식)을 함수로 구현하시오 

책 121페이지의 수식 4.4 

답:  
def  numerical_diff( f,  x ):  # 기울기 구하는 함수 
    h = 10e-50  # 0에 가까워 지는 숫자를 표현 0.00000000 ... 001  (0이 50개)
    return  (  f(x+h) - f(x) ) / h


def  f(x):
    return   2*x**2 + 2 

print ( numerical_diff(  f,  4)  )

위와 같이 진정한 미분은 컴퓨터로 구현할 수 가 없다.

진정한 접선말고 근사로 구한 접선으로 미분함수를 생성해야 합니다. 


                                                        f(x+h)  - f(x-h)
근사로 구한 접선(파란색 접선) = lim -----------------------------
                                            h->0   ( x + h)    -  ( x - h)

위의 식으로 함수를 생성합니다.

def  numerical_diff(f, x):
    h = 0.0001  # 극한값을 구현
    return  ( f(x+h) - f(x-h) ) / (2*h) 

def  f(x):
    return   2*x**2 + 2 

print ( numerical_diff(  f,  4)  )

15.999999999998238 결과가 이렇게 나왔습니다  16이 딱 안나온 이유는 진정한 미분의 공식이
아니라 근사로 구한 접선의 미분이기 때문입니다. 

문제114.  아래의 함수를 미분해서 x 가 6인 지점에서 미분계수(기울기) 를 구하시오 !






답글로 올려주시고 쉬세요

https://cafe.daum.net/oracleoracle/Shyl/355


def numerical_diff(f,x):
    h = 0.0001 # 극한값을 구현
    return (f(x+h) - f(x-h)) / (2*h)

def f(x):
    return 3*x**2 + 2*x + 7

print(numerical_diff(f,6))


▩ 편미분 (p125)

 편미분이란 ?  변수가 2개 이상인 함수를 미분할 때 미분 대상 변수외에
                    나머지 변수를 상수처럼 고정시켜 미분하는것을 편미분이라고 합니다. 
 
구글에서 z = x^2 + y^2 하고 검색하세요 ~~

 변수가 2개이상인 함수를 미분할때는 미분 대상 변수외에 나머지 변수를 상수처럼 고정시켜서
 미분하는것을 편미분이라고 합니다.

  f = x^2 + y^2 의 (7, 4) 지점의 기울기를 구한다면 기울기는 ( 14, 8 ) 이 됩니다. 

   w1 = w1 - 기울기   ------------> 기울기가 0 이 될 때까지 계속 w1 을 갱신
   w2 = w2 - 기울기   ------------> 기울기가 0 이 될 때까지 계속 w2 를 갱신 


 오차함수(f) 에 대해서 w1 에 대해서만 미분한다면 그냥 미분함수를 이용하면 되는데 
 w1 에 대해서도 미분해야하고 w2 에 대해서도 미분해야하고 w3 에 대해서도 미분해야하므로
 "편미분" 을 사용해야합니다. 

문제115. 아래의 함수를 편미분해서 x , y 좌표가 ( 3, 2 ) 지점에서의 기울기를 구하시오 !



문제116.  그림 4-8 의 오차함수를 파이썬으로 생성하시오 !


답:
import  numpy  as  np

x = np.array( [3.0, 4.0] )

def  loss_func(x):
    return  x[0]**2 + x[1]**2

print( loss_func(x) )  # 25

문제117. 위의 loss_func() 함수를 x0=3,  x1=4 인 지점에서 x0 에 대해서 편미분했을때의 기울기?

그림 4-9

def  loss_func(x):
    return  x[0]**2 + x[1]**2

def  function_tmp1(x0):
    return  x0**2 + 4**2    # x1 은 상수 취급이 되어서 이렇게 나옵니다. 

def  numerical_diff( f,  x):
    h = 0.0001
    return  ( f(x+h) - f(x-h) )  / (2*h) 

print ( numerical_diff(   function_tmp1,  3)  )

6.00000000000378

6이 딱 나오면 좋은데 뒤에 378 이 나온것은 중앙차분오차 때문입니다. 
근사로 구한 접선의 미분식으로 구현했기 때문에 오차가 발생할 수 밖에 없는데 위의 오차는
무시해도 될 만한 오차입니다. 

문제118.  위의 loss_func() 함수를 x0=3, x1=4 에서 x1 에 대해서 편미분했을때의 기울기는?

def  loss_func(x):
    return  x[0]**2 + x[1]**2

지금 방금 우리는 일일이 손으로 한쪽을 상수화 해서 편미분을 했습니다.
그런데 그냥 자동으로 다 편미분되게 해보겠습니다.

문제119. 책 127 페이지 아래에 나오는 numerical_gradient 함수를 생성하시오 !

x = np.array([3.0, 4.0]) 
print (np.zeros_like(x) )  # [0. 0.]   x 행렬이 1x2 행렬이므로 출력값도 1x2 행렬인데 원소가 0으로 채워짐

def  numerical_gradient(f, x):    # 오차함수와 가중치를 받을 입력 매개변수 2개를 생성 
    h = 0.0001         #  0 에 가까워지는 극한값을 코드로 간단하게 구현
    grad = np.zeros_like(x)   # x 와 형상이 같은 배열을 생성하는데 원소는 다 0 입니다. 
                                     # 기울기를 담는 변수 입니다. [0 , 0]

    for  i  in  range(x.size):  # 0, 1
        tmp_val = x[i]  # x[0] 이면 값이 3.0 을 tmp_val 에 담습니다. 
        x[i] = tmp_val + h  # 3.0 + 0.0001 = 3.0001 이 x[0] 로 들어가서 x 변수가 [3.0001, 4.0] 로 변경
        fxh1 = f(x)  # 3.0001**2 + 4.0**2 = 25.00060001

        x[i] = tmp_val - h  #  3.0 - 0.0001 = 2.9999 가 x[0] 에 담기고 [ 2.9999, 4.0] 
        fxh2 = f(x) # 2.9999**2 + 4.0**2 = 24.99940001 이 값이 fxh2 에 담기게 됩니다. 

        grad[i] = ( fxh1 - fxh2 ) / (2*h)  # ( 25.00060001 - 24.99940001 ) / (2*0.0001) = 6.00000000000378
                                               # grad[0] 에 6.00000000000378 를 담습니다. 
        x[i] = tmp_val  # tmp_val 에 있었던 3.0 을 다시 x[0] 에 넣어서 x 는 [3.0, 4.0] 으로 원복됩니다.

    return grad 

x = np.array([3.0, 4.0]) 

def  loss_func(x):
    return  x[0]**2 + x[1]**2

print ( numerical_gradient( loss_func, np.array([3.0, 4.0]) ) ) 

[6. 8.]

문제120.  위의 for 문은 첫번째 0 일때로 돌려서 기울기를 [ 6.00000000000378 ,  0 ] 로 완성했습니다.
             for 문을 계속 돌려서 i 가 1 일때로 루프문을 돌려서 [6.00000000000378 , ? ] 로 완성하세요
             ( 주석을 직접 달아서 설명을 쓰세요 ~)

x = np.array([3.0, 4.0]) 
print (np.zeros_like(x) )  # [0. 0.]   x 행렬이 1x2 행렬이므로 출력값도 1x2 행렬인데 원소가 0으로 채워짐

def  numerical_gradient(f, x):    # 오차함수와 가중치를 받을 입력 매개변수 2개를 생성 
    h = 0.0001         #  0 에 가까워지는 극한값을 코드로 간단하게 구현
    grad = np.zeros_like(x)   # x 와 형상이 같은 배열을 생성하는데 원소는 다 0 입니다. 
                                     # 기울기를 담는 변수 입니다. [0 , 0]
       
    for  i  in  range(x.size):  # 0, 1
        tmp_val = x[i]  # x[1] 이면 4.0 이 tmp_val 에 담기게 됩니다. 
        x[i] = tmp_val + h  #   4.0 + 0.0001 이 x[1] 에 담겨서 [3.0, 4.0001] 이 x 변수가 됩니다. 
        fxh1 = f(x)  # 3.0**2 + 4.0001*2 = 25.00080001  이 fxh1 에 담기게 됩니다. 

        x[i] = tmp_val - h  # 4.0 - 0.0001 = 3.9999 가 되어서 [3.0, 3.9999] 가 x 변수가 됩니다. 
        fxh2 = f(x) #  3.0**2 + 3.9999**2 = 24.99920001

        grad[i] = ( fxh1 - fxh2 ) / (2*h)  #  (25.00080001 - 24.99920001) / (2*0.0001)
                                               #7.999999999999119  이 grad[1] 에 들어갑니다. 
        x[i] = tmp_val  #    

    return grad   #  [6.00000000000378 , 7.999999999999119 ] 

x = np.array([3.0, 4.0]) 

def  loss_func(x):
    return  x[0]**2 + x[1]**2

print ( numerical_gradient( loss_func, np.array([3.0, 4.0]) ) ) 


문제121. (오늘의 마지막 문제)  그림 4-8 오차함수를 x0=8, x1=2 에서 편미분하여 구한 기울기 
            배열을 출력하시오 !

def  loss_func(x):
    return  x[0]**2 + x[1]**2


■ 4장의 주요 내용 3가지

1. 오차함수
2. 미니배치
3. 수치미분 

 신경망을 학습할 때 미분이 왜 필요하냐면 ? 가중치를 갱신하기 위한 기울기를 구하기 위해서 

 배치처리 --> 미분 ---> 편미분 ---> 편미분 

 배치처리가 필요한 이유 ?  컴퓨터에 사진을 한장씩 입력하는것보다 여러장씩 한번에 입력하는게
                                     더 학습 속도가 빠르고 효율적이기 때문입니다.

▩ 텐써 플로우로 1층 신경망 구현하기 (순전파만)

그림: https://cafe.daum.net/oracleoracle/Shyl/411

# 1. 필요한 패키지를 가져옵니다.
import  tensorflow  as  tf
from  tensorflow.keras.models  import  Sequential
from  tensorflow.keras.layers  import  Dense, Flatten
import numpy as np

#2. 모델을 구성합니다.
model = Sequential()
model.add(Flatten(input_shape=(2,) ) )  # 입력층(0층)
model.add(Dense( 3, activation ='softmax') ) # 출력층(1층)

#3. 입력 데이터 만들기 
x = np.array([0.6, 0.9]).reshape(1,2)

#4. 정답 데이터 만들기 
t = np.array([0, 0, 1]).reshape(1,3) 

#5. 모델을 compile 합니다. 
model.compile( optimizer='adam',
                     loss='categorical_crossentropy',
                     metrics=['acc'] )

#6. 모델을 평가하여 오차를 확인합니다.
model.evaluate(x,t)

문제122. 위의 층수를 1층에서 2층으로 변경하시오 !

 기존층:  입력층(2개)---> 출력층(3개)
 변경된 층: 입력층(2개) ----> 은닉1층(5개) ----> 출력층(3개)


# 1. 필요한 패키지를 가져옵니다.
import  tensorflow  as  tf
from  tensorflow.keras.models  import  Sequential
from  tensorflow.keras.layers  import  Dense, Flatten
import numpy as np

#2. 모델을 구성합니다.
model = Sequential()
model.add(Flatten(input_shape=(2,) ) )  # 입력층(0층)
model.add(Dense( 5, activation='sigmoid') ) # 은닉1층
model.add(Dense( 3, activation ='softmax') ) # 출력층(2층)

#3. 입력 데이터 만들기 
x = np.array([0.6, 0.9]).reshape(1,2)

#4. 정답 데이터 만들기 
t = np.array([0, 0, 1]).reshape(1,3) 

#5. 모델을 compile 합니다. 
model.compile( optimizer='adam',
                     loss='categorical_crossentropy',
                     metrics=['acc'] )

#6. 모델을 평가하여 오차를 확인합니다.
model.evaluate(x,t)

문제123. 입력값의 예측값을 출력하시오 !

y = model.predict(x)
print(y)  # [[0.36545238 0.3503088  0.2842388 ]]

문제124. 위에서 출력된 확률벡터에서 최대값의 원소의 인덱스 번호를 출력하시오 !

print( np.argmax(y) )

문제125. 위의 신경망에 사진을 한장씩 넣는게 아니라 100장을 한꺼번에 넣을 수 있도록
             고양이 사진 100장( 100, 784) 을 생성하시오 !

답:
import  numpy  as  np
x = np.random.randn(100,784)  # 100x784개의 난수를 생성
print (x.shape)

문제126. 위의 신경망에 사용할 정답 데이터를 (100, 3) 으로 생성하시오

from  tensorflow.keras.utils  import  to_categorical  #one hot encoding 하는 모듈

a =[]
for  i  in range(1, 101):
    x = np.random.randint(0,3)  # 0 에서 2까지의 숫자중 하나를 램덤으로 생성
    a.append(x)
print(a)   # a 리스트에는 0,1,2  중에 하나의 숫자가 랜덤으로 생성되어서 100개가 생성됨

a2 = np.array(a)  # a 리스트를 numpy array 로 변환합니다
t = to_categorical(a2)  #  a 리스트에 있는 숫자들을 원핫 인코딩 합니다. 
print (t.shape)  # (100, 3) 

또는 

a2 = np.random.randint(0,3,100) 로 하세요 

문제127. 위에서 텐써 플로우로 만든 2층 신경망을 텐써 플로우 없이 파이썬으로 구현하시오 ! 
            ( 코렙에서 수행하세요) 

목차24번의 2층 신경망을 텐써 플로우 없이 구현하기(순전파만)

https://cafe.daum.net/oracleoracle/Shyl/406

[쉬움주의] 코렙에서 밑바닥 딥러닝책 134 페이지 구현하기(순전파만)

1. 코렙에서 새노트를 열고 구글 드라이브와 연동합니다.

from google.colab import drive
drive.mount('/content/drive')

왜 연동을 하는가?  밑바닥 딥러닝 책의 소스 코드를 코랩에 올릴려면 구글 드라이브에 올려야하므로
                          구글 드라이브와 코랩을 연동해야 합니다. 

2. /content/drive/Mydrive 밑에 yys 라는 폴더를 생성하고 그 밑에 common 폴더를 생성하시오


3. 밑바닥 딥러닝 소스 코드중에 common 이라는 폴더에 있는 내용을 전부  코렙에
   /content/drive/Mydrive/yys/common  밑으로 다 올리시오 !

 common 폴더안에 신경망 구현에 필요한 함수 생성 코드들이 들어있습니다.

4.  /content/drive/Mydrive/yys  로 이동한 후의  아래의 코드를 실행하시오!

%cd /content/drive/MyDrive/yys  # yys 밑에 common 폴더(패키지)로 접근하기 위해서 이동

import  sys, os
sys.path.append(os.pardir) 
import  numpy  as  np
from common.functions  import  softmax, cross_entropy_error 
# common 폴더 안에 functions.py 모듈안에 softmax 함수와 cross_entropy_error 함수를 가져와라

class  simpleNet: 
    def  __init__(self):  # simpleNet 클래스(설계도)의 객체(제품)가 만들어질 때 자동으로 실행되는 함수
        self.W = np.random.randn(2,3)  #   2x3 행렬 난수들로 가중치 배열이 생성

    def  predict( self, x ):
        return  np.dot( x, self.W )  # (1,2) ◎ (2,3) =(1,3) 

    def  loss( self, x, t ):
        z = self.predict(x)
        y = softmax(z)
        loss = cross_entropy_error(y, t)
        return  loss 

net = simpleNet()  # 위에서 만든 설계도(클래스)로 제품(객체) 을 생산함
print ( net.W )  # 가중치 행렬 확인 

# 입력값 생성
x = np.array( [0.6, 0.9] )  # (1,2) 배열로 입력값 생성

# 예측값 
y = net.predict(x)
print (y)

# 최대값 원소의 인덱스 확인
print ( np.argmax(y) ) 

# 오차확인
t = np.array([ 0, 0, 1])
print ( net.loss(x,t)  )

문제128. 위의 설계도(class) 를 1층에서 2층으로 변경하시오 !

기존1층:  입력층(2개) -------> 출력층(3개)

변경된층 2층:  입력층(2개) ---> 은닉1층(5)  -----> 출력층(3개)

%cd /content/drive/MyDrive/yys  # yys 밑에 common 폴더(패키지)로 접근하기 위해서 이동

import  sys, os
sys.path.append(os.pardir) 
import  numpy  as  np
from common.functions  import  softmax, cross_entropy_error, sigmoid 
# common 폴더 안에 functions.py 모듈안에 softmax 함수와 cross_entropy_error 함수를 가져와라

class  simpleNet: 
    def  __init__(self):  # simpleNet 클래스(설계도)의 객체(제품)가 만들어질 때 자동으로 실행되는 함수
        self.W1 = np.random.randn(2,5)  #   2x5 행렬 난수들로 가중치 배열이 생성
        self.W2 = np.random.randn(5,3)

    def  predict( self, x ):
        k = np.dot( x, self.W1 ) 
        k_prime = sigmoid(k) 
        m = np.dot( k_prime, self.W2)
        return  m

    def  loss( self, x, t ):
        z = self.predict(x)
        y = softmax(z)
        loss = cross_entropy_error(y, t)
        return  loss 

net = simpleNet()  # 위에서 만든 설계도(클래스)로 제품(객체) 을 생산함

# 입력값 생성
x = np.array( [0.6, 0.9] )  # (1,2) 배열로 입력값 생성

# 예측값 
y = net.predict(x)
print (y)

# 최대값 원소의 인덱스 확인
print ( np.argmax(y) ) 

# 오차확인
t = np.array([ 0, 0, 1])
print ( net.loss(x,t)  )


문제129. (점심시간 문제) 아래의 신경망으로 위의 코드를 수정하시오 !
 
     입력층               은닉1층               은닉2층                  출력층(3층)

오전에 만든 신경망은 순전파 2층 신경망 입니다. 

 1.  텐써 플로우로를 사용해서 생성       ( 당장 현업에서 우리가 사용)
 2.  텐써 플로우로를 사용하지 않고 생성 ( 원리를 이해하려고)

오후에는 역전파 신경망을 구현 하겠습니다.

가중치를 갱신하기 위한 신경망 ( 기울기를 역전파 )을 구현하려면?

1. 러닝 레이트
2. 경사감소법

이 두가지를 이해해야 합니다. 

▩ 러닝 레이트(학습률, learning rate) 

 "한번의 학습으로 얼마만큼 매개변수(가중치와 바이어스)를 갱신할지를 결정하는 하이퍼 파라미터"

가중치 = 가중치 - 학습률*기울기 

위의 학습률은 신경망 개발자가 0.01 이나 0.1 등과 같이 알아서 줘야하는데
일반적으로  이 값이 너무 크거나 너무 작으면 global minimum 지점에 도착할 수 없습니다.

학습률이 너무 ↑  --->  학습은 빠르지만 global minimum 을 지나칠 수 있습니다.
학습률이 너무 ↓  --->  global minimum 을 지나칠 염려는 없지만 학습이 너무 느려서 수렴을 
                                 못합니다. 

적절한 학습률을 신경망 개발자가 직접 테스트를 통해서 알아내야합니다. 

결론을 먼저 애기하면 텐써 플로우를 사용하고 그리고 경사하강법 종류중에 Adam 이나 
Adagrade 를 사용하게 되면 학습률이 학습중에 자동조절 되므로 학습률은 신경쓰지 않아도 됩니다.

높은산에서는 성큼성큼 내려오고 목적지에 도달해서는 촘촘 걸음으로 내려옵니다. 

문제130. 러닝레이트를 0.01 로 실험하시오 !

딥러닝 목차 26번	. 러닝 레이트가 너무 작았을 때와 너무 컸을 때의 차이 실험

https://cafe.daum.net/oracleoracle/Shyl/408


코드:
# 1. 필요한 패키지 가져오는 코드 

import tensorflow as tf   # 텐써 플로우 2.0 
from tensorflow.keras.datasets.mnist import load_data  # 텐써플로우에 내장되어있는 
                                                                         # mnist 데이터를 가져온다.
from tensorflow.keras.models import Sequential  # 모델을 구성하기 위한 모듈
from tensorflow.keras.layers import Dense  # 완전 연결계층을 구성하기 위한 모듈
from tensorflow.keras.utils import to_categorical # one encoding 하는 모듈
from tensorflow.keras import backend as K  # 텐써 플로우를 사용하지 않았을때의 코드로 구현할 수 있게 하는 코드 

tf.random.set_seed(777)

(x_train, y_train), (x_test, y_test) = load_data(path='mnist.npz')  # mnist 데이터 로드
    
# 2. 정규화 진행 

# 3차원 ---> 2차원으로 차원축소하고서 정규화 진행  ( 한 픽셀이 0~255 로 되어있는데)
# 0 ~ 1 사이로 변경 
x_train = (x_train.reshape((60000, 28 * 28))) / 255 
x_test = (x_test.reshape((10000, 28 * 28))) / 255

# 3. 정답 데이터를 준비한다. 

# 하나의 숫자를 one hot encoding 한다. (예:  4 ---> 0 0 0 0 1 0 0 0 0 0 ) 
y_train = to_categorical(y_train)  # 훈련 데이터의 라벨(정답)을 원핫 인코딩
y_test = to_categorical(y_test)    # 테스트 데이터의 라벨(정답)을 원핫 인코딩 


# 4. 모델을 구성합니다. 3층 신경망으로 구성

model = Sequential()
model.add(Flatten(input_shape = (784,)))
model.add(Dense(100, activation = 'relu'))  # 2층 
model.add(Dense(10, activation = 'softmax'))  # 3층 출력층 


# 5. 모델을 설정합니다. ( 경사하강법, 오차함수를 정의해줍니다. )

model.compile(optimizer='adam', 
              loss = 'categorical_crossentropy', 
              metrics=['acc'])  # 학습과정에서 정확도를 보려고 


#6. 모델을 훈련 시킵니다.
K.set_value(model.optimizer.learning_rate, 0.01)  # 러닝 레이터를 0.01 로 지정하겠다. 
print("Learning rate before second fit:", model.optimizer.learning_rate.numpy())

history=model.fit( x_train, y_train, epochs=30, batch_size=100)


# 7.모델을 평가합니다. (오차, 정확도가 출력됩니다.)

model.eval‎uate(x_test, y_test)

# 8.테스트 데이터의 예측값을 출력합니다. 

results = model.predict(x_test)

#9. 정확도를 확인합니다.
import numpy as np
y_hat = np.argmax(results, axis=1)
y_label = np.argmax(y_test,axis=1)
print ( np.sum( y_hat == y_label ) / len(y_test) )

문제131. 러닝레이트는 0.01 이 아니라 0.5로 하고 수행하시오 

설명: 0.5 로 러닝 레이터를 주었더니 수렴하지 못하고 발산하였습니다. 

적절한 러닝 레이터값을 지정해줘야 합니다. 

45분까지 쉬세요 ~~~

신호 보냈습니다. 


가중치를 갱신하기 위한 신경망 ( 기울기를 역전파 )을 구현하려면?

1. 러닝 레이트
2. 경사감소법

▩ 경사하강법 (p129)

  오차가 최소화 되는 지점을 찾아가기 위해 아래로 내려오는 방법들

1. SGD (Stochastric  Gradient Descent)
            확률적 

 GD(Gradient Descent) 는 학습 데이터를 다 입력하고 한 걸음 이동하는 경사감소법입니다.
 그래서 GD 는 학습하는데 시간이 많이 걸립니다.  그래서 나온게 확률적 경사감소법인데
 미니배치+GD 로 데이터를 배치단위로 추출해서 학습하면서 경사하강하는 경사하강법
 
 그림 4-10

 SGD 는 아래로 내려올때 심하게 지그제그로 내려옵니다. 배치의 크기가 크면 지그제그의 정도
 가 덜하는데 배치의 크기가 작으면 술취한 사람처럼 지그제그로 내려옵니다.

 SGD 의 문제점 ?  Local  mininum 에 잘 빠집니다. 

2. momentum :  관성을 이용해서 local minima 를 빠져나가게 설계된 경사하강법입니다. 
                      텐써플로우 2.0 에는 모멘텀이 따로 없지만 Adam 에 모멘텀의 장점이 
                      포함되어져 있습니다. 

3. Adagrade : 학습률(learning rate) 을 자동조절되게 하는 경사하강법입니다. 
                   산위에 있을때는 발걸음을 크게해서 내려오고 목적지에 도달했을 때는
                   촘촘 발걸음을 내려오는게 Adagrade 입니다. 

4. Adam :  momentum 의 장점  + Adagrade 의 장점을 살린 경사하강법 
                           ↓                          ↓
              관성을 이용한다.             러닝레이트가 자동조절 됩니다. 

텐써 플로우2.0 에서 경사하강법의 종류를 기술하는 코드:

model.compile(optimizer='Adagrad',   <----- Adam, SGD, RMSprop
                     loss='categorical_crossentropy'
                     metric=['acc'] )

5. RMSprop :  Adagrade 의 장점을 더 좋게 만든 경사하강법입니다.
                   발걸음이 자동조절되는데 목표지점에 도달할때 이전에 내려오던
                   그 걸음걸이를 살펴서 발걸음(러닝레이트) 을 조절합니다. 

문제132.  2층 신경망으로 구현한 텐써 플로우 신경망 코드를 경사하강법 SGD 로 경사하강하여
             30에폭의 정확도를 확인하시오 !

https://cafe.daum.net/oracleoracle/Shyl/407

# 1. 필요한 패키지 가져오는 코드 

import tensorflow as tf   # 텐써 플로우 2.0 
from tensorflow.keras.datasets.mnist import load_data  # 텐써플로우에 내장되어있는 
                                                                         # mnist 데이터를 가져온다.
from tensorflow.keras.models import Sequential  # 모델을 구성하기 위한 모듈
from tensorflow.keras.layers import Dense  # 완전 연결계층을 구성하기 위한 모듈
from tensorflow.keras.utils import to_categorical # one encoding 하는 모듈

tf.random.set_seed(777)

(x_train, y_train), (x_test, y_test) = load_data(path='mnist.npz')  # mnist 데이터 로드
    
# 2. 정규화 진행 
# 3차원 ---> 2차원으로 차원축소하고서 정규화 진행  ( 한 픽셀이 0~255 로 되어있는데)
# 0 ~ 1 사이로 변경 
x_train = (x_train.reshape((60000, 28 * 28))) / 255 
x_test = (x_test.reshape((10000, 28 * 28))) / 255

# 3. 정답 데이터를 준비한다. 

# 하나의 숫자를 one hot encoding 한다. (예:  4 ---> 0 0 0 0 1 0 0 0 0 0 ) 
y_train = to_categorical(y_train)  # 훈련 데이터의 라벨(정답)을 원핫 인코딩
y_test = to_categorical(y_test)    # 테스트 데이터의 라벨(정답)을 원핫 인코딩 

# 4. 모델을 구성합니다. 2층 신경망으로 구성
model = Sequential()
model.add(Flatten(input_shape = (784,)))
model.add(Dense(100, activation = 'relu'))
model.add(Dense(10, activation = 'softmax'))  

# 5. 모델을 설정합니다. ( 경사하강법, 오차함수를 정의해줍니다. )
model.compile(optimizer='SGD', 
              loss = 'categorical_crossentropy', 
              metrics=['acc'])  # 학습과정에서 정확도를 보려고 

#6. 모델을 훈련 시킵니다.
model.fit( x_train, y_train, epochs=30, batch_size=100)

# 7.모델을 평가합니다. (오차, 정확도가 출력됩니다.)
model.eval‎uate(x_test, y_test)

문제133.  이번에는 Adam  으로  실험하시오 !

SGD :  [0.17041471600532532, 0.9503999948501587]
Adam : [0.10762511193752289, 0.9763000011444092]

문제134. 이번에는 RMSprop 으로 실험하시오 !

SGD :  [0.17041471600532532, 0.9503999948501587]
Adam : [0.10762511193752289, 0.9763000011444092]
RMSprop : [0.11625082045793533, 0.9764000177383423]

결론: mnist 데이터는 Adam 경사하강법이 가장 적합한 경사하강법이었습니다. 

문제135. 아래의 신경망을 텐써 플로우로 구현하시오 !

입력층(784개)        은닉1층(100개)      은닉2층(20개)             출력층(10개)

# 4. 모델을 구성합니다.
model = Sequential()
model.add(Flatten(input_shape = (784,)))
model.add(Dense(100, activation = 'relu'))
model.add(Dense(20, activation = 'relu'))
model.add(Dense(10, activation = 'softmax'))

문제136. 아래의 신경망을 텐써 플로우로 구현하시오 !

입력층 --> 은닉1층 ---> 은닉2층 ----> 은닉3층 ---> 은닉4층 ----> 출력층
( 784 개)    ( 50개)          (100개)          (50개)         (100개)           10개

# 4. 모델을 구성합니다.
model = Sequential()
model.add(Flatten(input_shape = (784,)))
model.add(Dense(50, activation = 'relu'))
model.add(Dense(100, activation = 'relu'))
model.add(Dense(50, activation = 'relu'))
model.add(Dense(100, activation = 'relu'))
model.add(Dense(10, activation = 'softmax')) 

[0.24243046343326569, 0.9729999899864197]

문제137. 위의 5층 신경망을 그림으로 그리시오 ! (배치단위가 100개)

          w1              w2               w3              w4              w5
입력층 --> 은닉1층 ---> 은닉2층 ----> 은닉3층 ---> 은닉4층 ----> 출력층
( 784 개)    ( 50개)          (100개)          (50개)         (100개)           10개

                      w1           output1         w2               output2          w3              output3
(100, 784) ◎ (784, 50) --> (100,50)   ◎ ( 50, 100) ---> ( 100, 100)  ◎ ( 100, 50) ---> ( 100,50)

 output3         w4              output4            w5                최종 output
 ( 100,50) ◎  (50, 100)  ---> ( 100, 100)  ◎  (100, 10) ---->  ( 100, 10) 

▦  딥러닝으로 할 수 있는 프로젝트1 ( 일반 사진 ----> 에니메이션으로 변경)

1. 아래의 github 주소에서 코드와 모델을 다운로드 받습니다.

https://github.com/kairess/UGATIT

2. UGATIT-master.zip 압축파일을 주피터 노트북 작업 디렉토리로 이동시켜서 거기서 압축을 푸세요

UGATIT-master  라는 폴더가 생성되었는지 확인하세요 !

3. 주피터 노트북을 tensorflow2.0 의 snowdeer_env1 을 엽니다. 

http://localhost:8889/notebooks/UGATIT-master/UGATIT-master/test_tflite.ipynb

# 1. 필요한 패키지를 가져옵니다. 
import tensorflow as tf # tensorflow 2.2+
import cv2
import numpy as np
import matplotlib.pyplot as plt

# 2. 텐써플로우 2버전으로 만든 모델을 불러옵니다.

with tf.io.gfile.GFile('checkpoint/selfie2anime.tflite', 'rb') as f:
    model_content = f.read()

interpreter = tf.lite.Interpreter(model_content=model_content)
interpreter.allocate_tensors()
input_index = interpreter.get_input_details()[0]['index']
output = interpreter.tensor(interpreter.get_output_details()[0]["index"])

#3. 이미지 시각화 코드 
img = cv2.imread('imgs/13.jpg')  # 이미지를 숫자로 변경하는 코드
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # 원래 이미지의 형상이 BGR --> RGB 로 변환
plt.imshow(img) # 시각화

#4. 3차원 이미지를 4차원 이미지로 변경하는 코드 (신경망에 4차원으로 입력해야하기 때문에)

# 사진의 가로, 세로 사이즈를 256x256 으로 변경하고
img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_NEAREST) 

# 3차원을 4차원으로 늘립니다. 
input_img = np.expand_dims(img, axis=0).astype(np.float32)
print(input_img.shape) # (1, 256, 256, 3)

# 5. 사진을 에니메이션으로 변환 
interpreter.set_tensor(input_index, input_img)  
interpreter.invoke()

fig, axes = plt.subplots(1, 2, figsize=(12, 8))    
axes[0].imshow(img)  # 일반 사진 시각화
axes[1].imshow(output()[0]) # 결과 아웃풋인 에니메이션을 시각화 

문제138.(오늘의 마지막 문제)  에니메이션으로 변경하고 싶은 사진을 구해서 
            위의 코드에 입력하고 변환시키전과 후의 사진을 올리시오 !


■ 4장의 주요내용

 1. 오차함수
 2. 미니배치
 3. 수치미분 

신경망을 구현하는 방법 2가지? 

         1. 텐써플로우 또는 파이토치를 이용해서 구현  (쉽게 구현할 수 있다)
         2. 직접 파이썬 코드를 날 코딩해서 구현  ( 원리가 잘 이해)  ---> 자기 노트정리 

▩ 경사하강법을 적용하기 전인 순전파 신경망(책의 예제, 파이썬 날코딩)

그림:    입력층 -----------> 은닉1층 -----------> 은닉2층 --------> 출력층
            (2개)                    (5개)                        (4개)               (3개)









     입력층         W1          output       W2        output       W3           output 
     (1,  2)   ◎  ( 2, 5 ) ---> (1, 5)  ◎ ( 5, 4 ) ---> ( 1, 4 ) ◎ ( 4, 3)  ---> ( 1, 3 )
       

# 1. 어제 점심시간에 만든 3층 신경망

%cd /content/drive/MyDrive/yys

import  sys, os
sys.path.append(os.pardir) 
import  numpy  as  np
from common.functions  import  softmax, cross_entropy_error, sigmoid

class  simpleNet:
    def  __init__(self): # 클래스(설계도)를 가지고 객체(제품) 를 만들때 바로 작동하는 함수 
        self.W1 = np.random.randn(2,5)  #   2x5 행렬 난수들로 가중치 배열이 생성
        self.W2 = np.random.randn(5,4)
        self.W3 = np.random.randn(4,3)

    def predict(self,x):  # 입력값을 받아서 소프트 맥스 함수에 값을 제공하는 값까지 값을 생성하는 함수 
        k = np.dot( x, self.W1 )   # 은닉1층
        k_prime = sigmoid(k)     # 은닉 1층의 시그모이드 함수
        m = np.dot( k_prime, self.W2)  # 은닉2층
        m_prime = sigmoid(m)           # 은닉2층의 시그모이드 함수
        n = np.dot( m_prime, self.W3)  # 은닉3층 
        return  n

    def  loss( self, x, t ):
        z = self.predict(x)  # 입력값을 받아서 은닉3층에서 발생한 값을 z 변수에 입력
        y = softmax(z)      # z 변수의 값을 소프트 맥스 함수에 넣어서 확률벡터를 y 에 담는다. 
        loss = cross_entropy_error(y, t)  # 확률벡터와 one hot encoding 된 정답을 받아서 오차를 출력하는 함수
        return  loss   # 오차를 리턴합니다. 

              
net = simpleNet()

# 입력값 생성
x = np.array( [0.6, 0.9] )

# 예측값 

y = net.predict(x)
print (y)

# 최대값 원소의 인덱스 확인
print ( np.argmax(y) ) 

# 오차확인
t = np.array([ 0, 0, 1])
print ( net.loss(x,t)  )

문제139. simplenet 클래스의 3층 신경망 구조가 아래와 같은데  클래스(설계도)를 net 이라는 
           이름으로 객체(제품)화 시키시오

     입력층         W1          output       W2        output       W3           output 
     (1,  2)   ◎  ( 2, 5 ) ---> (1, 5)  ◎ ( 5, 4 ) ---> ( 1, 4 ) ◎ ( 4, 3)  ---> ( 1, 3 )
       

net = simpleNet()

문제140. net = simpleNet() 명령어를 수행했을때 3층 신경망이 생성되었습니다.라는 메세지가
            출력되게하시오 !

답: 
class  simpleNet:
    def  __init__(self): # 클래스(설계도)를 가지고 객체(제품) 를 만들때 바로 작동하는 함수 
        self.W1 = np.random.randn(2,5)  #   2x5 행렬 난수들로 가중치 배열이 생성
        self.W2 = np.random.randn(5,4)
        self.W3 = np.random.randn(4,3)
        print('3층 신경망이 생성되었습니다.')  <--- 이 부분을 추가합니다. 

문제141.  제품화 시킨 3층 신경망에 입력할 입력 데이터를 1x2 행렬로 준비하시오 !

     입력층         W1          output       W2        output       W3           output 
     (1,  2)   ◎  ( 2, 5 ) ---> (1, 5)  ◎ ( 5, 4 ) ---> ( 1, 4 ) ◎ ( 4, 3)  ---> ( 1, 3 )
       
답:  x = np.array([0.6, 0.9] )

x =np.random.randn(1,2)
print(x)  # [[1.22237462 1.47406087]]

print (x.ndim) # 2차원 

※ 신경망에 데이터를 입력할 때는 1차원으로 입력하면 안되고 2차원으로 입력해 줘야 합니다. 

문제142. 정답 데이터도 아래의 3층 신경망 맞게 준비하시오 !


     입력층         W1          output       W2        output       W3         output 
     (1,  2)   ◎  ( 2, 5 ) ---> (1, 5)  ◎ ( 5, 4 ) ---> ( 1, 4 ) ◎ ( 4, 3)  ---> ( 1, 3 )
       
답:  t = np.array([ 0, 1, 0 ])

from  tensorflow.keras.utils  import  to_categorical
t = np.random.randint(0, 3, 1)  # 0, 1, 2 중에 랜덤으로 1개를 출력하겠다.
print( to_categorical(t, num_classes=3) ) 

46분까지 쉬세요 ~~

%cd /content/drive/MyDrive/yys   <-- 여기에는 # 으로 주석을 달지 마세요 ~~

문제143. 위에서 만든 객체(제품)의 가중치 행렬 W1, W2, W3 의 값을 출력하시오 !

답:
net = simpleNet()
print(net.W1)
print(net.W2)
print(net.W3)

문제144. 위에서 만든 입력값 x 를 net 신경망의 predict 함수에 넣어서 결과를 출력하시오 !

답:
x =np.random.randn(1,2)
result = net.predict(x)
print ( result ) # [[0.33138966 0.83545462 2.39990064]]

문제145. 위에서 만든 입력값 x (1x2) 와 정답 t (1x3) 를 net 신경망의 loss 함수에 넣어서
             오차를 출력하시오 

net = simpleNet()  # 신경망을 만듭니다. 

x =np.random.randn(1,2) # 입력 데이터를 만듭니다.

# 정답 데이터도 만듭니다. 
from  tensorflow.keras.utils  import  to_categorical
t = np.random.randint(0, 3, 1)  # 0, 1, 2 중에 랜덤으로 1개를 출력하겠다.
print( to_categorical(t, num_classes=3) ) 

# 오차를 출력합니다.
print( net.loss(x, t)  )

지금까지는 학습은 하지 않는 순전파의 3층신경망을 만들어 보았습니다.
지금 부터는 이 3층 신경망을 mnist 데이터셋에 맞겠금 수정을 하겠습니다.

문제146. simpleNet 클래스(설계도)를  mnist 데이터를 입력받을 수 있도록 수정하시오 !

기존 설계도:
     입력층         W1          output       W2        output       W3         output 
     (1,  2)   ◎  ( 2, 5 ) ---> (1, 5)  ◎ ( 5, 4 ) ---> ( 1, 4 ) ◎ ( 4, 3)  ---> ( 1, 3 )
       
변경된 설계도:
      입력층          W1          output       W2        output       W3         output 
     (1,  784)   ◎  ( 784, 5 ) ---> (1, 5)  ◎ ( 5, 4 ) ---> ( 1, 4 ) ◎ ( 4, 10)  ---> ( 1, 10 )
       

 필기체의 이미지 한장의 사이즈는 28x28 (784) 입니다.
 필기체 이미지 데이터셋의 정답은 총 10개 입니다. 

답:

%cd /content/drive/MyDrive/yys

import  sys, os
sys.path.append(os.pardir) 
import  numpy  as  np
from common.functions  import  softmax, cross_entropy_error, sigmoid

class  simpleNet:
    def  __init__(self): # 클래스(설계도)를 가지고 객체(제품) 를 만들때 바로 작동하는 함수 
        self.W1 = np.random.randn(784,5)  
        self.W2 = np.random.randn(5,4)
        self.W3 = np.random.randn(4,10)

    def predict(self,x):  # 입력값을 받아서 소프트 맥스 함수에 값을 제공하는 값까지 값을 생성하는 함수 
        k = np.dot( x, self.W1 )   # 은닉1층
        k_prime = sigmoid(k)     # 은닉 1층의 시그모이드 함수
        m = np.dot( k_prime, self.W2)  # 은닉2층
        m_prime = sigmoid(m)           # 은닉2층의 시그모이드 함수
        n = np.dot( m_prime, self.W3)  # 은닉3층 
        return  n

    def  loss( self, x, t ):
        z = self.predict(x)  # 입력값을 받아서 은닉3층에서 발생한 값을 z 변수에 입력
        y = softmax(z)      # z 변수의 값을 소프트 맥스 함수에 넣어서 확률벡터를 y 에 담는다. 
        loss = cross_entropy_error(y, t)  # 확률벡터와 one hot encoding 된 정답을 받아서 오차를 출력하는 함수
        return  loss   # 오차를 리턴합니다. 

문제147.  위의 변경된 3층 신경망에 맞도록 입력 데이터의 행렬을 1x784 로 해서 난수를 생성하고
             정답도 1x10 으로 해서 one encoding 된 데이터를 생성하시오 

답: 
x = np.random.randn(1,784)

from tensorflow.keras.utils  import  to_categorical
t = np.random.randint(0, 10, 1 )  # 0 번 부터 9번까지의 숫자중에 랜덤으로 1개를 추출해라
t = to_categorical(t, num_classes=10) 
print(t)

문제148. 위의 데이터와 정답을 변경된 신경망에 넣고 오차를 출력하시오 !

답: 
net = simpleNet()
print(net.loss(x,t))

문제149. 다시 신경망의 설계도를 변경하는데 다음과 같이 각층의 뉴런의 갯수를 늘리시오 

변경전:
 입력층          W1          output       W2        output       W3         output 
     (1,  784)   ◎  ( 784, 5 ) ---> (1, 5)  ◎ ( 5, 4 ) ---> ( 1, 4 ) ◎ ( 4, 10)  ---> ( 1, 10 )
       
변경후:
         입력층          W1           output          W2        output       W3         output 
     (1,  784)   ◎  ( 784, 50 ) ---> (1, 50)  ◎ ( 50, 20 ) ---> ( 1, 20 ) ◎ ( 20, 10)  ---> ( 1, 10 )
       
답:

%cd /content/drive/MyDrive/yys

import  sys, os
sys.path.append(os.pardir) 
import  numpy  as  np
from common.functions  import  softmax, cross_entropy_error, sigmoid

class  simpleNet:
    def  __init__(self): # 클래스(설계도)를 가지고 객체(제품) 를 만들때 바로 작동하는 함수 
        self.W1 = np.random.randn(784,50)  
        self.W2 = np.random.randn(50,20)
        self.W3 = np.random.randn(20,10)

    def predict(self,x):  # 입력값을 받아서 소프트 맥스 함수에 값을 제공하는 값까지 값을 생성하는 함수 
        k = np.dot( x, self.W1 )   # 은닉1층
        k_prime = sigmoid(k)     # 은닉 1층의 시그모이드 함수
        m = np.dot( k_prime, self.W2)  # 은닉2층
        m_prime = sigmoid(m)           # 은닉2층의 시그모이드 함수
        n = np.dot( m_prime, self.W3)  # 은닉3층 
        return  n

    def  loss( self, x, t ):
        z = self.predict(x)  # 입력값을 받아서 은닉3층에서 발생한 값을 z 변수에 입력
        y = softmax(z)      # z 변수의 값을 소프트 맥스 함수에 넣어서 확률벡터를 y 에 담는다. 
        loss = cross_entropy_error(y, t)  # 확률벡터와 one hot encoding 된 정답을 받아서 오차를 출력하는 함수
        return  loss   # 오차를 리턴합니다. 

문제148. 위의 뉴런수 늘린 신경망의 오차함수에 147번에서 만든 데이터와 정답을 입력하고 
            오차를 출력하시오

--- 147번에서 만든 데이터
x = np.random.randn(1,784)

from tensorflow.keras.utils  import  to_categorical
t = np.random.randint(0, 10, 1 )  # 0 번 부터 9번까지의 숫자중에 랜덤으로 1개를 추출해라
t = to_categorical(t, num_classes=10) 

net = simpleNet()
print( net.loss(x,t) )

지금까지는 이미지를 1장만 입력해서 오차를 출력했습니다. 

문제149.  입력 데이터를 한장(1x784) 이 아니라 100장(100x784) 으로 준비하세요 

답:
x = np.random.randn(100,784)
print(x.ndim) # 2차원

문제150. 정답도 100개를 생성하세요 ! (원핫 인코딩된 벡터 100개 생성)

답:
from  tensorflow.keras.utils  import  to_categorical

t = np.random.randint(0, 10, 100)
t = to_categorical( t, num_classes=10)
print(t.shape)  # (100, 10 )

문제151.  방금 만든 입력 데이터(100개)와 정답 데이터(100개) 을 net 신경망의 오차함수에
             넣고 오차를 출력하시오 !

1.   1개의 데이터를 입력했을때 
net = simpleNet()
print ( net.loss(x,t) )

2.  100개의 데이터를 입력했을때
net = simpleNet()
print ( net.loss(x,t) )

설명:  1개의 이미지를 넣든 100개의 이미지를 넣든 오차는 하나만 나옵니다.
        1개의 이미지에 대한 오차는 그 이미지에 대한 오차이고 100개의 이미지에 대한 오차는
        100개의 이미지의 오차들의 평균값이 출력 되는 것입니다.

  A 시험(시험문제 1문제)  ---> 100점 만점 

  B 시험(시험문제100문제) ---> 100점 만점 

  오차 / 입력된 데이터의 갯수 

  하나로 입력된 데이터의 오차는 1로 나눈것이고 100개의 데이터로 입력되면 100개 로 나누는것입니다

 오차를 출력하는 함수 cross_entropy_error 함수 입니다.  이 함수의 코드 p118 에 나오는데 보십시오

 코렙에서 cross_entropy_error 함수의 코드를 확인하는 방법

문제152. 텐써플로우에 내장된 mnist 데이터를 불러오시오 !

답:
from  tensorflow.keras.datasets.mnist  import  load_data

(x_train, y_train), (x_test, y_test) = load_data(path='mnist.npz')
print(x_train.shape)  # (60000, 28, 28)  3차원 데이터 입니다.
print(y_train.shape)  # (60000,  ) 정답 숫자 6만개 

문제153. 훈련 데이터에서 데이터 100개와 정답 100개를 뽑아서 x 변수와 t 변수에 각각
             넣으시오 !

답:
x = x_train[0:100]
t = y_train[0:100]
print(x.shape)  #(100, 28, 28)

우리가 오전에 만든 신경망에 데이터를 넣을때는 (100,28, 28) 로 넣으면 안되고 (100, 784)
로 넣어줘야합니다. 

       입력층          W1               output          W2                output       W3          output 
(100,  784)   ◎  ( 784, 50 ) ---> (100, 50)  ◎ ( 50, 20 ) ---> ( 100, 20 ) ◎ ( 20, 10)  ---> ( 100, 10 )
       
문제154.  입력 데이터의 shape 를 (100, 28, 28) 을 (100, 784) 로 reshape 하시오 !

x = x_train[0:100].reshape(100,28*28)
print (x.shape)  # (100, 784)

문제155.  출력되는 결과 행렬의 shape 가 (100,10) 이므로 정답도 (100,10) shape 여야합니다.
             그런데 지금 y_train[0:100] 는 shape 가 (100, ) 입니다. 그냥 숫자 100개 입니다.
             그래서 정답도 (100, ) 에서 원핫인코딩된 행렬인 (100,10) 으로 변경해서 t 변수에 
             담아주세요~

       입력층          W1               output          W2                output       W3          output 
(100,  784)   ◎  ( 784, 50 ) ---> (100, 50)  ◎ ( 50, 20 ) ---> ( 100, 20 ) ◎ ( 20, 10)  ---> ( 100, 10 )
       
답: 
t = to_categorical(y_train[0:100])
print(t.shape)  # (100, 10)

문제156. (점심시간 문제) 위에서 만든 입력데이터 x 와 정답 데이터 t 를 오전에 설계한 3층 신경망에
              넣고 오차를 출력하시오 !  (가급적 full code 로 올려주세요)


 1. 텐써 플로우를 이용해서 3층 신경망 (학습도 다 할 수 있는 신경망)

 2. 책에 나온데로 신경망이 어떻게 만들어지는지 원리를 이해하기 위해서 
    직접 파이썬으로 신경망을 생성

▩ 오전에 만든 신경망에 바이어스 추가하기 

 바이어스를 추가해야하는 이유 ?   " 신경망의 신호를 더 잘 활성화 시키기 위해서 "
바이어스를 추가하지 않았을때의 그림:

       입력층          W1               output          W2                output       W3          output 
(100,  784)   ◎  ( 784, 50 ) ---> (100, 50)  ◎ ( 50, 20 ) ---> ( 100, 20 ) ◎ ( 20, 10)  ---> ( 100, 10 )
 
바이이스를 추가했을때의 그림 :
      
  입력층               W1               output1   + b1                               W2            output2   + b2
(100,  784)   ◎  ( 784, 50 ) ---> (100, 50)  + ( 1, 50 )--> (100,50) ◎  ( 50, 20 ) --> (100,20) +  (1,20)
        
                        W3              output3  + b3            최종 output
--> (100,20) ◎  (20, 10) ---> ( 100, 10) + (1, 10) ---->  (100, 10)

바이어스는 가중치 처럼 np.random.randn 을 써서 평균 0 이고 표준편차가 1 인 가우시안 정규분포를 따르는
난수로 생성하지 않고 0 이나 1로 생성을 합니다. 그리고 학습이 되면서 이 바이어스 값이 가중치 처럼
변경이 됩니다. 
                                            
문법:  
def  __init__(self):      # 만들 때 바로 작동하는 함수
        self.W1 = np.random.randn(784, 50)
        self.b1  = np.zeros(50) 
        self.W2 = np.random.randn(50, 20)
        self.b2  = np.zeros(20)
        self.W3 = np.random.randn(20, 10)
        self.b3  = np.zeros(10)
        print('3층 신경망이 생성되었습니다.')

 def predict(self,x):
        k = np.dot( x, self.W1 )  + self.b1
        k_prime = sigmoid(k) 
        m = np.dot( k_prime, self.W2 ) + self.b2
        m_prime = sigmoid(m) 
        n = np.dot( m_prime, self.W3 ) + self.b3
        return  n

문제157.  점심시간 문제 코드에서 바이어스를 추가한 코드로 오차를 출력하시오 

%cd /content/drive/MyDrive/yys

import  sys, os
sys.path.append(os.pardir) 
import  numpy  as  np
from common.functions  import softmax, cross_entropy_error, sigmoid
# common 폴더 안에 functions.py 모듈 안의
# softmax 함수와 cross_entropy_error, sigmoid 함수를 가져와라

class  multiNet:   # 클래스(설계도)를 가지고 객체(제품)를
    def  __init__(self):      # 만들 때 바로 작동하는 함수
        self.W1 = np.random.randn(784, 50)
        self.b1  = np.zeros(50) 
        self.W2 = np.random.randn(50, 20)
        self.b2  = np.zeros(20)
        self.W3 = np.random.randn(20, 10)
        self.b3  = np.zeros(10)
        print('3층 신경망이 생성되었습니다.')


# 입력값을 받아 소프트맥스 함수에 제공하는 값까지 생성하는 함수
    def predict(self,x):
        k = np.dot( x, self.W1 ) + self.b1 
        k_prime = sigmoid(k) 
        m = np.dot( k_prime, self.W2 ) + self.b2
        m_prime = sigmoid(m) 
        n = np.dot( m_prime, self.W3 )  + self.b3
        return  n

    def  loss( self, x, t ):
        z = self.predict(x)
        y = softmax(z)
        loss = cross_entropy_error(y, t)
        return  loss 

# mnist 데이터 로드
from tensorflow.keras.datasets.mnist import load_data
(x_train, y_train),(x_test, y_test) =  load_data(path='mnist.npz')

# 입력 데이터 생성
x = x_train[0:100].reshape(100, 28*28)

# 정답 데이터 생성
from  tensorflow.keras.utils import  to_categorical
t = to_categorical(y_train[0:100])

# 오차 확인
net = multiNet()
print( net.loss(x,t) )


문제158. 신경망의 정확도를 출력하는 accuracy 함수를 생성하시오 !
            ( 나중에 학습 시킬때 정확도 데이터를 저장해서 정확도가 학습 될때마다
              점점 올라가는지 시각화하기 위해서 필요합니다.)

텐써 플로우에서는 그냥 단지 history=model.fit( ....... ) 라고 하면 history 에 오차와 정확도가
차곡차곡 학습될때마다 저장이 되었습니다. 

답:
net = simpleNet()

x = np.random.randn(100, 784)
t = np.random.randint(0, 10, 100)
t = to_categorical(t)

def  accuracy(x, t):
    y = net.predict(x)
    y = np.argmax(y, axis=1)  # 예측한 숫자
    t  = np.argmax(t, axis=1) # 정답 숫자
    acc = np.sum(y==t) / x.shape[0]
    return  acc

print ( accuracy(x,t) )

문제159. 위의 accuracy 함수를 점심시간 문제로 만들었던 simpleNet 클래스(설계도) 에
            맨 마지막에 추가하시오 !


%cd /content/drive/MyDrive/yys

import  sys, os
sys.path.append(os.pardir) 
import  numpy  as  np
from common.functions  import softmax, cross_entropy_error, sigmoid
# common 폴더 안에 functions.py 모듈 안의
# softmax 함수와 cross_entropy_error, sigmoid 함수를 가져와라

class  multiNet:   # 클래스(설계도)를 가지고 객체(제품)를
    def  __init__(self):      # 만들 때 바로 작동하는 함수
        self.W1 = np.random.randn(784, 50)
        self.b1  = np.zeros(50) 
        self.W2 = np.random.randn(50, 20)
        self.b2  = np.zeros(20)
        self.W3 = np.random.randn(20, 10)
        self.b3  = np.zeros(10)
        print('3층 신경망이 생성되었습니다.')


# 입력값을 받아 소프트맥스 함수에 제공하는 값까지 생성하는 함수
    def predict(self,x):
        k = np.dot( x, self.W1 ) + self.b1 
        k_prime = sigmoid(k) 
        m = np.dot( k_prime, self.W2 ) + self.b2
        m_prime = sigmoid(m) 
        n = np.dot( m_prime, self.W3 )  + self.b3
        return  n

    def  loss( self, x, t ):
        z = self.predict(x)
        y = softmax(z)
        loss = cross_entropy_error(y, t)
        return  loss 

    def  accuracy(self, x, t):
        y = self.predict(x)
        y = np.argmax(y, axis=1)  # 예측한 숫자
        t  = np.argmax(t, axis=1) # 정답 숫자
        acc = np.sum(y==t) / x.shape[0]
        return  acc

# mnist 데이터 로드
from tensorflow.keras.datasets.mnist import load_data
(x_train, y_train),(x_test, y_test) =  load_data(path='mnist.npz')

# 입력 데이터 생성
x = x_train[0:100].reshape(100, 28*28)

# 정답 데이터 생성
from  tensorflow.keras.utils import  to_categorical
t = to_categorical(y_train[0:100])

# 오차 확인
net = multiNet()
print( net.loss(x,t) )

문제160. 지금 설계도에 추가한 accuracy 함수를 실행해서 정확도를 출력하시오 !


%cd /content/drive/MyDrive/yys

import  sys, os
sys.path.append(os.pardir) 
import  numpy  as  np
from common.functions  import softmax, cross_entropy_error, sigmoid
# common 폴더 안에 functions.py 모듈 안의
# softmax 함수와 cross_entropy_error, sigmoid 함수를 가져와라

class  multiNet:   # 클래스(설계도)를 가지고 객체(제품)를
    def  __init__(self):      # 만들 때 바로 작동하는 함수
        self.W1 = np.random.randn(784, 50)
        self.b1  = np.zeros(50) 
        self.W2 = np.random.randn(50, 20)
        self.b2  = np.zeros(20)
        self.W3 = np.random.randn(20, 10)
        self.b3  = np.zeros(10)
        print('3층 신경망이 생성되었습니다.')


# 입력값을 받아 소프트맥스 함수에 제공하는 값까지 생성하는 함수
    def predict(self,x):
        k = np.dot( x, self.W1 ) + self.b1 
        k_prime = sigmoid(k) 
        m = np.dot( k_prime, self.W2 ) + self.b2
        m_prime = sigmoid(m) 
        n = np.dot( m_prime, self.W3 )  + self.b3
        return  n

    def  loss( self, x, t ):
        z = self.predict(x)
        y = softmax(z)
        loss = cross_entropy_error(y, t)
        return  loss 

    def  accuracy(self,x, t):
        y = self.predict(x)
        y = np.argmax(y, axis=1)  # 예측한 숫자
        t  = np.argmax(t, axis=1) # 정답 숫자
        acc = np.sum(y==t) / x.shape[0]
        return  acc

# mnist 데이터 로드
from tensorflow.keras.datasets.mnist import load_data
(x_train, y_train),(x_test, y_test) =  load_data(path='mnist.npz')

# 입력 데이터 생성
x = x_train[0:100].reshape(100, 28*28)

# 정답 데이터 생성
from  tensorflow.keras.utils import  to_categorical
t = to_categorical(y_train[0:100])

# 오차 확인
net = simpleNet()
print( net.accuracy(x,t) )

지금까지는 순전파만 구현 했습니다. 지금 부터는 신경망이 학습이 되게 해줘야 합니다.

학습이 되게하려면 가중치와 바이어스를 기울기를 가지고 갱신을 해줘야합니다. 

가중치 = 가중치 - 기울기 
바이어스 = 바이어스 - 기울기 

위의 작업을 계속 반복하면 경사 하강해나가다 보면 필기체 데이터를 분류할 수 있는
신경망으로 완성이 됩니다.  이 부분을 구현하는 함수가 하나가 필요합니다.

함수 이름이 numerical_gradient 함수입니다. (p 127 ~ 128 에 만들었던 편미분 함수)

문제120번에 만들었습니다.  그런데 common 패키지에 있는 코드를 불러와서 쓰겠습니다.

from  common.gradient  import  numerical_gradient

 numerical_gradient는 함수와 입력값을 넣어서 기울기를 출력하는 함수입니다.

문제161. 지금 방금 그린 오차함수를 생성하시오 !

그림: https://cafe.daum.net/oracleoracle/Shyl/495

답: 
def  function_2(x):
    return  x[0]**2 + x[1]**2

문제162.  위의 오차함수를 편미분하여 x0 이 3이고 x1 이 4 인 지점에서의 기울기를 구하시오 !
            ( 그림에서 x 축이 여기서는 x0 이고 그림에서 y축에 여기에서는 x1 입니다.)

from  common.gradient  import  numerical_gradient

numerical_gradient( function_2,  np.array([3.0, 4.0]) )  
                               ↑                ↑
                            오차함수      기울기를 구할 지점 

문제163. 위에서 만든 기울기를 출력하는 numerical_gradient 함수를 이용해서 경사하강하는
             gradient_descent 라는 함수를 생성하시오 ! ( p131)

답:

def  gradient_descent( f, init_x, lr=0.01, step_num=100):
    x = init_x

    for  i  in  range(step_num):
        grad = numerical_gradient(f, x)  # 오차함수(f) 의 x(지점)에서의 기울기를 구해서
        x -= lr * grad   # x(지점) 에서 러닝레이트 x 기울기 만큰 차감해서 새로운 x(지점)으로 이동
    return  x  # 최종 도착한 지점이 리턴됩니다.

 gradient_descent( 함수명, 지점위치) # 러닝 레이트와 step_num 은 기본값으로 수행됩니다. 

문제164. 위에서 만든 경사하강하는 gradient_descent 함수를 실행해서 (-3.0 ,4.0) 지점에서 
            출발해서 global mininum 인 (0, 0) 에 도달하는지 실험하시오 !

그림 4-10 

답:

def  function_2(x):
    return  x[0]**2 + x[1]**2

init_x = np.array([-3.0, 4.0])

result = gradient_descent( function_2, init_x=init_x, lr=0.1, step_num=100) 
result.round()  # array([-0.,  0.])

출력되는것은 100 번 걸어내려가서 도착한 도착지점입니다. 

array([-6.11110793e-10,  8.14814391e-10])

배운것을 활용하는 주제

딥러닝 목차 

■ 패션 mnist 데이터 한장 넣고 맞춰보기

패션 mnist 데이터는 옷과 신발, 가방과 같은 데이터 셋인데 28x28 의 흑백이미지 데이터
입니다. 훈련 데이터 60000만장, 테스트 10000장입니다. 

문제165. 패션 mnist 데이터를 불러와서 이미지 하나를 시각화 하세요 ~

답:
# 1. 패션 mnist 불러오는 코드
import  tensorflow  as  tf
from  tensorflow.keras.datasets.fashion_mnist  import  load_data
(x_train, y_train), (x_test, y_test) = load_data()

# 2. 시각화 하는 코드
import matplotlib.pyplot  as  plt
aa = x_train[0].reshape(28,28)
plt.imshow(aa)

문제166. 위의 x_train[0] 데이터의 정답 y_train[0] 이 무엇이지 출력하시오 !

print(y_train[0]) 

target_dict = {
 0: 'T-shirt/top',
 1: 'Trouser',
 2: 'Pullover',
 3: 'Dress',
 4: 'Coat',
 5: 'Sandal',
 6: 'Shirt',
 7: 'Sneaker',
 8: 'Bag',
 9: 'Ankle boot',
}

target_dict[9]

문제167.  fashion mnist 데이터를 학습 시켜서 모델을 fashion_model.h5 로 저장하시오 !

# 1. mnist 데이터를 불러옵니다.
import  tensorflow  as  tf
from tensorflow.keras.datasets.fashion_mnist import load_data

(x_train, y_train), (x_test, y_test) = load_data() 

# 2.1  28x28 의 shape 를 1 x 784 로 변경합니다.

x_train = x_train.reshape(60000,28*28)  # 신경망에 입력하려면 (60000, 768) 로 변경해야하기때문에
x_test  = x_test.reshape(10000, 28*28)  # reshape 해서 변경합니다.

x_train = x_train/255.0    # 학습이 잘되게 정규화를 진행합니다. 
x_test = x_test/255.0      # 0~1 사이의 숫자로 변경합니다.

# 2.2 정답 데이터를 준비합니다. (p98 원핫인코딩을 해야합니다.)
 
from  tensorflow.keras.utils import  to_categorical

y_train = to_categorical(y_train) # 정답을 [0, 0, 0, 0, 1, 0, 0, 0, 0, 0 ] 로 변경합니다. 
y_test = to_categorical(y_test)
print ( y_train.shape)  # (60000, 10)

# 3. 모델을 구성합니다.

from  tensorflow.keras.models  import  Sequential
from  tensorflow.keras.layers    import  Dense

model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(784, ) ) )  # 1층
model.add(Dense(128, activation='relu' ) )  # 2층
model.add(Dense( 10, activation='softmax') )  # 3층 

# 4. 모델을 설정합니다. (경사하강법과 오차함수를 정의해줍니다. 4장에서 배웁니다)

model.compile(optimizer='adam',  # 경사하강법 
                     loss='categorical_crossentropy',  #오차함수
                     metrics=['acc'] )  # 학습과정에서 정확도를 보려고 지정

# 5. 모델을 훈련 시킵니다.

model.fit( x_train, y_train, epochs=30, batch_size=100)

#model.fit( 훈련데이터, 정답, 에폭수, 배치사이즈) 
# 에폭수 :  학습횟수 (책을 몇번 볼건지)
# 배치사이즈:  한번에 학습할 양 ( 사람은 책을 한번에 한페이지 밖에 못보지만 컴퓨터는 한번에
#                  여러 페이지를 볼 수 있다)

# 6. 모델을 평가합니다. (시험을 봅니다.)

model.eval‎uate(x_test, y_test)  # 테스트 데이터 10000장으로 모델의 성능을 평가합니다.

model.save('fashion_model.h5')  # 모델을 저장합니다. 

%pwd

문제168.  저장한 모델인 fashion_model.h5 를 불러와서 신경망을 구성한후 테스트 데이터의 정확도
             를 확인하시오 !

# 1. 필요한 패키지 가져오는 코드 

import tensorflow as tf   # 텐써 플로우 2.0 
from tensorflow.keras.datasets.fashion_mnist import load_data
from tensorflow.keras.utils import to_categorical # one encoding 하는 모듈

tf.random.set_seed(777)

(x_train, y_train), (x_test, y_test) = load_data()  # fashion mnist 데이터 로드
    
# 2. 정규화 진행 

# 3차원 ---> 2차원으로 차원축소하고서 정규화 진행  ( 한 픽셀이 0~255 로 되어있는데)
# 0 ~ 1 사이로 변경 
x_train = (x_train.reshape((60000, 28 * 28))) / 255 
x_test = (x_test.reshape((10000, 28 * 28))) / 255

# 3. 정답 데이터를 준비한다. 

# 하나의 숫자를 one hot encoding 한다. (예:  4 ---> 0 0 0 0 1 0 0 0 0 0 ) 
y_train = to_categorical(y_train)  # 훈련 데이터의 라벨(정답)을 원핫 인코딩
y_test = to_categorical(y_test)    # 테스트 데이터의 라벨(정답)을 원핫 인코딩 

# 4. 모델을 불러옵니다.

from tensorflow.keras.models import load_model

new_model = load_model('fashion_model.h5')  # 모델을 로드 합니다. 

# 5.모델을 평가합니다. (오차, 정확도가 출력됩니다.)

new_model.eval‎uate(x_test, y_test)

[0.41405418515205383, 0.885699987411499]

설명: 이미지 10개중에 9개는 맞출 수 있는 모델입니다.

문제169. 한장의 사진을 넣고 시각화 합니다.

aa = x_test[4].reshape(28,28)
plt.imshow(aa)

문제170. 시각화된 사진을 new_model 에 입력해서 예측값을 출력합니다.

results = new_model.predict(x_test[4].reshape(1,784))
np.argmax(results)

target_dict = {
 0: 'T-shirt/top',
 1: 'Trouser',
 2: 'Pullover',
 3: 'Dress',
 4: 'Coat',
 5: 'Sandal',
 6: 'Shirt',
 7: 'Sneaker',
 8: 'Bag',
 9: 'Ankle boot',
}

문제171. y_test[4] 의 정답이 뭔지 확인하세요.

t = y_test[4]
np.argmax(t)


지금까지는 new_model 을 생성을 해봤습니다.  

문제172.  테스트 데이터 10000장 중에 하나를 시각화를 하고 이미지 캡쳐를 해서
             d:\\data100 폴더 밑에 확장자를 aaa.jpg 로 해서 저장하시오 !

bbb = x_test[703].reshape(28,28)
plt.imshow(bbb)

문제173. /content/drive/MyDrive/yys/data200 폴더 밑에 있는 aaa.jpg 파일을 숫자로 변경하시오 ! 

1. 코렙에  /content/drive/MyDrive/yys/ 밑에 data200 폴더를 만든다.
2. data200 폴더에 aaa.jpg 사진을 upload 합니다. 

import  cv2   #  이미지 데이터 전처리하는 모듈
import  os    #   os 의 파일들을 인식하기 위해서 필요한 모듈

path="/content/drive/MyDrive/yys/data200"      # 설현사진이 있는 위치를 path 변수에 넣습니다. 
file_list = os.listdir(path)  # d\\data100 폴더 안에 있는 파일 리스트를 file_list 변수에 입력
for  k  in  file_list:          # 여러개의 파일이 있을거라 가정하고 for loop문으로 구현
    img = cv2.imread(path +  '/' + k)  #  이미지를 숫자로 변경합니다.
print(img)  
print(img.shape) # (165, 201, 3)  ,  ( 가로 픽셀사이즈, 세로 픽셀 사이즈, 색조)

문제174. /content/drive/MyDrive/yys  폴더 밑에 resize100 이라는 폴더를 만들고 aaa.jpg 를 
           28x28 로 resize 해서 resize100 폴더에  저장 되게 하시오 !

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

for k in file_list:            # data100 폴더의 파일을 하나씩 불러옵니다. 
    img = cv2.imread(path + '/' + k)  # 그 파일을 숫자로 변경합니다. 
    resize_img = cv2.resize(img, (28 , 28), interpolation=cv2.INTER_CUBIC)  # 가로 28, 세로 28로 사이즈 변경
    cv2.imwrite('/content/drive/MyDrive/yys/resize100/' + k, resize_img)    # d 드라이브 밑에 resize100 폴더에 저장합니다.
    
plt.imshow(resize_img)
plt.show()    
print(resize_img.shape)

문제175.  resize 한 이미지를 흑백 처리 합니다.

j= '/content/drive/MyDrive/yys/resize100/aaa.jpg'
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

def rgb2gray(rgb):   # 어떤 컬러 사진이든 제대로 흑백 사진으로 나오게 하기 위해 사용하는 함수
    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])

img = mpimg.imread(j)  # 이미지를 불러와서 숫자로 변경합니다. 
gray = rgb2gray(img)

plt.imshow(gray, cmap = plt.get_cmap('gray'))  # 진짜 흑백 사진으로 변경하는 코드
plt.show()
print(gray.shape)

문제176. (오늘의 마지막 문제) 흑백처리한 이미지를 new_model 에 넣고 예측한 값과 정답이 일치하는지
          확인하시오 ! 

cv2.imwrite('/content/drive/MyDrive/yys/data200/aaa.jpg', gray)

import  matplotlib.image  as  mpimg

k="/content/drive/MyDrive/yys/data200/aaa.jpg"

img2 = mpimg.imread(k)
img2.shape  # (28, 28)

x = img2.reshape(1,784)
print(x.shape)  # (1, 784)

results = new_model.predict(x)                  
np.argmax(results)                               마지막 문제 올리시고 자유롭게 자습하세요 ~~~
 

세현이 코드:
import cv2 # 이미지를 전처리하는 opencv 모듈

# 사진 로드
fname = 'dress.jpg'
img = cv2.imread(fname)
img = cv2.bitwise_not(img) # 학습데이터처럼 바탕을 검은색으로 만들기 위한 코드

# 로드한 사진 흑백처리
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
def rgb2gray(rgb):  # 흑백으로 색깔을 변경하기 위한 함수 
    return np.dot(rgb[ :, :, : ], [0.299, 0.587, 0.114])                    

gray_img = rgb2gray(img)  # 컬러를 흑백으로 변환 

# 흑백처리한 사진 학습을 위해 resize, reshape
resize_img = cv2.resize(gray_img,(28,28), interpolation = cv2.INTER_CUBIC)
x = resize_img.reshape(1,784)
plt.figure
plt.imshow(resize_img)

results = new_model.predict(x)
print("예측: ", target_dict[np.argmax(results)])

■ 4장. 학습 알고리즘 구현하기 p136 

 "2층 신경망 구현하기"

큰 숲을 먼저 보고 구현하겠습니다.

클래스(설계도) 이름: TwolayerNet 

            1.  __init__  :  가중치 행렬과 바이어스 행렬을 생성 
            2. predict  :   모델의 층을 구현해서 값을 예측함
            3. loss      :   predict 함수와 cross_entropy_error 함수를 실행해서 오차를 출력
            4. accuracy  :  predict 함수를 실행해서 값을 예측하고 정답과 비교해서 정확도를 출력
            5. numerical_gradient :  기울기를 구하는 함수

클래스를 객체화 시켜서 학습시키는 단계

1단계- 미니배치
2단계- 기울기 산출
3단계 - 매개변수 갱신
4단계 - 1단계~3단계를 반복 

문제177. 어제 구현한 3층 신경망의 클래스 이름을 TwoLayerNet 이라는 이름을 변경하시오 !

게시글 515번. 점심시간 문제로 수행한 3층 신경망의 순전파 코드를 가져옵니다.

%cd /content/drive/MyDrive/yys

import  sys, os
sys.path.append(os.pardir) 
import  numpy  as  np
from common.functions  import  softmax, cross_entropy_error, sigmoid 
# common 폴더 안에 functions.py 모듈안에 softmax 함수와 cross_entropy_error 함수를 가져와라
from tensorflow.keras.utils import to_categorical

class  TwoLayerNet : 
    def  __init__(self):  
        self.W1 = np.random.randn(784,50)  #  
        self.W2 = np.random.randn(50,20)
        self.W3 = np.random.randn(20,10)
        print('3층 신경망이 생성되었습니다')
    
    def  predict( self, x ):
        k = np.dot( x, self.W1 ) 
        k_prime = sigmoid(k) 
        m = np.dot( k_prime, self.W2)
        m_prime = sigmoid(m) 
        n = np.dot( m_prime, self.W3)
        return  n

    def  loss( self, x, t ):
        z = self.predict(x) # 입력값을 받아서 은닉 3층에서 발생한 값을 z변수에 입력
        y = softmax(z)      # z변수의 값을 소프트맥스함수에 넣어서 확률벡터 y를 담는다.
        loss = cross_entropy_error(y, t) # 확률벡터와 원핫인코딩된 정답을 받아서 오차를 출력하는 함수
        return  loss

    def  accuracy(self,x, t):
        y = self.predict(x)
        y = np.argmax(y, axis=1)  # 예측한 숫자
        t  = np.argmax(t, axis=1) # 정답 숫자
        acc = np.sum(y==t) / x.shape[0]
        return  acc

net = TwoLayerNet()

from tensorflow.keras.datasets.mnist import load_data
(x_train, y_train), (x_test, y_test) = load_data(path = 'mnist.npz')

x = x_train[0:100].reshape(100,28*28)

t = to_categorical(y_train[0:100])
t = t.reshape(100,10)
net.loss(x,t)

문제178. 위의 코드를 실행하면 아래의 경고 메세지가 나오는데 이를 해결하시오 !

  RuntimeWarning: overflow encountered in exp return 1 / (1 + np.exp(-x))

 자연상수 e 의 지수의 값을 너무 큰값을 줘서 발행하는 경고 메세지 입니다.

답:   정규화를 하면 해결됩니다.  각 픽셀을 255로 나눠서 0~1 사이의 숫자로 변경하면 됩니다.

net = multipleNet()

from tensorflow.keras.datasets.mnist import load_data
(x_train, y_train), (x_test, y_test) = load_data(path = 'mnist.npz')

x = x_train[0:100].reshape(100,28*28)
x = x/255   <---  이 부분을 추가 하면 됩니다. 

문제179.  기존 설계도는 3층 신경망인데 2층 신경망으로 변경하시오 !

class  TwoLayerNet:
    def  __init__(self):  # multipleNet 클래스(설계도)의 객체(제품)가 만들어질 때 자동으로 실행되는 함수
        self.W1 = np.random.randn(784,50)  #   1층의 가중치
        self.b1 = np.zeros(50)             #   1층의 바이어스
        self.W2 = np.random.randn(50,10)   #   2층(출력층)의 가중치
        self.b2 = np.zeros(10)             #   2층(출력층)의 바이어스
        print('2층 신경망이 생성되었습니다')
    
    def  predict( self, x ):
        k = np.dot( x, self.W1 )  + self.b1  # 1층
        k_prime = sigmoid(k)                 # 1층 시그모이드
        m = np.dot( k_prime, self.W2) + self.b2 # 2층(출력층)
        n = softmax(m)                          # 2층(출력층) 의 소프트 맥스 함수
        return  n

    def  loss( self, x, t ):
        z = self.predict(x) # 입력값을 받아서 은닉 3층에서 발생한 값을 z변수에 입력
        loss = cross_entropy_error(z, t) # 확률벡터와 원핫인코딩된 정답을 받아서 오차를 출력하는 함수
        return  loss

문제180.  가중치와 바이어스를 신경망 학습할 때 변경되게 하기 쉽도록 키와 값으로 구성된
             딕셔너리 구조로 생성하시오 !

  가중치 = 가중치 - 기울기
  바이어스 = 바이어스 - 기울기 

 위의 작업이 일어나야하는데 가중치가 W1, W2 도 있고 바이어스도 b1, b2  있습니다.
 이렇게 4개의 행렬이 존재하기 때문에 나중에 학습할 때 각각 별도의 서랍장에 분리가 되어있어서
 꺼내기 쉽게 또 변경하기 쉽게 딕셔너리(서랍장) 형태로 보관하고 있어야 합니다. 

class  TwoLayerNet: 
    def  __init__(self):  # multipleNet 클래스(설계도)의 객체(제품)가 만들어질 때 자동으로 실행되는 함수
        self.params={}
        self.params['W1'] = np.random.randn(784,50)  #   1층의 가중치
        self.params['b1'] = np.zeros(50)             #   1층의 바이어스
        self.params['W2'] = np.random.randn(50,10)   #   2층(출력층)의 가중치
        self.params['b2'] = np.zeros(10)             #   2층(출력층)의 바이어스
        print('2층 신경망이 생성되었습니다')
    
    def  predict( self, x ):
        W1, W2 = self.params['W1'], self.params['W2']
        b1, b2 = self.params['b1'], self.params['b2']
        k = np.dot( x, W1 ) + b1  # 1층
        k_prime = sigmoid(k)                 # 1층 시그모이드
        m = np.dot( k_prime, W2) + b2 # 2층(출력층)
        n = softmax(m)                          # 2층(출력층) 의 소프트 맥스 함수
        return  n


문제181. 순전파 신경망 코드는 다 구현했고 이제부터는 학습이 되게 오차함수의 기울기를
            출력하는 numerical_gradient 함수를 설계도 추가하시오 !

           w1 의  기울기 (784,50) =   numerical_gradient( 오차함수,  w1 )  # (784, 50) 의 w1 의 가중치
           b1 의  기울기 (1, 50)  =   numerical_gradient( 오차함수, b1)  # (1, 50)  의 바이어스
           w2 의  기울기 (50, 10) =  numerical_gradient( 오차함수,  w2 )  # (50, 10) 의 w2 의 가중치
           b2 의  기울기 (1, 10)   =  numerical_gradient( 오차함수, b2) # (1, 10) 의 바이어스

# 4장에서 구현한 기울기 구하는 함수
def  numerical_gradient( self, x, t):
    loss_W = lambda  W : self.loss(x, t)
    grads = {}
    grads['W1'] = numerical_gradient( loss_W , self.params['W1'])
    grads['b1'] =  numerical_gradient( loss_W, self.params['b1'])
    grads['W2'] = numerical_gradient( loss_W, self.params['W2'])
    grads['b2'] =  numerical_gradient( loss_W, self.params['b2'])
    return  grads

설명:  numerical_gradient 함수내에 또 numerical_gradient  가 있어서 재귀함수인지 오해할 수 있는데
         재귀함수는 아니고 그냥 기능이 다른 함수가 이름만 같은 것입니다. 

문제182. 지금 설계도에 추가한 numerical_gradient 를 실행하시오 !

%cd /content/drive/MyDrive/yys

import  sys, os
sys.path.append(os.pardir) 
import  numpy  as  np
from common.functions  import  softmax, cross_entropy_error, sigmoid 
# common 폴더 안에 functions.py 모듈안에 softmax 함수와 cross_entropy_error 함수를 가져와라
from tensorflow.keras.utils import to_categorical
from common.gradient  import  numerical_gradient

class  TwoLayerNet: 
    def  __init__(self):  # multipleNet 클래스(설계도)의 객체(제품)가 만들어질 때 자동으로 실행되는 함수
        self.params={}
        self.params['W1'] = np.random.randn(784,50)  #   1층의 가중치
        self.params['b1'] = np.zeros(50)             #   1층의 바이어스
        self.params['W2'] = np.random.randn(50,10)   #   2층(출력층)의 가중치
        self.params['b2'] = np.zeros(10)             #   2층(출력층)의 바이어스
        print('2층 신경망이 생성되었습니다')
    
    def  predict( self, x ):
        W1, W2 = self.params['W1'], self.params['W2']
        b1, b2 = self.params['b1'], self.params['b2']
        k = np.dot( x, W1 ) + b1  # 1층
        k_prime = sigmoid(k)                 # 1층 시그모이드
        m = np.dot( k_prime, W2) + b2 # 2층(출력층)
        n = softmax(m)                          # 2층(출력층) 의 소프트 맥스 함수
        return  n

    def  loss( self, x, t ):
        z = self.predict(x) # 입력값을 받아서 은닉 3층에서 발생한 값을 z변수에 입력
        loss = cross_entropy_error(z, t) # 확률벡터와 원핫인코딩된 정답을 받아서 오차를 출력하는 함수
        return  loss

    def  accuracy(self,x, t):
        y = self.predict(x)
        y = np.argmax(y, axis=1)  # 예측한 숫자
        t  = np.argmax(t, axis=1) # 정답 숫자
        acc = np.sum(y==t) / x.shape[0]
        return  acc
    
    # 4장에서 구현한 기울기 구하는 함수
    def  numerical_gradient( self, x, t):
        loss_W = lambda  W : self.loss(x, t)
        grads = {}
        grads['W1'] =  numerical_gradient( loss_W , self.params['W1'])
        grads['b1'] =  numerical_gradient( loss_W, self.params['b1'])
        grads['W2'] =  numerical_gradient( loss_W, self.params['W2'])
        grads['b2'] =  numerical_gradient( loss_W, self.params['b2'])
        return  grads

net = TwoLayerNet()

from tensorflow.keras.datasets.mnist import load_data
(x_train, y_train), (x_test, y_test) = load_data(path = 'mnist.npz')

x = x_train[0:100].reshape(100,28*28)
x = x/255

t = to_categorical(y_train[0:100])
t = t.reshape(100,10)

net.numerical_gradient(x,t)

지금까지는 신경망의 설계도(클래스)를 완성했습니다. 지금 부터는 신경망에 데이터를 넣고
학습시키는 아래의 4단계를 구현 해보겠습니다. 

클래스를 객체화 시켜서 학습시키는 단계

1단계- 미니배치
2단계- 기울기 산출
3단계 - 매개변수 갱신
4단계 - 1단계~3단계를 반복 

문제183.  위의 클래스(설계도)를 객체(제품) 화 시키고 1단계를 구현하시오 !

# 1. 설계도로 제품을 만듭니다. 
net = TwoLayerNet() 

#2. 필기체 데이터를 로드합니다. 
from tensorflow.keras.datasets.mnist import load_data
(x_train, y_train), (x_test, y_test) = load_data(path = 'mnist.npz')

#3. 입력데이터를 구성합니다. 
x_train = x_train.reshape(60000,28*28)
x_train = x_train/255

#4. 정답데이터를 구성합니다.
y_train = to_categorical(y_train)
y_train = y_train.reshape(60000,10)

for  i  in  range(3):
    batch_mask = np.random.choice(60000, 100)  # 0부터 60000까지의 숫자중에서 100개의 숫자를 랜덤으로 추출
    x_batch = x_train[batch_mask]  # 100개의 이미지 데이터를 추출
    t_batch = y_train[batch_mask]  # 100개의 정답 데이터를 추출
    grad = net.numerical_gradient(x_batch, t_batch)
    print(grad)

지금 구현한 코드는 미니배치를 하긴 했는데 전체 60000장 중에 300개만 학습했습니다. 

300개가 아니라 전체 60000장을 다 학습시키고 싶다면?

for  i  in  range(600):
    batch_mask = np.random.choice(60000, 100)  # 0부터 60000까지의 숫자중에서 100개의 숫자를 랜덤으로 추출
    x_batch = x_train[batch_mask]  # 100개의 이미지 데이터를 추출
    t_batch = y_train[batch_mask]  # 100개의 정답 데이터를 추출
    grad = net.numerical_gradient(x_batch, t_batch) # 기울기 산출
    print(grad)

600x100 = 60000 이니까 for 문을 600 번 돌려야 60000 장 전체를 다 학습하는 것입니다.
60000 전체를 다 학습한게 바로 1 에폭(epoch) 입니다. 

지금까지의 코드는 미니배치를 하면서  기울기를 뽑아보았는데 4장의 방법(오차함수를 미분해서
가중치를 갱신)으로 학습을 시키면 정확하게 학습은 되지만 시간이 너무 오래 걸립니다. 
1에폭만 돌려도 아마 1시간 이상 걸립니다.  5장에서 배울 오차역전파를 구현한 함수를 가져다가
그 함수로 기울기를 구해서 학습을 시키겠습니다. 

4장: 수치미분으로 기울기를 산출 ( 속도가 너무 느립니다.)
5장: 오차역전파로 기울기를 산출 ( 아주 빠르게 수행됩니다.)

1단계- 미니배치
2단계- 기울기 산출  <----  5장의 오차역전파로 기울기를 산출하는 함수를 사용합니다. 
3단계 - 매개변수 갱신
4단계 - 1단계~3단계를 반복 

카페에 529번 게시글에 올렸습니다. 

문제184. 5장에서 배울 오차역전파로 기울기를 산출하는 함수인 gradient 함수를 설계도 맨아래에
             추가하시오 !

1. 맨위의 코드에 sigmoid_grad 를 추가합니다.
from common.functions  import  softmax, cross_entropy_error, sigmoid , sigmoid_grad

2. 맨아래의 코드에 numerical_gradient 대신 gradient 함수를 쓰세요 ~

for  i  in  range(600):  
    batch_mask = np.random.choice(60000, 100)  # 0부터 60000까지의 숫자중에서 100개의 숫자를 랜덤으로 추출
    x_batch = x_train[batch_mask]  # 100개의 이미지 데이터를 추출
    t_batch = y_train[batch_mask]  # 100개의 정답 데이터를 추출
    grad = net.gradient(x_batch, t_batch)
    print(grad)

4장의 수치미분을 이용해서 기울기를 구하는 함수를 사용했다면 30시간 걸릴 일을 
5장에서 배울 오차 역전파로 기울기를 구하는 함수를 썼더니 1분도 안되어서 끝났습니다.

문제185. (점심시간 문제)  위의 코드는 1에폭만 돌린 코드 입니다. 30 에폭이 돌도록 코드를 수정하고
            전체 full  code 를 올려서 검사 받으세요 ~~

for  i  in  range(600*30): # 600x100(배치사이즈) = 60000 x 30(에폭)
    batch_mask = np.random.choice(60000, 100)  # 0부터 60000까지의 숫자중에서 100개의 숫자를 랜덤으로 추출
    x_batch = x_train[batch_mask]  # 100개의 이미지 데이터를 추출
    t_batch = y_train[batch_mask]  # 100개의 정답 데이터를 추출
    grad = net.gradient(x_batch, t_batch)
    print(grad)

문제186. 위의 코드는 기울기를 구하는 코드이고 실제로 될려면 가중치와 바이어스가 변경이 되어야
            하므로 가중치와 바이어스를 변경하는 코드를 위의 코드 아래에 추가하시오

net.params['W1'] = net.params['W1'] - 0.1 * grad['W1']
net.params['b1'] = net.params['b1'] - 0.1 * grad['b1']
net.params['W2'] = net.params['W2'] - 0.1* grad['W2']
net.params['b2'] = net.params['b2'] - 0.1 *grad['b2']

위의 코드를 for loop 문으로 구현하면?

for  key  in ('W1', 'b1', 'W2', 'b2'):
    net.params[key] -= 0.1 * grad[key]

문제187. 학습이 되고 있는지 확인하기 위해서 오차를 출력하시오 !

loss = net.loss(x_batch, t_batch)
train_loss_list.append(loss)

문제188. 위에서 담은 train_loss_list 에 있는 오차값을 가지고 x 축을 에폭수로 하고 y 축을 오차로
            해서 시각화 하시오 !

import  matplotlib.pyplot  as  plt

x = np.arange( len(train_loss_list) )
plt.plot( x, train_loss_list, label='train loss')
plt.ylim(0, 1.0)
plt.show()

문제189. 위의 코드를 수정해서 1 에폭마다 오차가 train_loss_list 에 append 되도록 하시오 !

loss = net.loss(x_batch, t_batch)

    if  i % 600==0:   # i 를 600 으로 나눈 나머지값이 0 이 1 에폭입니다. 
        train_loss_list.append(loss)

# 그리고 다시 시각화
import  matplotlib.pyplot  as  plt

x = np.arange( len(train_loss_list) )
plt.plot( x, train_loss_list, label='train loss')
plt.ylim(0, 7.0)
plt.show()

문제190. 이번에는 정확도를 train_acc_list 에 append 시키시오 

train_loss_list=[] # 오차값을 저장할 리스트
train_acc_list =[] # 정확도를 저장할 리스트 
for  i  in  range(600*30):
    batch_mask = np.random.choice(60000, 100)  # 0부터 60000까지의 숫자중에서 100개의 숫자를 랜덤으로 추출
    x_batch = x_train[batch_mask]  # 100개의 이미지 데이터를 추출
    t_batch = y_train[batch_mask]  # 100개의 정답 데이터를 추출
    grad = net.gradient(x_batch, t_batch)
    
    for  key  in ('W1', 'b1', 'W2', 'b2'):
        net.params[key] -= 0.1 * grad[key]
    
    loss = net.loss(x_batch, t_batch)

    if  i % 600==0: # 1에폭 마다
        train_loss_list.append(loss)
        train_acc = net.accuracy(x_train, y_train)
        train_acc_list.append(train_acc)

print(train_acc_list)

import  matplotlib.pyplot  as  plt

x = np.arange( len(train_acc_list) )
plt.plot( x, train_acc_list, label='train acc')
plt.ylim(0, 1)
plt.show()

문제191. 위의 그래프는 훈련 데이터에 대한 정확도만 나오기 때문에
             오버피팅 여부를 확인할 수가 없습니다.  테스트 데이터까지 같이 추가하여
             테스트 데이터에 대한 정확도를 test_acc_list 변수에 담으시오 


문제192.  train_acc_list 와 test_acc_list 에 담긴 정확도를 같이 시각화 해서 오버피팅이 발생하고 
             있는지 확인하시오 !

import  matplotlib.pyplot  as  plt

x = np.arange( len(train_acc_list) )
plt.plot( x, train_acc_list, label='train acc')
plt.plot( x, test_acc_list, label='test acc',  linestyle='--')
plt.ylim(0, 1)
plt.legend(loc='lower right')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.show()

설명: 30 에폭 돌때까지는 정확도도 점점 좋아지고 있고 오버피팅도 발생하지 않았습니다. 


문제193. 30에폭을 40 에폭으로 늘려서 수행하고 시각화해서 정확도가 계속 더 올라가고 
            오버피팅이 일어나는지 확인하시오 

현업에서는 텐써 플로우 아니면 파이토치로 신경망을 구현하므로 앞에 내용을 잘 이해못했다 하더라도
아래의 코드만 확실하게 알면 됩니다. 

문제194.  위의 시각화 결과를 텐써 플로우로 구현하시오 !

게시글 550번 :[쉬움주의] 4장 137페이지의 2층 신경망을 텐써 플로우로 구현한다면?

# 0. 필요한 패키지 가져오는 코드 
import tensorflow as tf   # 텐써 플로우 2.0 
from tensorflow.keras.datasets.mnist import load_data  # 텐써플로우에 내장되어있는 mnist 데이터를 가져온다.
from tensorflow.keras.models import Sequential  # 모델을 구성하기 위한 모듈
from tensorflow.keras.layers import Dense  # 완전 연결계층을 구성하기 위한 모듈
from tensorflow.keras.utils import to_categorical # one hot encoding 하는 모듈

tf.random.set_seed(777)

# 1. 필기체 데이터를 불러옵니다.
(x_train, y_train), (x_test, y_test) = load_data(path='mnist.npz')  # mnist 데이터 로드
    
# 2. 정규화 진행  
x_train = (x_train.reshape((60000, 28 * 28))) / 255 
x_test = (x_test.reshape((10000, 28 * 28))) / 255

# 3. 정답 데이터를 준비한다. 
# 하나의 숫자를 one hot encoding 한다. (예:  4 ---> 0 0 0 0 1 0 0 0 0 0 ) 
y_train = to_categorical(y_train)  # 훈련 데이터의 라벨(정답)을 원핫 인코딩
y_test = to_categorical(y_test)    # 테스트 데이터의 라벨(정답)을 원핫 인코딩 


# 4. 모델을 구성합니다. 2층 신경망으로 구성

model = Sequential()
model.add(Dense(50, activation = 'sigmoid', input_shape = (784, )))  # 1층
model.add(Dense(10, activation = 'softmax'))  # 2층 출력층 


# 5. 모델을 설정합니다. ( 경사하강법, 오차함수를 정의해줍니다. )

model.compile(optimizer='SGD',  # 경사하강법의 종류를 확률적 경사하강법으로 지정
              loss = 'categorical_crossentropy',  # 분류의 오차함수 
              metrics=['acc'])  # 학습과정에서 정확도를 보려고 

#6. 모델을 훈련시킵니다. 

history = model.fit(x_train, y_train, 
                    epochs = 30,  # 30에폭
                    batch_size = 100)

# 7.모델을 평가합니다. (오차, 정확도가 출력됩니다.)

model.eval‎uate(x_test, y_test)

문제195. 학습과정에서 에폭마다의 훈련 데이터의 정확도 30개를 train_acc_list 에 담으시오 !

train_acc_list=history.history['acc']
train_acc_list

문제196. 학습과정에서 에폭마다의 테스트 데이터의 정확도 30개를 test_acc_list 에 담으시오 !

#6. 모델을 훈련시킵니다. 

history = model.fit(x_train, y_train, 
                         epochs = 30,  # 30에폭
                         batch_size = 100,
                         validation_data=(x_test, y_test) )

test_acc_list=history.history['val_acc']
test_acc_list

문제197. 4장 마지막 코드처럼 위의 결과(훈련 데이터의 정확도, 테스트 데이터의 정확도) 를
             같이 시각화 하시오 !

import  matplotlib.pyplot  as  plt

x = np.arange( len(train_acc_list) )
plt.plot( x, train_acc_list, label='train acc')
plt.plot( x, test_acc_list, label='test acc',  linestyle='--')
plt.ylim(0, 1)
plt.legend(loc='lower right')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.show()

여기까지가 4장입니다. 

■ 화장하는 인공지능 코드 구현하기

 https://github.com/kairess/BeautyGAN

Download pretrained model

https://pan.baidu.com/s/1wngvgT0qzcKJ5LfLMO7m8A，7lip
https://drive.google.com/drive/folders/1pgVqnF2-rnOxcUQ3SO4JwHUFTdiSe5t9

4개의 파일 다운로드 받고 45분까지 쉬세요 ~~

# 특정 깃허브의 원작자의 모든 코드와 파일들을 나의 구글 드라이브로 다운로드 받는 명령어
%cd /content/drive/MyDrive/yys4
!git clone https://github.com/kairess/BeautyGAN  

리눅스 서버를 올리시고 putty 로 접속하세요 ~

1.리눅스 10문제 (빅데이터 플렛폼 아키텍쳐 설계)
2.하둡 몽고디비 10문제 (빅데이터 플렛폼 요구사항 분석) 

답안을 결과 캡쳐해서 제출하셔야 합니다.

제출파일 이름: 빅데이터 플렛폼 아키텍쳐 설계_전인훈
                    빅데이터 플렛폼 요구사항 분석_전인훈 


문제9. root 유져에서 아래의 텍스트 파일을 a.txt 라는 이름으로 생성하고 a.txt 의 소유자를 
          oracle 로 그룹명도 oracle 로 변경하세요.

■ 딥러닝 수업 복습

1장. Numpy 에 신경망에서 왜 필요한지?
2장. 퍼셉트론
3장. 3층 신경망(저자가 만들어온 가중치 피클파일을 신경망에 셋팅) 구현
4장. 2층 신경망(수치미분을 이용해서 신경망을 직접 학습 시킴)
5장. 2층 신경망(오차역전파를 이용해서 신경망을 직접 학습 시킴)
6장. 신경망 학습 시키는 방법들(언더피팅, 오버피팅 막는 방법들 소개)
7장. CNN 을 신경망 
8장. 딥러닝을 활용한 새로운 기술들을 소개 ( GAN 신경망 : 일반 사진을 미술작품으로 변환, 기타)

딥러닝을 활용한 최종 포트폴리오 구현하기 위해 미리 알아야하는 내용들
 
1. R shiny 를 이용해서 딥러닝 신경망을 활용하는 홈페이지를 구현
2. object detection 을 이용한 신경망 구현
3. 인공지능 오목 프로그램 신경망 개발
4. 기타
                                                           
■ 5장. 오차역전파를 이용한 2층 신경망 구현 

"4장의 수치미분을 이용한 신경망을 생성해서 mnist 필기체 데이터를 학습을 시켰는데
 너무 학습이 느려서 우리가 끝까지 학습 시키지 않았습니다. 
 수치미분이 너무 느리므로 신경망을 학습 시킬때는 오차 역전파를 이용해서 학습을 시킵니다."

 5장의 내용은 오차 역전파를 이용해서 학습을 시킨다는게 어떤것인지를 배우게 됩니다.

            수치미분으로 기울기 구하는 함수   vs   오차역전파로 기울기 구하는 함수 
                ( numerical_gradient 함수)                         ( gradient )


▩ 오차역전파로 기울기 구하는 함수

 아래의 함수는 기울기를 구할 때 수치미분을 구하는 numerical_gradient 함수 처럼 미분을 해서
  기울기를 구하는게 아니라 사람이 함수를 직접 손으로 수학식을 미분해서 도함수를 구해서
  도함수를 이용해서 기울기를 구하는 함수 

예제: f(x) = 2*x^2 + 3x + 7   

       x가 3인 지점에서의 미분계수(기울기)를 구해라 ~


   이렇게 사람이 직접 도함수를 구해서 그 도함수에 값을 대입해서 미분계수(기울기) 를 구하겠금
   하는것이 오차역전파를 이용해서 기울기를 구하는 gradient 함수 입니다. 

    numerical_gradient 는 미분을 해야했지만 gradient 는 그냥 방정식이 되었습니다. 

 5장은 신경망의 함수들(시그모이드, 렐루, 소프맥스, 오차함수)을 미분해서 도함수를 구해서 
 그 도함수를 아래의 gradient 함수에 셋팅하는게 5장의 내용입니다. 

  def gradient(self, x, t):
        W1, W2 = self.params['W1'], self.params['W2']  # 가중치 W1 과 W2 를 가져오는 코드
        b1, b2 = self.params['b1'], self.params['b2']      # 바이어스 b1 과 b2 를 가져오는 코드
        grads = {}                                                 # 기울기를 담기위한 딕셔너리를 생성 
     
        batch_num = x.shape[0]                            # (100, 784) 에서 배치사이즈 100을 가져오는 코드 

        # forward
        a1 = np.dot(x, W1) + b1               # 순전파 1층 구현
        z1 = sigmoid(a1)                         # 순전파 1층의 sigmoid 함수 통과
        a2 = np.dot(z1, W2) + b2             # 순전파 2층(출력층)을 구현
        y = softmax(a2)                          # 소프트맥스함수를 통과해서 확률백터를 출력

        # backward                               # 오차를 역전파하는 역전파 코드 
        dy = (y - t) / batch_num             # 오차함수와 소프트맥스함수의 도함수 (예측값-정답)
        grads['W2'] = np.dot(z1.T, dy)      # 2층신경망의 가중치에 대한 역전파를 구현한 코드(기울기 생성)
        grads['b2'] = np.sum(dy, axis=0)  # 2층신경망의 바이어스에 대한 역전파 구현 코드  (기울기 생성)

        da1 = np.dot(dy, W2.T)             #  2층 신경망의 역전파를 구현한 코드(기울기로 가중치 변경)
        dz1 = sigmoid_grad(a1) * da1    # 1층 신경망의 시그모이드 함수의 도함수의 값을 출력하겠금 구현
        grads['W1'] = np.dot(x.T, dz1)    #  1층 신경망의 가중치의 역전파 (기울기 생성)
        grads['b1'] = np.sum(dz1, axis=0) # 1층 신경망의 바이어스의 역전파 (기울기 생성)
        return grads         
                                     45분까지 쉬세요 ~~

■ 계산 그래프를 이용해서 신경망 순전파를 구현하기  (p148)

 신경망 순전파와 역전파 코드를 파이썬으로 구현할때 계산 그래프(플로우 차트)를 이용하면
 쉽게 구현할 수 가 있습니다. 

예: 책 148 페이지 그림 5-1

▦ 왜 계산 그래프를 이용해서 순전파 신경망에대한 코드를 구현하려 하는가?

 전체가 아무리 복잡해도 각 노드에서 수행되는 단순한 계산에만 집중해서 문제를 단순화 시키겠다.
        ↓                                             ↓
  신경망이 아무리 복잡해도         1층 노드에만 집중하거나, 2층 노드에만 집중하거나 해서 

 큰 문제를 단순화 시키겠다. 

그림 5-2  

첫번째 노드에서는 사과의 가격 200원이 어떻게 나왔는지에 대한 계산에만 집중을 하고
두번째 노드에서는 사과의 가격 200원의 소비세(10%)  를 적용해서 220원이 어떻게 계산되었는지만
집중하겠다.

그림 5-3

그림5-2 보다는 조금더 복잡한 계산이 이뤄지고 있지만 국소적 계산이 이뤄지고 있는 부분은 
4군데로 각 뉴런이 담당하고 있는 계산에만 집중하면 되고 다른 뉴런에서 어떤일이 벌어지는지는
신경쓰지 않아도 됩니다. 


그림 5-4 

전체가 아무리 복잡해도 각 노드에서 수행되는 단순한 계산에만 집중하여 문제를 단순화 시킬수 
있습니다.

■ 왜 계산 그래프로 신경망의 구현 문제를 푸는가 ?  p151

  신경망 전체가 아무리 복잡해도 각 노드에서 수행되는 단순한 계산에만 집중하여
  문제를 단순화 시킬 수 있기 때문입니다.  

그림 5-5 


설명:  순전파는 100-->200-->220 으로 값이 전파되고 있고 역전파는 다시 거꾸로
        1 --> 1.1 ---> 2.2 순으로 미분값을 전달하면서 역전파 되는것 입니다.

■ 계산 그래프의 역전파 (p153)

  역전파를 통해서 미분을 효율적으로 계산을 할 수 있는데 

              W1                   W2 
  입력값 ------->  1층 ---------------->  출력층 -----------------> 오차함수 ---> 오차
                       ↓                             ↓                               ↓
                  시그모이드 함수         소프트 맥스 함수             교차 엔트로피 함수 

이중에서 가중치(W1) 의 기울기는 어떻게 구할 수 있는가 ?  

신경망 학습을 통해서 최종적으로 산출하고 하는것은 ?     오차가 가장 적은 가중치 
                                 ↓ 
'가중치(w1)' 에 변화가 생겼을 때  '오차' 는 얼마나 달라지는가 ? 
                                 ↓ 
'사과값' 이 아주 조금 올랐을때 '지불금액' 이 얼마나 증가되는지 알고 싶다면 ?

 ∂지불금액
-------------                     사과값이 1원이 더 오르면 지불금액이 얼마나 더 증가하나요? 2.2 원
 ∂ 사과값 

 지불금액을 사과값으로 편미분하면 알 수 있습니다.  (그림 5-5)

 ∂ 오차함수 
------------  =  기울기 ( W1 을 갱신시키기 위한 기울기) 
  ∂  W1  

■ 계산 그래프의 역전파(p153) 


그림 5-6


문제186. 아래의 기울기(미분계수)를 구하시오 !

https://cafe.daum.net/oracleoracle/Shyl/568

그림 5-6


문제187. (점심시간 문제)  아래의 기울기(미분계수) 를 구하시오 !
https://cafe.daum.net/oracleoracle/Shyl/570

그림 5-6

오전에 배운 내용은 수치미분 보다 오차 역전파가 훨씬 속도가 빠르므로 오차 역전파로 기울기를
구해서 가중치를 갱신한다는게 무엇인지 배울려고 무엇을 이용해서 쉽게 이해하려고 했나요?

 " 계산 그래프 "  


■ 합성함수 미분(p153) 

 신경망에는 활성화 함수가 여러개 이므로 합성함부 미분을 알아야 신경망 오차 역전파를
 이해 할 수 있습니다.

   z = t^2 
   t = x + y   

   ∂z
  -----  =  식 5.2  
   ∂x 

■ 연쇄법칙과 계산 그래프(p154)

그림 5-7  -------------> 그림 5-8


   z = t^2 
   t = x + y   

■ 덧셈 노드의 역전파 (p156)

  z = x + y              그림5-9


덧셈노드의 역전파 값은 상류에서 전해진 값이 그대로 흘러갑니다. 

■ 곱셈 노드의 역전파 (p157)

 z = xy

그림 5-12

곱셈노드의 역전파는 상류에서 흘러왔던 값에 상대편쪽의 값을 곱해주는것

문제188. 아래의 덧셈 노드의 역전파 값을 쓰시오 ! (https://cafe.daum.net/oracleoracle/Shyl/598)




문제189. 아래의 곱셈 노드의 역전파 값을 쓰시오 !



문제190.  책 p161 페이지에 나오는 곱셈계층 클래스(설계도) 파이썬으로 구현하시오 !

class MulLayer:
    def __init__(self):
        self.x = None
        self.y = None

    def forward(self, x, y):  # 순전파 함수 
        self.x = x
        self.y = y
        out = x*y   
        return  out

    def backward(self, dout):  # 역전파 함수 
        dx = dout * self.y
        dy = dout * self.x
        return dx, dy

문제191. 위에서 만든 곱셈 클래스(설계도) 를 객체화(제품) 시켜서 아래의 사과 가격을 구하시오 !


apple=100
apple_num = 2

mul_apple_layer = MulLayer() # 곱셈계층
apple_price = mul_apple_layer.forward(apple, apple_num)
print(apple_price)

문제192. 덧셈 계층 클래스를 파이썬으로 구현하시오 ! (P 163) 

class AddLayer:
    def __init__(self):
        self.x = None
        self.y = None 

    def  forward(self, x, y):
        self.x = x
        self.y = y
        out = x + y
        return  out

    def backward(self, dout):
        dx = dout
        dy = dout 
        return  dx, dy 

문제193. 그림 5-2 계산 그래프를 곱셈 클래스를 이용해서 구현하시오 !

apple = 100
apple_num = 2
tax = 1.1 

# 계층들
mul_apple_layer= MulLayer() 
mul_tax_layer = MulLayer()

# 순전파
apple_price = mul_apple_layer.forward( apple, apple_num )
price = mul_tax_layer.forward( apple_price, tax)
print(price)

문제194. 그림 5-2 에 대한 역전파 그림을 먼저 그리시오 !

그림: https://cafe.daum.net/oracleoracle/Shyl/599

답: https://cafe.daum.net/oracleoracle/Shyl/600

apple = 100
apple_num = 2
tax = 1.1 

# 계층들
mul_apple_layer= MulLayer() 
mul_tax_layer = MulLayer()

# 순전파
apple_price = mul_apple_layer.forward( apple, apple_num )
price = mul_tax_layer.forward( apple_price, tax)
print(price)

# 역전파 (p164 페이지 참고)
dprice=1
dall_price, dtax = mul_tax_layer.backward(dprice)
dapple_price, dapple_num = mul_apple_layer.backward(dall_price)
print(dapple_price)  # 2.2
print(dapple_num)   # 110 

문제195. 위에서 만든 곱셈 클래스와 덧셈 클래스를 이용해서 그림 5-17의 순전파를 구현해서 
            과일 가격만 출력하시오 !

apple= 100
apple_num =2
orange = 150
orange_num = 3
tax = 1.1 

# 계층들
mul_apple_layer = MulLayer()
mul_orange_layer = MulLayer()
add_apple_orange_layer=AddLayer()
mul_tax_layer= MulLayer()

# 순전파
apple_price = mul_apple_layer.forward(apple, apple_num)
orange_price = mul_orange_layer.forward(orange, orange_num)
all_price = add_apple_orange_layer.forward(apple_price, orange_price)
price = mul_tax_layer.forward(all_price, tax) 
print(price) # 715 
                             

■  파이토치를 이용하여 흑백처리와 resize 를 간단하게

 이번 실습은 

1. 지난번에 했던 패션 mnist 데이터를 학습 시켜서 만든 신경망의 모델을 저장하고
   저장된 모델이 잘 불러와지는지 확인합니다.

2. 불러온 모델에 옷이나 신발 사진을 컬러 상태 그대로 입력해서 분류를 할 것입니다.

3. 컬러사진 ---> 흑백처리 ---> 28x28 로 resize 를 합니다. 

   지난번에 이 작업을 하기 위해서 폴더를 2개 만들고 함수를 2개나 이용해서 복잡하게
   수행했는데 이를 한번에 간단하게 할 수 있는 기능이 파이토치에 있습니다. 
   파이토치의 신기능을 이용해서 수행할 것입니다.

4.  전처리한 이미지를 신경망에 넣고 잘 맞추는지 확인

   이때 색을 반전시키는 opencv 의 함수(세현이가 알아낸 함수)를 이용해서 전처리할 것입니다.

# 실험 시작

1. 패션 mnist 데이터를 학습 시켜 모델을 준비합니다.

# 1. mnist 데이터를 불러옵니다.
import  tensorflow  as  tf
from tensorflow.keras.datasets.fashion_mnist import load_data  # 패션 mnist 데이터를 불러옵니다. 

(x_train, y_train), (x_test, y_test) = load_data()  # 훈련과 테스트로 데이터를 불러옵니다. 

# 2.1  28x28 의 shape 를 1 x 784 로 변경합니다.

x_train = x_train.reshape(60000,28*28)
x_test  = x_test.reshape(10000, 28*28)

x_train = x_train/255.0  # 정규화 
x_test = x_test/255.0

# 2.2 정답 데이터를 준비합니다. (p98 원핫인코딩을 해야합니다.)
 
from  tensorflow.keras.utils import  to_categorical # 오차함수에 정답을 제공하기 위해서 one hot encoding

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)
print ( y_train.shape)  # (60000, 10)

# 3. 모델을 구성합니다.

from  tensorflow.keras.models  import  Sequential
from  tensorflow.keras.layers    import  Dense

model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(784, ) ) ) # 은닉1층 (W1)
model.add(Dense(128, activation='relu' ) ) # 은닉2층 (W2)
model.add(Dense( 10, activation='softmax') )  # 3층 신경망(W3)

# 4. 모델을 설정합니다. (경사하강법과 오차함수를 정의해줍니다. 4장에서 배웁니다)

model.compile(optimizer='adam',  # 경사하강법 
                     loss='categorical_crossentropy',  #오차함수
                     metrics=['acc'] )  # 학습과정에서 정확도를 보려고 지정

# 5. 모델을 훈련 시킵니다.

model.fit( x_train, y_train, epochs=30, batch_size=100)

#model.fit( 훈련데이터, 정답, 에폭수, 배치사이즈) 
# 에폭수 :  학습횟수 (책을 몇번 볼건지)
# 배치사이즈:  한번에 학습할 양 ( 사람은 책을 한번에 한페이지 밖에 못보지만 컴퓨터는 한번에
#                  여러 페이지를 볼 수 있다)


# 6. 모델을 평가합니다. (시험을 봅니다.)

model.evaluate(x_test, y_test) 

model.save('fashion_model.h5')  # 모델 저장



[쉬움주의] 파이토치를 이용하여 흑백처리와 resize 를 간단하게

 

파이토치로_이미지_한장_전처리해서_신경망에_넣기.ipynb
379.66KB
1. 패션 mnist 데이터를 학습 시켜 모델을 준비합니다.

# 1. mnist 데이터를 불러옵니다.
import  tensorflow  as  tf
from tensorflow.keras.datasets.fashion_mnist import load_data

(x_train, y_train), (x_test, y_test) = load_data() 

# 2.1  28x28 의 shape 를 1 x 784 로 변경합니다.

x_train = x_train.reshape(60000,28*28)
x_test  = x_test.reshape(10000, 28*28)

x_train = x_train/255.0
x_test = x_test/255.0

# 2.2 정답 데이터를 준비합니다. (p98 원핫인코딩을 해야합니다.)
 
from  tensorflow.keras.utils import  to_categorical

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)
print ( y_train.shape)  # (60000, 10)

# 3. 모델을 구성합니다.

#그림: https://cafe.daum.net/oracleoracle/Shyl/183

from  tensorflow.keras.models  import  Sequential
from  tensorflow.keras.layers    import  Dense

model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(784, ) ) ) # 은닉1층
model.add(Dense(128, activation='relu' ) ) # 은닉1층
model.add(Dense( 10, activation='softmax') ) 

# 4. 모델을 설정합니다. (경사하강법과 오차함수를 정의해줍니다. 4장에서 배웁니다)

model.compile(optimizer='adam',  # 경사하강법 
                     loss='categorical_crossentropy',  #오차함수
                     metrics=['acc'] )  # 학습과정에서 정확도를 보려고 지정

# 5. 모델을 훈련 시킵니다.

model.fit( x_train, y_train, epochs=30, batch_size=100)

#model.fit( 훈련데이터, 정답, 에폭수, 배치사이즈) 
# 에폭수 :  학습횟수 (책을 몇번 볼건지)
# 배치사이즈:  한번에 학습할 양 ( 사람은 책을 한번에 한페이지 밖에 못보지만 컴퓨터는 한번에
#                  여러 페이지를 볼 수 있다)


# 6. 모델을 평가합니다. (시험을 봅니다.)

model.eval‎uate(x_test, y_test) 

model.save('fashion_model.h5')

2. 만들어진 모델이 잘 불러와지는지 확인합니다.

# 모델 불러오는 코드

# 1. 모델을 불러옵니다.

from tensorflow.keras.models import load_model

new_model = load_model('fashion_model.h5')

# 2.모델을 평가합니다. (오차, 정확도가 출력됩니다.)

new_model.eval‎uate(x_test, y_test)

[0.3813323378562927, 0.895799994468689]

10개중에 9개 맞추는 신경망입니다.



[쉬움주의] 파이토치를 이용하여 흑백처리와 resize 를 간단하게

 

파이토치로_이미지_한장_전처리해서_신경망에_넣기.ipynb
379.66KB
1. 패션 mnist 데이터를 학습 시켜 모델을 준비합니다.

# 1. mnist 데이터를 불러옵니다.
import  tensorflow  as  tf
from tensorflow.keras.datasets.fashion_mnist import load_data

(x_train, y_train), (x_test, y_test) = load_data() 

# 2.1  28x28 의 shape 를 1 x 784 로 변경합니다.

x_train = x_train.reshape(60000,28*28)
x_test  = x_test.reshape(10000, 28*28)

x_train = x_train/255.0
x_test = x_test/255.0

# 2.2 정답 데이터를 준비합니다. (p98 원핫인코딩을 해야합니다.)
 
from  tensorflow.keras.utils import  to_categorical

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)
print ( y_train.shape)  # (60000, 10)

# 3. 모델을 구성합니다.

#그림: https://cafe.daum.net/oracleoracle/Shyl/183

from  tensorflow.keras.models  import  Sequential
from  tensorflow.keras.layers    import  Dense

model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(784, ) ) ) # 은닉1층
model.add(Dense(128, activation='relu' ) ) # 은닉1층
model.add(Dense( 10, activation='softmax') ) 

# 4. 모델을 설정합니다. (경사하강법과 오차함수를 정의해줍니다. 4장에서 배웁니다)

model.compile(optimizer='adam',  # 경사하강법 
                     loss='categorical_crossentropy',  #오차함수
                     metrics=['acc'] )  # 학습과정에서 정확도를 보려고 지정

# 5. 모델을 훈련 시킵니다.

model.fit( x_train, y_train, epochs=30, batch_size=100)

#model.fit( 훈련데이터, 정답, 에폭수, 배치사이즈) 
# 에폭수 :  학습횟수 (책을 몇번 볼건지)
# 배치사이즈:  한번에 학습할 양 ( 사람은 책을 한번에 한페이지 밖에 못보지만 컴퓨터는 한번에
#                  여러 페이지를 볼 수 있다)


# 6. 모델을 평가합니다. (시험을 봅니다.)

model.eval‎uate(x_test, y_test) 

model.save('fashion_model.h5')

2. 만들어진 모델이 잘 불러와지는지 확인합니다.

# 모델 불러오는 코드

# 1. 모델을 불러옵니다.

from tensorflow.keras.models import load_model

new_model = load_model('fashion_model.h5')

# 2.모델을 평가합니다. (오차, 정확도가 출력됩니다.)

new_model.eval‎uate(x_test, y_test)

3. 테스트할 이미지를 올리기 위해 코렙과 구글 드라이브를 연동합니다.

from google.colab import drive
drive.mount('/content/drive')

4. /content/drive/MyDrive/ 밑에 yys19 폴더를 만듭니다.

5.  /content/drive/MyDrive/yys19 밑에 아래의 dress.jpg 이미지를 올립니다.

6. dress.jpg 를 흑백처리하고 28x28 로 resize 합니다.

%cd /content/drive/MyDrive/yys19

import torch  # 코렙은 알아서 pip 으로 torch 를 설치하고 import 합니다. 
import torchvision.transforms as transforms
import cv2
import matplotlib.pyplot as plt

img_size = (28,28)  # resize 할 가로, 세로 사이즈를 img_size 변수에 할당
img_path = 'dress.jpg'   # 신경망 넣을 이미지 파일명을 img_path 에 할당

img = cv2.imread(img_path) #  이미지를 숫자로 변환합니다. 
img = cv2.bitwise_not(img)  #  색을 반전시키는 코드인데 하얀색을 검정색으로 변경하고 
print(img.shape)           #     (683, 427, 3) 가로 683, 세로 427, 채널3은 rgb 컬러사진
print(img[:, :, ::-1].shape)  #     (683, 427, 3)  원본이미지 bgr ---> rgb 로 채널을 변경


T = transforms.Compose([    # 이미지 전처리를 시작합니다.
    transforms.ToPILImage(),   # 이미지를 Pillow 형태로 변경합니다. 
    transforms.Grayscale(1),    #  흑백처리 합니다. 
    transforms.Resize(img_size), # 28x28 로 resize 합니다. 
    transforms.ToTensor()  # 위에서 전처리한 이미지 데이터를 텐써형태(다차원 배열)로 변환
])

img_input = T(img)  # 이미지 전처리 T 객체에 img 이미지를 넣어서 전처리된 결과를 img_input 
print(img_input.shape)  # 에 넣고 shape 를 봅니다. 

# 결과 :  torch.Size([1, 28, 28])  파이토치의 자료구조로 감싼 다차원 배열이 출력되었습니다. 

11. 전처리한 데이터를 신경망에 넣고 예측합니다.

import numpy as np
img_input.shape  

x = img_input.reshape(1,784)   # 패션 mnist 신경망의 input 사이즈 맞게 reshape 합니다.
print(np.array(x).shape)
x = np.array(x)  #  파이토치 자료구조---> numpy array 로 변경

results = new_model.predict(x)          # 불러온 모델에 x 값을 넣고 예측합니다.     
np.argmax(results)  # 최대원소값의 인덱스 번호를 출력                                         
                                                                  

문제196. (오늘의 마지막 문제) 아래의 티셔츠 사진을 확장자 jpg 저장해서 구글 드라이브에 올리고
             전처리 후 신경망에 넣어서 잘 맞추는지 확인하시오 !

■ 어제 배운 5장 앞부분 내용 복습 

1. 4장에서 배운 수치미분을 해서 기울기를 구하는 numerical_gradient 함수는 너무 느려서
   신경망 학습으로 사용할 수 가 없습니다. 그래서 오차 역전파로 기울기를 구하는 
   gradient함수를 이용해서 기울기를 구해서 신경망 학습을 해야 합니다.

   이 gradient 함수는 역전파를 구현하기 위해서 신경망에 들어가는 함수들
    (활성화함수, 출력층 함수, 오차함수) 을 손으로 미분해서 도함수(방정식)를 코딩한 함수 입니다. 

   이 함수를 쉽게 만들려면 이 함수를 만들기 위한 플로우 차트가 필요한데 그 플로우 차트를
   그리는 계산법이 계산 그래프 입니다.  계산 그래프를 이용하면 쉽게 gradient 함수를  
   만들 수 있습니다. 

   어제 수업은 계산 그래프에서 덧셈노드, 곱셈노드를 구현해보았습니다. 

 def gradient(self, x, t):
        W1, W2 = self.params['W1'], self.params['W2']
        b1, b2 = self.params['b1'], self.params['b2']
        grads = {}
     
        batch_num = x.shape[0]

        # forward
        a1 = np.dot(x, W1) + b1
        z1 = sigmoid(a1)
        a2 = np.dot(z1, W2) + b2
        y = softmax(a2)

        # backward
        dy = (y - t) / batch_num
        grads['W2'] = np.dot(z1.T, dy)
        grads['b2'] = np.sum(dy, axis=0)

        da1 = np.dot(dy, W2.T)
        dz1 = sigmoid_grad(a1) * da1
        grads['W1'] = np.dot(x.T, dz1)
        grads['b1'] = np.sum(dz1, axis=0)
        return grads         

■ 활성화 함수 계층 구현하기  (p165) 

▩ 계산 그래프
   - 뎃셈 그래프
   - 곱셈 그래프
   - 렐루 함수 그래프
   - 시그모이드 함수 그래프
   - 오차함수 교차 엔트로피 함수 그래프(부록)
   - 출력층 함수 소프트 맥스 함수 그래프(부록)

■ 렐루 함수를 위한 계산 그래프 

  0 보다 큰값이 입력이 되면 그 값을 그대로 출력하고 0 이거나 0보다 작은 값이 입력이 되면
  0 을 출력하는 함수 

그림 5-18 


렐루의 함수의 역전파는 x>0 이 순전파일때 흘러갔으면 역전파 일때도 오차가 역으로 흘러 갑니다.
그런데 x <=0 이라면 순전파일때 값이 흘러가지 않았으므로 역전파 일때도 값이 흘러가지 않는것
입니다. 

위의 계산 그래프를 보고 렐루 함수의 계산 그래프를 파이썬으로 구현하려면 2가지를 알아야합니다.

1. copy 모듈 사용법
2. x[ x<=0 ] 의 의미 

▩ 1. copy 모듈 사용법

a = [ 1, 2, 3 ]
b = a   # a가 가리키고 있는곳을 b 도 가리키겠다는 것입니다. 
print (b)
a[1] = 6
print(a)  # [ 1, 6, 3 ]
print(b)  # [ 1, 6, 3 ] 

지금 b는 a 와 같은 곳을 바라보고 있는것이므로 똑같이 [1, 6, 3] 이 출력됩니다. 
그런데 만약에 b 를 위한 [1, 2, 3] 을 만들고 싶다면 copy 를 이용해야 합니다. 

#from  copy  import  copy
a = [ 1, 2, 3]
#b = copy(a)  #  copy 를 했기때문에 b 도 별도의 객체가 됩니다. 
b = a.copy()
a[1] = 6
print(a) # [ 1, 6, 3]
print(b) # [ 1, 2, 3 ]

2. x[x<=0] 의 의미 ?  렐루는 순전파때 신호를 보냈다는 유무를 기억하고 있어야 하기 때문에
                            이 문법이 필요합니다. ( 그 자리에 신호가 보내졌었는가를 기억해야합니다.)

x = np.array([[1.0, -0.5], [-2.0, 3.0]])
print(x)
mask = (x<=0)
print(mask)

[[ 1.  -0.5]
 [-2.   3. ]]

[[False  True]
 [ True False]]

out = x.copy()
out[mask]=0
print(out)

문제197. 책 166 페이지에 나오는 Relu 클래스를 생성하시오 

class Relu:
    def __init__(self):   # Relu 클래스(설계도)로 객체(제품)를 만들때 자동으로 작동되는 함수
        self.mask = None  

    def  forward(self, x):  # 순전파를 구현하는 코드
        self.mask = (x<=0)  
        out = x.copy()
        out[self.mask] =0  # 음수이거나 0보다 같은 요소에 다 0 이 할당됩니다. 
        return out

    def backward(self, dout): # 역전파 코드 
        dout[self.mask]=0
        dx = dout
        return dx         

문제198. 위의 Relu 클래스를 객체화 시켜서 아래의 x 데이터를 흘려보내고 순전파 결과를 출력하시오

x = np.array([[1.0, -0.5], [-2.0, 3.0]])

답:
relu = Relu()
print (relu.forward(x) )

문제199. 위의 Relu 클래스를 객체화 시켜서 아래의 데이터를 역전파로 흘려보내시오 

dout= np.array([[2.0, 3.0], [-3.0, -4.0]])

위의 dout 을 역전파 데이터로 해서 backward 를 실행하려면 순전파가 먼저 수행이 되어서
순전파때 데이터가 흘러갔는지 안 흘러갔는지에 대한 기억이 있어야합니다.
그래서 순전파를 먼저 수행하고 역전파를 수행해야 합니다. 
답:
x = np.array([[1.0, -0.5], [-2.0, 3.0]])
relu = Relu()
print (relu.forward(x) )
dout= np.array([[2.0, 3.0], [-3.0, -4.0]])
print(relu.backward(dout))

■ sigmoid 계층(p167)

  "시그모이드 함수는 값을 입력받아서 0~1사이의 실수로 출력하는 함수"

 식:      식5.9


순전파 계산 그래프:  그림 5-19

문제200. 시그모이드 계층의 순전파(forward 함수)를 sigmoid 클래스를 만들면서 구현하시오 !
             (p170)

class  Sigmoid:
    def  __init__(self)"
        self.out = None
  
    def forward(self, x):
        out = 1 / ( 1 + np.exp(-x) )
        self.out = out
        return  out 

문제201. 위의 sigmoid 클래스를 객체화 시켜서 아래의 데이터를 forward 함수에 넣고 실행하시오

x = np.array([ 24, 32, 5] ) 

답:
sigmoid = Sigmoid()
sigmoid.forward(x)

array([1.        , 1.        , 0.99330715])

▩ 시그모이드 계층의 역전파 코드 구현을 위한 계산 그래프 이해하기

책 167 ~169 페이지까지가 시그모이드 계층의 역전파를 구현하는 계산 그래프 설명 

그림 5-20

https://cafe.daum.net/oracleoracle/Shyl/627

https://cafe.daum.net/oracleoracle/Shyl/628

그림5-21 -->  그림 5-22

순전파일때는 x 값이 중요하지만 역전파일때는 y 값이 중요합니다.

문제202. 그림 5-22 에 최종으로 구한 시그모이드 도함수를 이용해서 sigmoid 클래스의
             역전파(backward) 함수를 구현하시오 

답:
class  Sigmoid:
    def  __init__(self)"
        self.out = None
  
    def forward(self, x):
        out = 1 / ( 1 + np.exp(-x) )
        self.out = out
        return  out 

    def  backward(self, dout):
        dx = dout * (1.0 - self.out) * self.out  # 도함수를 이용해서 기울기를 출력합니다.

        return dx 

문제203. 위의 시그모이드 클래스를 객체화 시켜서 아래의 입력 데이터를 순전파(forward) 함수에
             넣어서 결과를 출력하시오 !

x = np.array( [[1.0, -0.5], [-2.0, 3.0]] ) # 2x2 행렬
sim = Sigmoid()
print ( sim.forward(x) )

[[0.73105858 0.37754067]
 [0.11920292 0.95257413]]

문제204. 이번에는 역전파 함수를 아래의 dout 데이터로 수행하시오!

dout = np.array( [ [ 2.0, 3.0 ], [-3.0, -4.0] ]) 

print( sim.backward(dout) )

[[ 0.39322387  0.70501114]
 [-0.31498076 -0.18070664]]

신경망에서는 순전파일때의 행렬의 shape 그대로 역전파일때도 같은 shape 입니다. 

딥러닝 인공신경망을 현업에서 어떻게 활용하냐면 ?

  1. 정상제품과 불량 제품을 판별하는것을 사람이 대신 기계가 할 수 있게 수행 
  2. 정상 폐사진과 폐결절 사진을 판독을 신경망에게 시킨다.

위의 데이터셋을 코렙에 올리기 

1. 이파리 훈련 데이터와 테스트 데이터를 다운로드 받습니다.

게시글 630번. 정상 이파리와 질병 이파리 데이터

2.  코렙과 구글 드라이브를 연동하세요

from google.colab import drive
drive.mount('/content/drive')

3. /content/drive/MyDrive/ 밑에 leaf 라는 폴더를 만들고 leaf 폴더에 압축파일 2개를 올리세요.

  test.zip  <---  먼저 올리고 
  train.zip  <--- 나중에 올리세요

■ Affine 계층  p170

 신경망의 순전파때 수행하는 행렬의 내적을 기하학에서는 어파인(Affine) 변환이라고 합니다.
  그래서 신경망에서 입력값과 가중치의 내적의 합에 바이어스를 더하는 층을 Affine 계층 이라고
  부르면서 구현을 합니다. 

  앞에서는 sigmoid 와 relu 의 forward 와 backward 를 구현을 했는데
  지금은 입력값과 가중치를 내적하고 바이어스를 더하는 Affine 계층의 forward 와 backward 를
  구현하겠습니다. 

  지금까지의 계산 그래프에서는 노드 사이에 '스칼라값' 이 흘렀는데
  이에 반에 어파인 계층에서는 행렬 내적을 해야하므로 '행렬'이 흐릅니다. 

 그림 5-24



문제205. 책 175 페이지에 나오는 Affine 클래스를 생성하시오 (forward 함수만 구현하세요)

class  Affine:
    def  __init__(self, W, b):
        self.W = W
        self.b = b
        self.dW = None
        self.db  = None

    def  forward(self, x):
        self.x = x
        out = np.dot(x, self.W) + self.b
        return  out

문제206. 위의 Affine 클래스(설계도)로  affine1 이라는 객체를 만들고 아래의 입력값과 가중치와
             바이어스를 이용해서 순전파 결과를 출력하시오 !

x = np.array([1, 2])
W = np.array([[1, 3, 5], [2, 4, 6]])
b = np.array([1, 1, 1]) 

답:

affine1 = Affine(W, b)  # 가중치와 바이어스를 입력하고 객체를 생성한다. 
affine1.forward(x)

결과: array([ 6, 12, 18])

■ Affine 계층의 역전파 구현하기

계산그래프: 그림 5-25

 1. 순전파일 때 흘러갔던 행렬의 shape 그대로 역전파일때도 같은 shape 로 흘러와야합니다. 

문제207.  Affine 클래스의 forward 함수 밑에 backward 함수도 만드시오 !

class  Affine:
    def  __init__(self, W, b):
        self.W = W
        self.b = b
        self.x = None
        self.dW = None
        self.db  = None

    def  forward(self, x):
        self.x = x
        out = np.dot(x, self.W) + self.b
        return  out

    def  backward(self, dout):
        dx = np.dot( dout, sef.W.T)
        self.dW = np.dot( self.x.T, dout)
        self.db = np.sum( dout, axis=0)
        return  dx

문제208.  아래의 입력값과 가중치 행렬값과 dout 행렬값을 넣어서  입력값에 대한 기울기 행렬을
              출력하시오 !

x = np.array([[1, 2]])  # [1, 2] --> (2, )  ,  [[1,2]] --> (1, 2)
W = np.array([[1, 3, 5], [2, 4, 6]])
b = np.array([[1, 1, 1]]) 
dout =np.array([[ 2, 2, 1]])

affine1=Affine(W,b)
affine1.forward(x)
affine1.backward(dout)

위와 같이 대괄호를 한번씩 더 감싸줘야 브로드 케스트 되어서 제대로 연산이 됩니다. 

책은 174 페이지부터 내일 나가겠습니다. 

■ (딥러닝 활용) 텐써플로우를 이용해서 데이터 전처리해서 패션 mnist 신경망에 이미지 입력하기

목차 39번 텐써플로우를 이용하여 흑백처리와 resize 를 간단하게

1. 패션 mnist 데이터를 학습 시켜 모델을 준비합니다.

2. 만들어진 모델이 잘 불러와지는지 확인합니다.

3. 테스트할 이미지를 올리기 위해 코렙과 구글 드라이브를 연동합니다.

4. /content/drive/MyDrive/ 밑에 yys19 폴더를 만듭니다.

5. /content/drive/MyDrive/yys19 밑에 아래의 dress.jpg 이미지를 올립니다.

6. 텐써 플로우를 이용하여 dress.jpg 를 흑백처리하고 28x28 로 resize 합니다.

%cd /content/drive/MyDrive/yys19

import tensorflow as  tf
import cv2

img_path = '/content/drive/MyDrive/yys19/dress.jpg'

img = cv2.imread(img_path)   # 이미지를 숫자로 변환합니다. 
img = cv2.bitwise_not(img)     # 색을 반전 시킵니다. (하얀색 배경을 검정색으로 변경)
print(img.shape)

import tensorflow.compat.v1 as tf   # 텐써플로우 2.0 버전에서 텐써 플로우 1.0 버전의 명령어를 
tf.disable_v2_behavior()                 # 사용하고 싶을때 쓰는 코드

resized_images=tf.image.resize_images(img, (28, 28))  # 텐써 플로우 1.0 의 함수이고 이미지를 resize 하는 함수
a = tf.image.rgb_to_grayscale(resized_images)  # 컬러 이미지를 흑백으로 변경하는 코드
print(a.shape)  (28,28,1)  

7. 전처리한 데이터를 신경망에 넣고 예측합니다.

import numpy as np

x =tf.reshape(a, [ 28,28])  # (28, 28, 1) ---> (28, 28)
x2 =tf.reshape(x, [1, 784]) # (28, 28 )----> (1, 784) 
print(x2.shape)  # (1, 784)

from tensorflow.keras.models import load_model

new_model = load_model('fashion_model.h5')

results = new_model.predict(x2, steps=1) # 사진 1개를 예측하는거라 steps=1 을 씁니다. 

np.argmax(results)  # 결과 확인 

dress 를 잘 맞췄습니다.

문제209.  다음의 티셔츠 사진을 신경망에 넣고 잘 맞추는지 확인합니다. 


문제210. 신발 옆 모습 사진을 구글에서 구해서 신경망에 넣고 예측하시오

■ 어제 배웠던 파이토치의 데이터 전처리하는 코드를 사용한 딥러닝 활용

▩ 일반 사진을 유명 애니메이션 감독의 화풍으로 변환하기 

문제211. (오늘의 마지막 문제)  인터넷에서 애니메이션 이미지로 변환하고 싶은
            사진으로 골라서 변환하고 원본이미지와 결과이미지를 올려서 검사 받으세요 ~

■ 밑바닥 딥러닝 책 1권

1장. numpy 가 신경망에서 왜 필요한지
2장. 퍼셉트론
3장. 3층신경망(저자가 만들어온 가중치로) 구성
4장. 수치미분을 이용한 2층 신경망을 생성해서 학습 시킴
5장. 오차 역전파를 이용한 2층 신경망을 생성해서 학습 시킴

 " 오차가 어떤식으로 역전파되는지를 이해"
                               
   학습이 되려면 기울기를 구해야 하는데 기울기를 미분으로 구하면 시간이 너무 오래걸리므로
   도함수로 기울기를 구해서 학습을 시키자
      ↓
  1. simoid 함수의 도함수 (기울기)
  2. relu  함수의 도함수 (기울기)
  3. Affine 계층의 도함수 (기울기)

■ 배치용 Affine 계층 (p 174) 

  신경망에 이미지를 넣을때는 한장씩 넣어서 학습 시키지 않고 
  여러장을 한꺼번에 넣어서 학습을 시키기 때문에 배치 단위 학습을 하는 Affine 계층을 이해
  해야 합니다.

class  Affine:
    def  __init__(self, W, b):
        self.W = W
        self.b = b
        self.x = None
        self.dW = None
        self.db  = None

    def  forward(self, x):
        self.x = x
        out = np.dot(x, self.W) + self.b
        return  out

    def  backward(self, dout):
        dx = np.dot( dout, self.W.T)
        self.dW = np.dot( self.x.T, dout)
        self.db = np.sum( dout, axis=0)
        return  dx

# 배치처리전
x = np.array([[1, 2]])   # (1, 2)
W = np.array([[1, 3, 5], [2, 4, 6]])
b = np.array([[1, 1, 1]]) 
dout =np.array([[ 2, 2, 1]])

affine1=Affine(W,b)
affine1.forward(x)  # array([[ 6, 12, 18]])
#affine1.backward(dout)

# 배치처리후
x = np.array([[1, 2],[3, 4],[4, 1], [2, 3], [9, 1] ])    # (5, 2)                                        2 2 1
W = np.array([[1, 3, 5], [2, 4, 6]])        # (2, 3)                                                    2 2 1
b = np.array([[1, 1, 1]])                     #(1, 3)                                                    2 2 1
dout =np.array([[ 2, 2, 1],[ 2, 2, 1],[ 2, 2, 1],[ 2, 2, 1],[ 2, 2, 1]])  # (5, 3)                   2 2 1
                                                                                                                2 2 1
affine1=Affine(W,b)
affine1.forward(x)  # array([[ 6, 12, 18]])                                 np.sum(dout,  axis = 0 )
affine1.backward(dout)
affine1.db

문제212. 설현 사진 1장(1,28,28) ------> 설현 사진 5장(5, 28, 28) # 3차원
             설현 사진 5장을 생성하시오 !

답:
x = np.random.randn(5, 28*28)  # 2차원 (이미지를 flatten)
print(x.shape)

문제213. 설현사진 5장과 내적할 가중치(W) 를 생성하는데 뉴런의 갯수를 3개로 하시오 

답:
W = np.random.randn(28*28, 3 )  

문제214. 설현 사진 5장과 문제213번에서 만든 가중치와의 내적의 결과 행렬과 덧셈 행렬을 할
             바이어스(b) 행렬을 생성하시오 !

답:
b = np.random.randn( 1 ,  3  )                             
                                                                    
문제215. 위에서 만든 x(입력값), W(가중치), b(바이어스) 를 가지고 Affine 계층을 만들고
             forward 함수를 실행해서 결과를 수행하시오 !

x = np.random.randn(5, 28*28)
W = np.random.randn(28*28, 3)
b = np.random.randn(1, 3) 

답:
affine1 = Affine(W,b) # 계층 생성 
affine1.forward(x)  

문제216. dout 값을 다음과 같이 주고 위의 affine1 계층의 역전파(backward) 함수를 실행해서
            바이어스의 기울기인 db 변수 값을 출력하시오 

그림 참고: https://cafe.daum.net/oracleoracle/Shyl/659

dout = np.random.randn(5,3) 

답:
x = np.random.randn(5, 28*28)
W = np.random.randn(28*28, 3)
b = np.random.randn(1, 3) 
dout = np.random.randn(5,3) 

affine1 = Affine(W,b) # 계층 생성 
affine1.forward(x)  
affine1.backward(dout)
affine1.db  # array([-1.74463645,  1.68743085, -1.76535133])

문제217. 위의 afffine 계층의 기울기인 dW 값을 출력하시오 !

x = np.random.randn(5, 28*28)
W = np.random.randn(28*28, 3)  # (784, 3) 
b = np.random.randn(1, 3) 
dout = np.random.randn(5,3) 

affine1 = Affine(W,b) # 계층 생성 
affine1.forward(x)  
affine1.backward(dout)
affine1.db  # array([-1.74463645,  1.68743085, -1.76535133])
affine1.dW # (784, 3) 

설명:  W =  W(784,3) - dW(784,3)  
        가중치 = 가중치 - 기울기

▦ 오차역전파로 기울기를 구하는 gradient 함수 알아보기 

그림: https://cafe.daum.net/oracleoracle/Shyl/661

def gradient(self, x, t):
        W1, W2 = self.params['W1'], self.params['W2']   # 가중치 가져오는 코드
        b1, b2 = self.params['b1'], self.params['b2']       # 바이어스 가져오는 코드
        grads = {}                                                  # 기울기를 담을 딕셔너리 변수 
     
        batch_num = x.shape[0]    # 설현 사진 5장(5, 28, 28) 

        # forward
        a1 = np.dot(x, W1) + b1  # Affine1  (첫번째 어파인 계층) 
        z1 = sigmoid(a1)            # 1층의 시그모이드 함수
        a2 = np.dot(z1, W2) + b2 # Affine2 (두번째 어파인 계층)
        y = softmax(a2)              # softmax 함수를 통과해서 예측값 y 를 출력 (그림 5-28)

# 순전파:  Affine1 --> sigmoid --> Affine2 ---> softmax ---> y값 출력     
# 역전파:  오차함수 --> softmax --> Affine2 --> sigmoid --> Affine1 


        # backward
        dy = (y - t) / batch_num    # (예측값 - 정답) / 배치    --> 오차 (dy)  
        grads['W2'] = np.dot(z1.T, dy)  # Affine2 의 가중치의 기울기를 구하는 코드
        grads['b2'] = np.sum(dy, axis=0) # Affine2 의 바이어스의 기울기를 구하는 코드

        da1 = np.dot(dy, W2.T)
        dz1 = sigmoid_grad(a1) * da1
        grads['W1'] = np.dot(x.T, dz1)
        grads['b1'] = np.sum(dz1, axis=0)
        return grads         

▒ sigmoid_grad 함수 소개 

 시그모이드 함수의 도함수 

def sigmoid_grad(x):
    return (1.0 - sigmoid(x)) * sigmoid(x)
    
■ 오차 역전파로 기울기를 구하는 gradient 함수를 이용해서 필기체 데이터를 학습 시키는 전체코드

https://cafe.daum.net/oracleoracle/Shyl/555

gradient 함수로 미분계수(기울기)를 구해서 학습 시켜서 0.92의 정확도가 출력되었습니다.    

정확도를 제대로 올리는 방법은 다음장 6장에서 학습합니다. 

문제218.(점심시간 문제) 위의 2층 신경망을 3층 신경망으로 변경하고 
            다시 똑같이 40에폭으로 학습시키시오

 이 코드에서 W3 과 b3 에 대한 코드를 추가해주면 됩니다.

  W3의 뉴런의 갯수는 10개로 하세요. b3 도 똑같이 10개 입니다. 


답글로 올리시고 식사하세요 ~~    즐거운 점심시간 되세요 ~~

직접 수정해 봐야 이 코드가 내것이 됩니다. 

출력층이니까 W3 과 b3 의 뉴런의 갯수가 10개여야됩니다. 식사들 하세요 ~~
식사하고 같이하겠습니다. 


2층 신경망 코드를 3층으로 수정하겠습니다. 
 3층 신경망의 순전파 그림

















%cd /content/drive/MyDrive/yys

import  sys, os
sys.path.append(os.pardir) 
import  numpy  as  np
from common.functions  import  softmax, cross_entropy_error, sigmoid , sigmoid_grad
# common 폴더 안에 functions.py 모듈안에 softmax 함수와 cross_entropy_error 함수를 가져와라
from tensorflow.keras.utils import to_categorical
from common.gradient  import  numerical_gradient

class  TwoLayerNet: 
    def  __init__(self):  # multipleNet 클래스(설계도)의 객체(제품)가 만들어질 때 자동으로 실행되는 함수
        self.params={}
        self.params['W1'] = np.random.randn(784,50)  #   1층의 가중치 W1
        self.params['b1'] = np.zeros(50)             #   1층의 바이어스 b1
        self.params['W2'] = np.random.randn(50,50)   #   2층 은닉층  가중치 W2
        self.params['b2'] = np.zeros(50)             #   2층(은닉층)의 바이어스 b2
        self.params['W3'] = np.random.randn(50,10)   #   3층 출력층 의 W3
        self.params['b3'] = np.zeros(10)             #   3층(출력층)의 바이어스
        print('2층 신경망이 생성되었습니다')

 #                       W1                         b1                           W2                           b2
 # (N, 784) ◎ (784, 50) --> (N, 50) + (1, 50) --> ( N, 50) ◎ ( 50, 50)  --> ( N, 10) + ( 1, 50)
 
 #                              W3                         b3
 # ---> (N, 50)  ◎  (50, 10 ) --> ( N, 10) + ( 1, 10)  ---> (N, 10)


    def  predict( self, x ):
        W1, W2, W3 = self.params['W1'], self.params['W2'], self.params['W3']
        b1, b2, b3 = self.params['b1'], self.params['b2'], self.params['b3']
        k = np.dot( x, W1 ) + b1  # 1층의 Affine
        k_prime = sigmoid(k)         # 1층 시그모이드
        m = np.dot( k_prime, W2) + b2 # 2층의 Affine
        n_prime = sigmoid(m)                       # 2층의 시그모이드
        p =np.dot( n_prime, W3) + b3  # 3층의 Affine
        q =  softmax(p)                      # 소트트 맥스
        return  q

    def  loss( self, x, t ):
        z = self.predict(x) # 입력값을 받아서 은닉 3층에서 발생한 값을 z변수에 입력
        loss = cross_entropy_error(z, t) # 확률벡터와 원핫인코딩된 정답을 받아서 오차를 출력하는 함수
        return  loss

    def  accuracy(self,x, t):
        y = self.predict(x)
        y = np.argmax(y, axis=1)  # 예측한 숫자
        t  = np.argmax(t, axis=1) # 정답 숫자
        acc = np.sum(y==t) / x.shape[0]
        return  acc


    # 5장에서 배운 기울기 구하는 함수
    def gradient(self, x, t):
        W1, W2, W3 = self.params['W1'], self.params['W2'],  self.params['W3']
        b1, b2, b3 = self.params['b1'], self.params['b2'],  self.params['b3']
        grads = {}
     
        batch_num = x.shape[0]

        # forward
        a1 = np.dot(x, W1) + b1
        z1 = sigmoid(a1)
        a2 = np.dot(z1, W2) + b2
        z2 = sigmoid(a2)
        a3 = np.dot(z2, W3) + b3
        y = softmax(a3)

        # backward
        dy = (y - t) / batch_num  # 오차
        grads['W3'] = np.dot(z2.T, dy)   # 3층의 Affine로 3층의 가중치 기울기 
        grads['b3'] = np.sum(dy, axis=0) # 3층의 Affine로 3층의 바이어스 기울기

        da2 = np.dot(dy, W3.T)  # 2층의 시그모이드로 역전파값을 넣어주기 위한 부분
        dz2 = sigmoid_grad(a2) * da2   # 2층의 시그모이드의 기울기

        grads['W2'] = np.dot(z1.T, dy)   # 2층의 Affine로 2층의 가중치 기울기 
        grads['b2'] = np.sum(dz2, axis=0) # 2층의 Affine로 2층의 바이어스 기울기
     
        da1 = np.dot(dy, W2.T)  # 1층의 시그모이드로 역전파값을 넣어주기 위한 부분
        dz1 = sigmoid_grad(a1) * da1   # 1층의 시그모이드의 기울기

        grads['W1'] = np.dot(x.T, dz1)    # 1층의 Affine 으로 1층의 가중치 기울기
        grads['b1'] = np.sum(dz1, axis=0) # 1층의 Affine 으로 1층의 바이어스의 기울기
        return grads         


# 1. 설계도로 제품을 만듭니다. 
net = TwoLayerNet() 

#2. 필기체 데이터를 로드합니다. 
from tensorflow.keras.datasets.mnist import load_data
(x_train, y_train), (x_test, y_test) = load_data(path = 'mnist.npz')

#3.훈련 데이터를 구성합니다. 
x_train = x_train.reshape(60000,28*28)
x_train = x_train/255

#4.훈련 데이터의 정답데이터를 구성합니다.
y_train = to_categorical(y_train)
y_train = y_train.reshape(60000,10)

#5.테스트 데이터를 구성합니다. 
x_test = x_test.reshape(10000,28*28)
x_test = x_test/255

#6.테스트 데이터의 정답데이터를 구성합니다.
y_test = to_categorical(y_test)
y_test = y_test.reshape(10000,10)

train_loss_list=[] # 오차값을 저장할 리스트
train_acc_list =[] # 훈련 데이터의 정확도를 저장할 리스트 
test_acc_list = [] # 테스트 데이터의 정확도를 저장할 리스트

for  i  in  range(600*40):
    batch_mask = np.random.choice(60000, 100)  # 0부터 60000까지의 숫자중에서 100개의 숫자를 랜덤으로 추출
    x_batch = x_train[batch_mask]  # 100개의 이미지 데이터를 추출
    t_batch = y_train[batch_mask]  # 100개의 정답 데이터를 추출
    grad = net.gradient(x_batch, t_batch)
    
    for  key  in ('W1', 'b1', 'W2', 'b2', 'W3', 'b3'):  # 가중치와 바이어스를 기울기 값으로 갱신하는 코드
        net.params[key] -= 0.1 * grad[key]
    
    loss = net.loss(x_batch, t_batch)

    if  i % 600==0:
        train_loss_list.append(loss)
        train_acc = net.accuracy(x_train, y_train)
        test_acc = net.accuracy(x_test, y_test)
        train_acc_list.append(train_acc)
        test_acc_list.append(test_acc)
        print("train acc, test acc :" +str(train_acc) + ',' + str(test_acc))

print(train_acc_list)
print(test_acc_list)


문제219. 점심시간 문제 코드를 텐써 플로우로 구현하시오 

    입력층 ------> 은닉1층 -------> 은닉2층 -----> 출력층
    (784개)          ( 50개)                (50개)            (10개)


참고코드: 딥러닝 목차 13번의 손글씨 2층 신경망 

# 1. mnist 데이터를 불러옵니다.
import  tensorflow  as  tf
from  tensorflow.keras.datasets.mnist  import  load_data

(x_train, y_train), (x_test, y_test) = load_data(path='mnist.npz') 

# 2.1  28x28 의 shape 를 1 x 784 로 변경합니다.

x_train = x_train.reshape(60000,28*28)
x_test  = x_test.reshape(10000, 28*28)

x_train = x_train/255.0
x_test = x_test/255.0

# 2.2 정답 데이터를 준비합니다. (p98 원핫인코딩을 해야합니다.)
 
from  tensorflow.keras.utils import  to_categorical

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)
print ( y_train.shape)  # (60000, 10)

# 3. 모델을 구성합니다.

from  tensorflow.keras.models  import  Sequential
from  tensorflow.keras.layers    import  Dense

model = Sequential()
model.add(Dense(50, activation='sigmoid', input_shape=(784, ) ) ) # 은닉1층
model.add(Dense(50, activation='sigmoid') ) # 2층  
model.add(Dense( 10, activation='softmax') ) # 출력층

# 4. 모델을 설정합니다. (경사하강법과 오차함수를 정의해줍니다. 4장에서 배웁니다)

model.compile(optimizer='adam',  # 경사하강법 
                     loss='categorical_crossentropy',  #오차함수
                     metrics=['acc'] )  # 학습과정에서 정확도를 보려고 지정

# 5. 모델을 훈련 시킵니다.

model.fit( x_train, y_train, epochs=30, batch_size=100)

#model.fit( 훈련데이터, 정답, 에폭수, 배치사이즈) 
# 에폭수 :  학습횟수 (책을 몇번 볼건지)
# 배치사이즈:  한번에 학습할 양 ( 사람은 책을 한번에 한페이지 밖에 못보지만 컴퓨터는 한번에
#                  여러 페이지를 볼 수 있다)

# 6. 모델을 평가합니다. (시험을 봅니다.)

model.eval‎uate(x_test, y_test) 

# [0.09719103574752808, 0.9721999764442444]

지금 학습한 필기체 데이터는 학습하기 좋은 예쁜 데이터입니다.
현업에서 사용하는 이미지 데이터를 이렇게 깔끔한 데이터는 아니고 그리고 이미지수도 
많이 부족합니다. 

많이 튜닝해야 정확도가 올라가는 데이터로 변경해서 학습 시켜 보겠습니다.

■ cifar10 데이터셋 소개 

10개의 클래스이고 훈련 데이터가 60000 개이고 클래스당 6000개의 이미지가 있습니다.
테스트 데이터는 10000개 입니다.  

데이터 셋트

0. 비행기
1. 자동차
2.  새
3.  고양이
4. 사슴
5. 개
6. 개구리
7. 말
8. 배
9. 트럭 

문제220. cifar10 데이터를 텐써플로우에서 불러오시오 !

from  tensorflow.keras.datasets  import  cifar10

(x_train, y_train), (x_test, y_test) = cifar10.load_data()

print( x_train.shape) # (50000, 32, 32, 3)  컬러 사진 입니다. 
print( y_train.shape)
print( x_test.shape)  # (10000, 32, 32, 3)
print( y_test.shape)

문제221.  cifar10 훈련 이미지를 흑백으로 변경하시오 !

import  tensorflow  as  tf 
x_train_gray = tf.image.rgb_to_grayscale(x_train)
print(x_train_gray.shape)  # (50000, 32, 32, 1)

문제222. cifar10 테스트 이미지를 흑백으로 변경하시오 !

import  tensorflow  as  tf 
x_test_gray = tf.image.rgb_to_grayscale(x_test)
print(x_test_gray.shape)  # (10000, 32, 32, 1)

문제223. 흑백으로 변경한 cifar10 훈련 이미지를 4차원에서 3차원으로 변경하시오!

x_train_gray_3dim = tf.reshape( x_train_gray, [50000, 32, 32] )
print( x_train_gray_3dim.shape) # (50000, 32, 32)

문제224.  흑백으로 변경한 cifar10 테스트 이미지를 4차원에서 3차원으로 변경하시오 !

x_test_gray_3dim = tf.reshape( x_test_gray, [10000, 32, 32] )
print( x_test_gray_3dim.shape) # (10000, 32, 32)

문제225. 텐써의 자료구조로 되어져있는 x_train_gray_3dim 과 x_test_gray_3dim 을
              numpy  array 로 변환하시오 !

x_train_gray_3dim = np.array(x_train_gray_3dim)
x_test_gray_3dim = np.array(x_test_gray_3dim)


문제226. 5장에서 만든 텐써플로우로 구성한 3층 신경망에 위의 cifar10 데이터를 넣어서
            학습 시키시오 !

# 1. cifar10 데이터를 불러옵니다.

from  tensorflow.keras.datasets  import  cifar10
import  tensorflow  as  tf 

(x_train, y_train), (x_test, y_test) = cifar10.load_data()

x_train_gray = tf.image.rgb_to_grayscale(x_train)
x_test_gray = tf.image.rgb_to_grayscale(x_test)

x_train_gray_3dim = tf.reshape( x_train_gray, [50000, 32, 32] )
x_test_gray_3dim = tf.reshape( x_test_gray, [10000, 32, 32] )

x_train_gray_3dim = np.array(x_train_gray_3dim)
x_test_gray_3dim = np.array(x_test_gray_3dim)

x_train= x_train_gray_3dim # 3차원으로 변경한 데이터
x_test =  x_test_gray_3dim

# 2.1  32x32 의 shape 를 1 x 1024 로 변경합니다.

x_train = x_train.reshape(50000,32*32)  # 2차원으로 변경
x_test  = x_test.reshape(10000, 32*32)

x_train = x_train/255.0
x_test = x_test/255.0

# 2.2 정답 데이터를 준비합니다. (p98 원핫인코딩을 해야합니다.)
 
from  tensorflow.keras.utils import  to_categorical

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# 3. 모델을 구성합니다.

from  tensorflow.keras.models  import  Sequential
from  tensorflow.keras.layers    import  Dense

model = Sequential()
model.add(Dense(50, activation='sigmoid', input_shape=(32*32, ) ) ) # 은닉1층
model.add(Dense(50, activation='sigmoid') ) # 2층  
model.add(Dense( 10, activation='softmax') ) # 출력층

# 4. 모델을 설정합니다. (경사하강법과 오차함수를 정의해줍니다. 4장에서 배웁니다)

model.compile(optimizer='adam',  # 경사하강법 
                     loss='categorical_crossentropy',  #오차함수
                     metrics=['acc'] )  # 학습과정에서 정확도를 보려고 지정

# 5. 모델을 훈련 시킵니다.

model.fit( x_train, y_train, epochs=30, batch_size=100)

#model.fit( 훈련데이터, 정답, 에폭수, 배치사이즈) 
# 에폭수 :  학습횟수 (책을 몇번 볼건지)
# 배치사이즈:  한번에 학습할 양 ( 사람은 책을 한번에 한페이지 밖에 못보지만 컴퓨터는 한번에
#                  여러 페이지를 볼 수 있다)

# 6. 모델을 평가합니다. (시험을 봅니다.)

model.evaluate(x_test, y_test) 


500/500 [==============================] - 1s 3ms/step - loss: 1.3859 - acc: 0.5061
313/313 [==============================] - 1s 2ms/step - loss: 1.6855 - acc: 0.4118

[1.6855309009552002, 0.41179999709129333]

내일 6장에서 이 신경망의 정확도를 더 올려보도록 하겠습니다. 

45분까지 쉬세요 ~~~ 

■  [배운거 활용하기] 화장하는 인공지능

문제227.(오늘의 마지막 문제)  인터넷에서 화장 시키고 싶은 사진을 골라서 인공지능으로
           화장을 시키고 원본 이미지와 메이크업 이미지와 결과 이미지를 올리세요 ~~


■ 6장. 학습관련 기술들 ( 인공신경망의 언더피팅과 오버피팅을 막는 방법들)

1. underfitting 을 방지하는 방법들

 - 가중치 초기값 선정
 - 경사하강법의 종류
 - 배치정규화
 - L2 정규화 (가중치 감소)

2. overfitting 을 방지하는 방법들

  - 드롭아웃
  - 배치정규화

▩ 가중치 초기값 선정  p202

 랜덤으로 생성되는 가중치 W 와 바이어스 b 의 초기값을 어떻게 선정하느냐에 따라
 학습이 잘될수도 있고 잘 안될 수 도 있습니다.
 학습이 잘될려면 가중치 초기값들의 분포가 정규분포 형태를 이루어야 합니다. 
 그런데 W1= np.random.randn(784,100) 이렇게 생성하게 되면 가우시안 정규분포(평균이 0 이고
 표준편차가 1) 인 난수를 생성합니다. 

 1. 생성되는 가중치의 표준편차가 너무 큰 경우

   시험문제가 너무 어려우면 아주 잘하는 학생들과 아주 못하는 학생들로 점수가 나뉜다.

  구현 코드:  W1= np.random.randn(784,100)  * 1 

 그림 6-10

 2. 생성되는 가중치의 표준편차가 너무 작은 경우 

 시험문제가 너무 쉬우면 학생들의 점수가 평균에 가까워진다. 

  구현 코드:  W1= np.random.randn(784,100)  * 0.001 

 그림 6-11

그림 6-13과 같은 분포여야 신경망 학습이 잘됩니다. 

가중치 초기값을  아래의 2가지 경우로 테스트 합니다. 

   1. W1= np.random.randn(784,100)  * 1   의 정확도?  train acc,    test acc :  0.92115,    0.9161
   2. W1= np.random.randn(784,100)  * 0.01 의 정확도? train acc, test acc :0.9526166666666667,  0.9473
   
가중치 초기값을 생성할 때 표준편차의 범위를 지정하기 위해서 0.01 을 곱해서 난수를 생성했더니
0.01 을 곱하지 않았을 때 보다 정확도가 더 좋아졌습니다. 

이 애기는 시험문제가 너무 어렵지 않고 적당한 문제이다는 것입니다.

가중치를 생성하기 위해서 0.01 을 곱해야하는지 아니면 0.03 을 곱해야하는지 
정할려면 테스트를 많이 해봐야한다는것인데 그냥 결과가 잘나오는 가중치 초기값 선정하는
수학 공식이 있는가?

1. Xavier(사비에르) 초기값 선정
2. He 초기값 선정 
 
위의 가중치 초기값 선정은 텐써플로우나 파이토치에는 이미 내장되어 있습니다. 
날코딩으로 신경망을 구현 할 때는 위의 공식을 적용할 수 있습니다. 

문제228.  He 초기값으로 가중치 초기값을 생성하여 정확도를 확인하시오 !

 1. 가중치 초기값 선정 안했을때의 정확도: train acc, test acc :  0.92115,     0.9161
 2. 가중치 초기값에 0.01 을 곱할때의 정확도: train acc, test acc :0.9526166666666667,0.9473
 3. 가중치 초기값에 He 를 적용했을때의 정확도: train acc, test acc :0.9688333333333333,0.9628

  self.params={}
        self.params['W1'] = np.random.randn(784,50)* np.sqrt(2/784)  #   1층의 가중치 W1
        self.params['b1'] = np.zeros(50)             #   1층의 바이어스 b1
        self.params['W2'] = np.random.randn(50,50) * np.sqrt(2/50)  #   2층 은닉층  가중치 W2
        self.params['b2'] = np.zeros(50)             #   2층(은닉층)의 바이어스 b2
        self.params['W3'] = np.random.randn(50,10) * np.sqrt(2/50) #   3층 출력층 의 W3
        self.params['b3'] = np.zeros(10)             #   3층(출력층)의 바이어스
        print('3층 신경망이 생성되었습니다')

■ 언더 피팅을 막기 위한 방법

 1. 가중치 초기값 선정
 2. 배치 정규화
 3. 경사하강법을 변경


▩ 배치 정규화(batch normalization) p210

 가중치 초기값을 적정히 설정을 하면 각 층의 활성화 값의 분포가 적당히 퍼지는 효과를 보이는데
 신경망이 깊어지고 학습이 반복되다 보면 각 층의 활성화 값의 분포가 정규성을 읽어버리는
 현상이 발생하게 됩니다. 

 그림 6-13

 층이 깊어질 수록 정규성을 읽어버리는 현상이 그림 6-13에서 일어나고 있습니다. 

참고 그림 : https://cafe.daum.net/oracleoracle/Sedp/239


배치 정규화 수학식 식 6-7 의 공식을 이용해서 층마다 이 수학식을 적용해서 뉴런에서 출력되는
값의 정규성을 강제로 유지시키게 되면 정확도가 올라가게 됩니다. 

설명 그림: https://cafe.daum.net/oracleoracle/Shyl/689


▩  배치정규화를 썼을 때와 안썼을 때의 차이 실험(텐써 플로우)

# 1. 필요한 패키지 가져오는 코드 

import tensorflow as tf   # 텐써 플로우 2.0 
from tensorflow.keras.datasets.mnist import load_data  # 텐써플로우에 내장되어있는 
                                                                         # mnist 데이터를 가져온다.
from tensorflow.keras.models import Sequential  # 모델을 구성하기 위한 모듈
from tensorflow.keras.layers import Dense  # 완전 연결계층을 구성하기 위한 모듈
from tensorflow.keras.utils import to_categorical # one encoding 하는 모듈

tf.random.set_seed(777)

(x_train, y_train), (x_test, y_test) = load_data(path='mnist.npz')  # mnist 데이터 로드
    
# 2. 정규화 진행  
x_train = (x_train.reshape((60000, 28 * 28))) / 255 
x_test = (x_test.reshape((10000, 28 * 28))) / 255

# 3. 정답 데이터를 준비한다. 
# 하나의 숫자를 one hot encoding 한다. (예:  4 ---> 0 0 0 0 1 0 0 0 0 0 ) 
y_train = to_categorical(y_train)  # 훈련 데이터의 라벨(정답)을 원핫 인코딩
y_test = to_categorical(y_test)    # 테스트 데이터의 라벨(정답)을 원핫 인코딩 

# 4. 모델을 구성합니다. 3층 신경망으로 구성
model = Sequential()
model.add(Dense(50, activation = 'sigmoid', input_shape = (784, )))  # 1층
model.add(Dense(50, activation = 'sigmoid') ) # 2층 은닉층 
model.add(Dense(10, activation = 'softmax'))  # 3층 출력층 

# 5. 모델을 설정합니다. ( 경사하강법, 오차함수를 정의해줍니다. )
model.compile(optimizer='SGD', 
                     loss = 'categorical_crossentropy', 
                     metrics=['acc'])  # 학습과정에서 정확도를 보려고 

#6. 모델을 훈련시킵니다. 

history = model.fit(x_train, y_train, 
                         epochs = 30,  # 30에폭
                         batch_size = 100,
                         validation_data=(x_test, y_test) )

# 7.모델을 평가합니다. (오차, 정확도가 출력됩니다.)
model.eval‎uate(x_test, y_test)

train_acc_list=history.history['acc']
train_acc_list

test_acc_list=history.history['val_acc']
test_acc_list

import  matplotlib.pyplot  as  plt

x = np.arange( len(train_acc_list) )
plt.plot( x, train_acc_list, label='train acc')
plt.plot( x, test_acc_list, label='test acc',  linestyle='--')
plt.ylim(0, 1)
plt.legend(loc='lower right')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.show()

훈련 데이터 정확도: 0.8875 , 테스트 데이터 정확도: 0.8894

위와 같이 3층 신경망에 활성화함수 sigmoid, 경사하강법 SGD 를 썼을때의 정확도가 
그리 좋지 않았습니다.  가중치의 정규성을 유지시키게 하는 배치 정규화를 사용해서
다시 실험해 보겠습니다. 

from tensorflow.keras.layers import Dense, BatchNormalization  # 완전 연결계층을 구성하기 위한 모듈

그림 6-16을 보면 Affine 계층과 활성화 함수 계층 사이에 배치 정규화 층을 넣습니다. 

model = Sequential()
model.add(Dense(50, activation = 'sigmoid', input_shape = (784, )))  # 1층
model.add(BatchNormalization())
model.add(Dense(50, activation = 'sigmoid') ) # 2층 은닉층 
model.add(BatchNormalization())
model.add(Dense(10, activation = 'softmax'))  # 3층 출력층 

- 배치 정규화 안썼을 때:  훈련 데이터 정확도: 0.8875 , 테스트 데이터 정확도: 0.8894
- 배치 정규화 썼을 때:  훈련 데이터 정확도: 0.9611 , 테스트 데이터 정확도:0.9572

* 정확도 올리는 방법

1. 가중치 초기값 선정(사이에르 , He 초기화)
2. 배치정규화 
3. 경사하강법 과 활성화 함수의 조합 적절하게 선정

  - SGD + sigmoid :  훈련 데이터 정확도: 0.9611 , 테스트 데이터 정확도:0.9572
  - Adam + relu  :     훈련 데이터 정확도: 0.9952 , 테스트 데이터 정확도:0.9726
  - RMSprop + relu :  훈련 데이터 정확도: 0.9943 , 테스트 데이터 정확도:0.9756

경사하강법을 변경하고 활성화 함수도 변경하고 배치 정규화를 적용해서 정확도가 
많이 상승 되었습니다. 그런데 오버피팅이 심한건 아닌데 오버피팅이 조금 일어났습니다. 
이 오버피팅 문제를 해결하는 방법을 보겠습니다.

▩ 오버피팅 문제를 해결하는 방법 2가지

 1. 드롭아웃
 2. L2 정규화 

 신경망에서 오버피팅은 주로 다음의 두경우에 일어납니다 (P215)

  1. 매개변수가 많고(뉴런의 갯수가 많다) 표현력이 높은(층이 깊은) 모델
  2. 훈련 데이터가 적을때 

  이미지를 분류하고 싶은 사진을 웹에서 직접 스크롤링을 해야합니다.
  제규어와 사슴을 분류하고 싶다면 ?   제규어 사진 2000장, 사슴 사진 2000장

▩  드롭아웃 (dropout)  p 219

 "오버피팅을 억제하기 위해서 뉴런을 임의로 삭제하면서 학습시키는 방법"

 그림 6-22


 뉴런의 갯수를 너무 많이 삭제하면 정확도 ↓ 있으니 적절하게 설정해줘야합니다.
 
* 텐써 플로우에서 드롭아웃 지정하기 ( 20% 의 뉴런을 랜덤으로 삭제하고 실험)

from tensorflow.keras.layers import Dense, BatchNormalization, Dropout

model = Sequential()
model.add(Dense(50, activation = 'relu', input_shape = (784, )))  # 1층
model.add(BatchNormalization())
model.add(Dropout(0.2))
model.add(Dense(50, activation = 'relu') ) # 2층 은닉층 
model.add(BatchNormalization())
model.add(Dropout(0.2))
model.add(Dense(10, activation = 'softmax'))  # 3층 출력층 

훈련 데이터의 정확도가  0.9721 이고 테스트 데이터의 정확도가  0.9746 이므로 
오버피팅 발생하지 않았습니다. 

문제229. (점심시간 문제)  드롭아웃 비율을 0.1 로 했을때 즉 뉴런의 갯수를 랜덤으로 신경망에서
            10% 만 삭제했을때의 결과는 어떻게 나오는지 실험하시오 !

 20% :  훈련 데이터의 정확도가  0.9721,  테스트 데이터의 정확도가  0.9746
 10% :  훈련 데이터의 정확도가   ? ,  테스트 데이터의 정확도가   ?


 드롭아웃 기능을 사용할 때 짝꿍처럼 같이 사용하는 keras 의 기능 ?  얼리스탑 

  훈련 데이터와 테스트 데이터의 정확도가 같아지는 그 시점에 모델 훈련을 자동으로 멈춰버리겠다.
  
■ EarlyStopping 기능

 무조건 에폭을 많이 돌린후 , 특정 시점에서 멈추는 것입니다.

 이 특정 시점을 어디로 둘것인가 ?  오버피팅이 발생하지 않는 그 시점 

 30에폭을 돌려서 모델을 학습 시킨다면 훈련 데이터와 테스트 데이터의 정확도가 비슷해지거나
 또는 테스트 데이터의 정확도가 훈련데이터의 정확도를 역전하는 그 시점에서 학습을 멈추겠다.

 30 에폭중 14에폭즈음에서 테스트 데이터의 정확도가 훈련 데이터의 정확도 보다 더 높아지고
 계속해서 테스트 데이터의 정확도가 높아지는 그 시점에 멈춰버리겠다. 
 
* 얼리스탑 기능 코드:

from  tensorflow.keras.callbacks  import  EarlyStopping

#콜백을 정의 합니다.
callbacks = [EarlyStopping(monitor='val_acc', patience=3, verbose=1) ] 

# 설명:  -  monitor :   관찰하고자 하는 항목으로 'val_loss' 나 'val_acc' 를 주로 사용합니다.

           -  patience :  개선이 없다고 바로 종료하지 않고 개선이 없는 에폭을 얼마나 기다려 줄건지를
                              지정하는데 만약에 10 을 준다면 개선이 없는 에폭이 10번 지속될 경우
                              학습을 종료하겠다.

           - verbose :  얼마나 자세하게 정보를 표현 할 것인가를 지정(0,1,2) 

model.fit( x_train, y_train, 
              batch_size =100,
              validation_data = ( x_test, y_test ),
              epochs = 30,
              callbacks = callbacks )

model.evaluate( x_test, y_test )

Epoch 21/30
 4s 2ms/step 훈련의 정확도: 0.9749 , 테스트 데이터의 정확도: 0.9741
Epoch 00021: early stopping

훈련 데이터의 정확도가 테스트 데이터의 정확도를 역전하는 그 시점(21에폭)에서 조기종료 했습니다. 

문제230. 이번에는 정확도가 아니라 오차값을 기준으로 조기종료되게 하시오 ! (val_loss)

답:

# 콜백을 정의합니다.
callbacks = [EarlyStopping(monitor = 'val_loss', patience = 3, verbose = 1)]

문제231. 학습을 조기종료 했을때의 그 모델을 저장하시오 !( 모델명: mnist_model.h5) 

# 7.모델을 평가합니다. (오차, 정확도가 출력됩니다.)

model.evaluate(x_test, y_test)
model.save('/content/drive/MyDrive/mnist_model.h5')

■ 오버피팅을 방지하는 방법

1. 드롭아웃 + 얼리스탑 기능
2. 가중치 감소 (Weight  Decay)

▩ 가중치 감소(Weight Decay)

 "학습하는 과정에서 큰 가중치에 대해서는 그에 상응하는 큰 패널티를 부여하여
  오버피팅을 억제하는 방법"

                     입력층 -------------------> 은닉층 --------------------> 
고양이 사진        ○ ----------------------> 귀가있어요   -------------------> 아주 큰 가중치로 갱신
                       ○  ---------------------->  꼬리가 있어요  ---------------> 가중치
                       ○  -----------------------> 집계발을 가지고 있어요 -------> 가중치
                       ○  ------------------------> 장난스럽게 보여요 --------------> 가중치 


 귀가 없는 고양이 사진이 들어오면 이 사진은 고양이가 아니다라고 판단을 하는 이 신경망은
 오버피팅이 발생하는 신경망 입니다.  이를 해결하는 방법이 ?   "가중치 감소"

 아주 큰 가중치에 대해서는 큰 패널티를 부여해서 가중치의 매개변수값이 작아지도록 만드는
  학습방법이 가중치 감소입니다. 

예제: model.add(Dense(50, kernel_regularizer='l2', activation='relu') ) 

신호보냈습니다. ~~

■ 7장. 합성곱 신경망 (Convolution Neural Network)
                                  ↑               ↑     ↑
                               합성곱          신경    망 

합성곱 신경망 ?       convolution 층과             pooling 층을 포함하는 신경망 
                               ↓                                  ↓
                       이미지의 특징을 잡아내는 역활    이미지를 선명하게 만드는 역활

기존 신경망과의 차이?

 - 기존방법 :  입력값 ----->  Affine ---> Relu ---> Affine ---> Relu ---> Affine ---> softmax
 (완전연결계층)  ↓
          사진을 사진 그대로 입력하지 않고 1차원으로 flatten 시켜서 입력했음 (1, 784)

 - CNN :  입력값 ---->  convolution  ---> Relu ---> pooling -----> 완전 연결 계층
                ↓                                                                 ↓             
  사진을 사진 그대로 입력한다. ( 1, 28, 28)                       flatten 시킨다. 


■ CNN 을 이용하지 않았을때의 기존층의 문제점?  P229 

  "이미지의 형상이 무시된다" 

게시글 714번  [쉬움주의] 7장. 완전 연결계층의 문제점

정리:  필기체 이미지 --> 28x28=784 의 1차원 데이터로 flatten 시켜서 784개의 데이털르
         첫 affine 계층에 입력한게 기존 방법입니다.

               ↓   문제점은 ?

 형상을 무시하고 모든 입력 데이터를 동등한 뉴런으로 취급하기 때문에 이미지가 갖는
 본질적인 패턴을 읽지 못합니다.

                 ↓ 해결하는 방법 ?

  원본 이미지를 가지고 여러개의 feature  map 을 만들어서 데이터를 여러개 생성합니다.
   ( convolution 층에서 이 일이 일어납니다.)


합성곱 연산은 ? 원본 이미지에 필터(filter) 로 슬라이딩 해서 피쳐맵(feature map) 을 만드는 것을
                      말합니다. 

■ 딥러닝 활용 ( 사진을 보고 성별과 나이를 맞추는 인공지능)

 이 모델은 텐써플로우나 파이토치로 만든 모델은 아니고 caffe 라는 프레임워크로 만든
  모델입니다. 그래서 우리는 opencv 를 이용해서 caffe 로 만든 모델을 불러올것 입니다. 

*  코드 순서

 1. 모델을 불러옵니다.
 2. 이미지에서 얼굴을 찾습니다.
 3. 찾은 얼굴 이미지를 신경망에서 학습하기 좋도록 전처리를 합니다.
   ( min/max 정규화가 아니라 표준화를 해서 저자가 학습 했으므로 우리도 성별과 나이를
    맞추기를 원하는 사진을 저자가 표준화한 방법으로 표준화 시켜서 신경망에 넣을 겁니다.)
  4. 성별을 맞추는 모델에 이미지를 넣고 예측한 성별을 출력
  5. 나이를 맞추는 모델에 이미지를 넣고 예측한 나이를 출력
  6. 예측한 성별과 나이를 원본 이미지 위에 덧붙여서 이미지 출력을 합니다. 

코드설명: 

%cd /content/drive/MyDrive/yys8/age_gender_estimation

import cv2, glob, dlib  # 얼굴을 인식하는 모듈인 dlib 을 임폴트 합니다. 
from google.colab.patches import cv2_imshow #  코렙에서 이미지를 디스플레이 하기 위해서 필요한 함수

age_list = ['(0, 2)','(4, 6)','(8, 12)','(15, 20)','(25, 32)','(38, 43)','(48, 53)','(60, 100)'] # 레이블할 나이의 범위
gender_list = ['Male', 'Female'] # 성별 레이블 

detector = dlib.get_frontal_face_detector() # 얼굴을 인식하는 dlib의 함수 

age_net = cv2.dnn.readNetFromCaffe(   # opencv 를 이용해서 cafe 로 만든 모델을 불러오는 코드 
          'models/deploy_age.prototxt',    # 이 모델은 나이를 예측하는 모델입니다. 
          'models/age_net.caffemodel')

gender_net = cv2.dnn.readNetFromCaffe( # opencv 를 이용해서 cafe 로 만든 모델을 불러오는 코드 
          'models/deploy_gender.prototxt',  # 성별을 예측하는 모델입니다. 
          'models/gender_net.caffemodel')

img_list = glob.glob('img/*.jpg') #  img 폴더에 확장자가 jpg 로 끝나는 이미지들을 모두 불러온다. 

for img_path in img_list:  # img_list 에 있는 이미지들을 하나씩 불러와서 
  img = cv2.imread(img_path)  # 숫자로 변환합니다. 

  faces = detector(img)  # 이미지에서 얼굴을 찾습니다. 

  for face in faces:  # 얼굴들을 하나씩 불러와서 
    x1, y1, x2, y2 = face.left(), face.top(), face.right(), face.bottom()  # 얼굴의 위치정보 4개을 찾아서 저장

    face_img = img[y1:y2, x1:x2].copy()  # 인공지능 모델이 얼굴만 인식하므로 얼굴만 잘라내서 face_img 
                                                    # 에 저장합니다. 

   # 신경망에 이미지를 넣기 전에 이미지를 전처리하는 코드 
    blob = cv2.dnn.blobFromImage(face_img, scalefactor=1, size=(227, 227),
      mean=(78.4263377603, 87.7689143744, 114.895847746),
      swapRB=False, crop=False)

 # scalefactor=1/255 로 하면 이미지 픽셀을 0~255 사이로 변경하겠다. 
 # 신경망에 맞는 이미지 사이즈가 가로 227, 세로 227 여서 그대로 resize 합니다. 
 #  mean=(78.4263377603, 87.7689143744, 114.895847746) 저자가 사용한 이미지 표준화를 위한 평균값
 #  이어서 그대로 따라서 표준화 시키겠다. 
 # swapRB=False   RGB  --> BGR 로 바꾸지 않겠다. 
 # crop=False 이미지를 잘라내지 않겠다. 

    # predict gender   성별을 예측합니다. 
    gender_net.setInput(blob)  # 성별을 예측하는 모델인 gender_net( 이미지)를 넣고 예측합니다. 
    gender_preds = gender_net.forward()  # 이미지 흘려보내서 예측한 결과를 gender_preds
    gender = gender_list[gender_preds[0].argmax()] # 출력된 확률벡터에서 최대값의 원소의 인덱스 추출

    # predict age  나이를 예측합니다. 
    age_net.setInput(blob)  # 나이를 예측하는 모델 age_net 에 이미지를 넣고 
    age_preds = age_net.forward()  # 이미지를 흘려보내서 예측한 결과를 age_preds 에 넣습니다. 
    age = age_list[age_preds[0].argmax()]  # 나이의 레이블을 출력

    # visualize
    cv2.rectangle(img, (x1, y1), (x2, y2), (255,255,255), 2)  # 얼굴있는 부분에 사각형을 표시해라 
    overlay_text = '%s %s' % (gender, age)  # 나이와 성별을 묶어서 
    cv2.putText(img, overlay_text, org=(x1, y1), fontFace=cv2.FONT_HERSHEY_SIMPLEX,
      fontScale=1, color=(0,0,0), thickness=10)  # 이미지 위에 나이와 성별을 써라 
    cv2.putText(img, overlay_text, org=(x1, y1),
      fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255,255,255), thickness=2)

  cv2_imshow(img)  # 코렙의 cv2_imshow 로 이미지를 시각화 한다. 
  cv2.imwrite('result/%s' % img_path.split('/')[-1], img)  # 원하는 경로에 이미지를 저장합니다. 

  key = cv2.waitKey(0) & 0xFF    # 멈추는데
  if key == ord('q'):                 # q 라는 키보드를 누르면 끝내겠다. 
    break

문제232. (오늘의 마지막 문제)  본인의 사진도 괜찮고 인터넷에서 나이와 성별을 확인하기 원하는 사진을
             인공지능에 넣고 맞춘 결과를 올리시오 ~  

이파리 데이터 훈련 4000장과 테스트 100장 압축파일 2개를 내려받아 코렙에
구글 드라이브와 연동해서 /content/drive/Mydrivce/leaf3 밑에 올리세요 ~ 

주제는 자유주제인데 딥러닝을 활용한 주제
팀은 2~3명, 4~5명 

■ 어제 배웠던 7장 cnn 의 내용 복습 

CNN(합성곱 신경망)을 신경망에 사용해야 하는 이유?

 이미지를 이미지 그대로 받아들여서 학습 시키기 위해서 입니다. 

              입력 데이터        --------------------->  신경망

1. 기존층 :  ( 1, 784 ) -------------------------------> 신경망

2. CNN층 : (1, 28, 28)  ------------------------------> 신경망 

■ 합성곱 연산을 컴퓨터로 구현하는 방법 

  원본 이미지 한장을 filter 100개로 합성곱 연산을 하면 feature map 이 100개가 생성됩니다. 

  합성곱의 역활 ?  이미지의 특징을 잡아내는 역활을 한다. 

문제233. 아래의 그림의 합성곱을 하기 위해서 입력 데이터와 filter 를 만드시오 ! (그림 7-3)

import numpy  as  np

x = np.array([1, 2, 3, 0, 0, 1, 2, 3, 3, 0, 1, 2, 2, 3, 0, 1]).reshape(4,4)
filter = np.array([2, 0, 1, 0, 1, 2, 1, 0, 2]).reshape(3,3)
print(x)
print(filter)

문제234. 입력 이미지 x 에서 아래의 3x2 영역만 가져오시오 !

답: 
print (x[0:3, 0:3])

문제235. 위에서 가져온 3x3 영역의 원소들과 filter 의 원소들과의 곱셈을 하시오 !

답:
print (x[0:3, 0:3] * filter)

문제236. 위에서 곱셈을 해서 출력된 원소들의 합을 출력하시오 !

답:
print ( np.sum(x[0:3, 0:3] * filter ))

문제237. 이번에는 원본 이미지를 한칸 옆으로 슬라이딩하고 필터와 합성곱을 해서 16를 출력하시오

답: print( np.sum( x[0:3, 1:4]  * filter) )

문제238. 이번에는 한칸 아래로 슬라이딩하고 필터와 합성곱을 해서 6을 출력하시오

답: print( np.sum( x[1:4, 0:3]  * filter) )

문제239. 그림 7-4에 나온것처럼 결과적 합성곱해서 나와야할 숫자 4개를 다 출력하시오 !

print ( np.sum(x[0:3, 0:3] * filter ))
print ( np.sum(x[0:3, 1:4] * filter ))
print ( np.sum(x[1:4, 0:3] * filter ))
print ( np.sum(x[1:4, 1:4] * filter ))

문제240. 위의 4개의 계산을 하기 위해 위와 같이 4번 하드코딩하지 않고 이중 루프문으로 
            한번에 출력되게하시오 !  ( 온라인 수업의 집중을 높이기 위해서 카페에 답글로 올려주세요)

a = []
for i in range (2):
  for j in range (2):
    a.append (np.sum(x[0+i:3+i, 0+j:j+3] * filter) )
print(a)

문제241. 위에서 출력된 원소 4개를 가지고 2x2 행렬의 넘파이 배열을 생성하시오 

답:
a = []
for i in range (2):
  for j in range (2):
    a.append (np.sum(x[0+i:3+i, 0+j:j+3] * filter) )
b = np.array(a).reshape(2,2)
print(b)

■ 패딩 (p232)

  패딩이란 이미지를 합성곱하게 되면 피쳐맵의 크기가 원본 이미지보다 작아지게 됩니다. 
  (지금 방금 예를 보아도 5x5 가 2x2 로 작아졌습니다.) 
 그런데 지금 나온 결과를 다시 한번 또 합성곱을 할것 입니다. 

 원본이미지 ---> 합성곱 ----> 풀링 ---> 합성곱 ---> 풀링  ---> 합성곱
                          
패딩이란 합성곱 연산을 수행하기 전에 입력 데이터 주변을 특정값으로 채워 늘리는 것을 패딩이라
합니다.  패딩을 하지 않을 경우 data 의 공간의 크기는 합성곱 계층을 지날때 마다
작아지게 되므로 가장 자리 정보들이 사라지게 되는 문제가 발생하게 됩니다.
그래서 패딩을 해줘야 합니다. 패딩은 다음 그림 7-6과 같습니다. 

문제242. 아래의 2x2 행렬을 제로 패딩 1 로 해서 4x4 행렬로 만드시오 !

                            0    0    0    0
   18  19                 0   18  19  0
    9   18                0    9    18  0
                            0    0    0    0


x = np.array([ [18, 19], [9, 18] ] )
x_pad = np.pad( x, pad_width=1, mode='constant', constant_values=0)
print(x_pad)

[[ 0  0  0  0]
 [ 0 18 19  0]
 [ 0  9 18  0]
 [ 0  0  0  0]]
​
문제243. 그림 7-6 을 실험해서 원본이미지가 4x4 를 1 패딩해서 필터와 합성곱 한 결과가
             4x4 행렬로 출력이 되는지 실험하시오 !

x = np.array([1,2,3,0,0,1,2,3,3,0,1,2,2,3,0,1]).reshape(4,4)
x_pad = np.pad( x, pad_width=1, mode='constant', constant_values=0)
print(x_pad)

filter =np.array([2,0,1,0,1,2,1,0,2]).reshape(3,3)

a = []
for i in range (4):
    for j in range (4):
        a.append (np.sum(x_pad[0+i:3+i, 0+j:j+3] * filter) )
b = np.array(a).reshape(4,4)
print(b)

※ 패딩을 사용해서 우리가 하고자것은?

 원본 이미지를 convolution 층을 지날때 마다 계속 같은 형상으로 유지 시키는것

 원본 이미지 ------> 컨볼루션 층 ----->  원본이미지와 행과 열이 같은 이미지 (피쳐맵)
  (1장)                   (필터 100개)                  (피쳐맵 100장)

60000만장 -----> 필터 100개 ----->  6000000 장

6000000장으로 학습 데이터가 늘어나서 다양한 이미지들을 학습하게 됩니다.

텐써플로우 2.0 으로 convolution 층을 구성한다면?

model.add(Conv2D( 100, kernel_size=(5,5), input_size=(28,28,1), activation='relu') )
                            ↑                     ↑                             
                      뉴런의 갯수           필터의 가로세로 사이즈 
                       (필터의 갯수)

완전연결계층:  input_size=(784, )        ---> 1차원
CNN           :  input_size=(28, 28, 1)    --->  3차원

■ 텐써플로우 2.0 으로 필기체 데이터 학습 시키기(cnn층을 넣어서 학습 시키기)

▩  CNN 을 사용하지 않았을때의 코드

# 1. 필요한 패키지 가져오는 코드 

import tensorflow as tf   # 텐써 플로우 2.0 
from tensorflow.keras.datasets.mnist import load_data  # 텐써플로우에 내장되어있는 
                                                                         # mnist 데이터를 가져온다.
from tensorflow.keras.models import Sequential  # 모델을 구성하기 위한 모듈
from tensorflow.keras.layers import Dense  # 완전 연결계층을 구성하기 위한 모듈
from tensorflow.keras.utils import to_categorical # one encoding 하는 모듈

tf.random.set_seed(777)

(x_train, y_train), (x_test, y_test) = load_data(path='mnist.npz')  # mnist 데이터 로드
    
# 2. 정규화 진행  
x_train = (x_train.reshape((60000, 28 * 28))) / 255 
x_test = (x_test.reshape((10000, 28 * 28))) / 255

# 3. 정답 데이터를 준비한다. 
# 하나의 숫자를 one hot encoding 한다. (예:  4 ---> 0 0 0 0 1 0 0 0 0 0 ) 
y_train = to_categorical(y_train)  # 훈련 데이터의 라벨(정답)을 원핫 인코딩
y_test = to_categorical(y_test)    # 테스트 데이터의 라벨(정답)을 원핫 인코딩 

# 4. 모델을 구성합니다. 3층 신경망으로 구성
model = Sequential()
model.add(Dense(50, activation = 'sigmoid', input_shape = (784, )))  # 1층
model.add(Dense(50, activation = 'sigmoid') ) # 2층 은닉층 
model.add(Dense(10, activation = 'softmax'))  # 3층 출력층 

# 5. 모델을 설정합니다. ( 경사하강법, 오차함수를 정의해줍니다. )
model.compile(optimizer='SGD', 
                     loss = 'categorical_crossentropy', 
                     metrics=['acc'])  # 학습과정에서 정확도를 보려고 

#6. 모델을 훈련시킵니다. 

history = model.fit(x_train, y_train, 
                         epochs = 30,  # 30에폭
                         batch_size = 100,
                         validation_data=(x_test, y_test) )

# 7.모델을 평가합니다. (오차, 정확도가 출력됩니다.)
model.eval‎uate(x_test, y_test)

train_acc_list=history.history['acc']
train_acc_list

test_acc_list=history.history['val_acc']
test_acc_list

import  matplotlib.pyplot  as  plt

x = np.arange( len(train_acc_list) )
plt.plot( x, train_acc_list, label='train acc')
plt.plot( x, test_acc_list, label='test acc',  linestyle='--')
plt.ylim(0, 1)
plt.legend(loc='lower right')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.show()

훈련 데이터의 정확도 : 0.8875  , 테스트 데이터의 정확도: 0.8894

▩  CNN 을 사용했을때의 코드

# 1. 필요한 패키지 가져오는 코드 

import tensorflow as tf   # 텐써 플로우 2.0 
from tensorflow.keras.datasets.mnist import load_data  # 텐써플로우에 내장되어있는 
                                                                         # mnist 데이터를 가져온다.
from tensorflow.keras.models import Sequential  # 모델을 구성하기 위한 모듈
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten  # 완전 연결계층을 구성하기 위한 모듈
from tensorflow.keras.utils import to_categorical # one encoding 하는 모듈
import  numpy as  np

tf.random.set_seed(777)

(x_train, y_train), (x_test, y_test) = load_data(path='mnist.npz')  # mnist 데이터 로드
print(x_train.shape) # (60000, 28, 28)  
print(x_test.shape) # (10000, 28, 28)    

#2. 색조까지 포함한 4차원 shape 로 reshape 해야합니다.

# 3차원(60000x28x28) ----> 4차원( ? x 28 x 28 x 1 ) 을 변경하는데 안의 요소(픽셀)의 갯수는 동일해야합니다.
x_train = x_train.reshape(-1, 28, 28, 1)
print(x_train.shape)  # (60000, 28, 28, 1)
x_test = x_test.reshape(-1, 28, 28, 1)
print(x_test.shape) # (10000, 28, 28, 1)

# 2. 정규화 진행  
x_train = x_train / 255   # 0~1 사이의 데이터로 변경합니다. 
x_test = x_test / 255

# 3. 정답 데이터를 준비한다. 
# 하나의 숫자를 one hot encoding 한다. (예:  4 ---> 0 0 0 0 1 0 0 0 0 0 ) 
y_train = to_categorical(y_train)  # 훈련 데이터의 라벨(정답)을 원핫 인코딩
y_test = to_categorical(y_test)    # 테스트 데이터의 라벨(정답)을 원핫 인코딩 

# 4. 모델을 구성합니다. 3층 신경망으로 구성
model = Sequential()
model.add(Conv2D(100, kernel_size=(5,5), input_shape=(28,28,1),  activation='relu')  ) 
model.add(MaxPooling2D(pool_size=(2,2), padding='same') ) # 이미지를 선명하게 해주는 층
model.add( Flatten() )  # 완전연결계층들어갈 수 있도록 이미지(피쳐맵들)를 1차원으로 변경 
model.add(Dense(50, activation = 'sigmoid', input_shape = (784, )))  # 1층 완전연결계층
model.add(Dense(50, activation = 'sigmoid') ) # 2층 은닉층 
model.add(Dense(10, activation = 'softmax'))  # 3층 출력층 

# 5. 모델을 설정합니다. ( 경사하강법, 오차함수를 정의해줍니다. )
model.compile(optimizer='SGD', 
                     loss = 'categorical_crossentropy', 
                     metrics=['acc'])  # 학습과정에서 정확도를 보려고 

#6. 모델을 훈련시킵니다. 

history = model.fit(x_train, y_train, 
                         epochs = 30,  # 30에폭
                         batch_size = 100,
                         validation_data=(x_test, y_test) )

# 7.모델을 평가합니다. (오차, 정확도가 출력됩니다.)
model.evaluate(x_test, y_test)

train_acc_list=history.history['acc']
train_acc_list

test_acc_list=history.history['val_acc']
test_acc_list

import  matplotlib.pyplot  as  plt

x = np.arange( len(train_acc_list) )
plt.plot( x, train_acc_list, label='train acc')
plt.plot( x, test_acc_list, label='test acc',  linestyle='--')
plt.ylim(0, 1)
plt.legend(loc='lower right')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.show()


문제244. (점심시간 문제) CNN 을 사용한 전체 코드를 돌리고 코드 전체를 카페에 올리고 정확도도 
             올리시오!

# 1. 필요한 패키지 가져오는 코드 

import tensorflow as tf   # 텐써 플로우 2.0 
from tensorflow.keras.datasets.mnist import load_data  # 텐써플로우에 내장되어있는 
                                                                         # mnist 데이터를 가져온다.
from tensorflow.keras.models import Sequential  # 모델을 구성하기 위한 모듈
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten  # 완전 연결계층을 구성하기 위한 모듈
from tensorflow.keras.utils import to_categorical # one encoding 하는 모듈
import  numpy as  np

tf.random.set_seed(777)

(x_train, y_train), (x_test, y_test) = load_data(path='mnist.npz')  # mnist 데이터 로드
print(x_train.shape) # (60000, 28, 28)  
print(x_test.shape) # (10000, 28, 28)    

#2. 색조까지 포함한 4차원 shape 로 reshape 해야합니다.

# 3차원(60000x28x28) ----> 4차원( ? x 28 x 28 x 1 ) 을 변경하는데 안의 요소(픽셀)의 갯수는 동일해야합니다.
x_train = x_train.reshape(-1, 28, 28, 1)
print(x_train.shape)  # (60000, 28, 28, 1)
x_test = x_test.reshape(-1, 28, 28, 1)
print(x_test.shape) # (10000, 28, 28, 1)

# 2. 정규화 진행  
x_train = x_train / 255   # 0~1 사이의 데이터로 변경합니다. 
x_test = x_test / 255

# 3. 정답 데이터를 준비한다. 
# 하나의 숫자를 one hot encoding 한다. (예:  4 ---> 0 0 0 0 1 0 0 0 0 0 ) 
y_train = to_categorical(y_train)  # 훈련 데이터의 라벨(정답)을 원핫 인코딩
y_test = to_categorical(y_test)    # 테스트 데이터의 라벨(정답)을 원핫 인코딩 

# 4. 모델을 구성합니다. 3층 신경망으로 구성
model = Sequential()
model.add(Conv2D(100, kernel_size=(5,5), input_shape=(28,28,1),  activation='relu', padding='same')  ) 
model.add(MaxPooling2D(pool_size=(2,2), padding='same') ) # 이미지를 선명하게 해주는 층
model.add( Flatten() )  # 완전연결계층에 들어갈 수 있도록 이미지(피쳐맵)를 1차원으로 변경 
model.add(Dense(50, activation = 'sigmoid', input_shape = (784, )))  # 1층 완전연결계층
model.add(Dense(50, activation = 'sigmoid') ) # 2층 은닉층 
model.add(Dense(10, activation = 'softmax'))  # 3층 출력층 

# 5. 모델을 설정합니다. ( 경사하강법, 오차함수를 정의해줍니다. )
model.compile(optimizer='SGD', 
                     loss = 'categorical_crossentropy', 
                     metrics=['acc'])  # 학습과정에서 정확도를 보려고 
model.summary()

#6. 모델을 훈련시킵니다. 

history = model.fit(x_train, y_train, 
                         epochs = 30,  # 30에폭
                         batch_size = 100,
                         validation_data=(x_test, y_test) )

# 7.모델을 평가합니다. (오차, 정확도가 출력됩니다.)
model.evaluate(x_test, y_test)

train_acc_list=history.history['acc']
train_acc_list

test_acc_list=history.history['val_acc']
test_acc_list

import  matplotlib.pyplot  as  plt

x = np.arange( len(train_acc_list) )
plt.plot( x, train_acc_list, label='train acc')
plt.plot( x, test_acc_list, label='test acc',  linestyle='--')
plt.ylim(0, 1)
plt.legend(loc='lower right')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.show()

문제245. 지금까지의 정확도는 0.94 입니다.  경사하강법을 Adam 으로 변경하고 배치 정규화를 
             추가해서 다시 정확도를 확인하세요 !

# 1. 필요한 패키지 가져오는 코드 

import tensorflow as tf   # 텐써 플로우 2.0 
from tensorflow.keras.datasets.mnist import load_data  # 텐써플로우에 내장되어있는 
                                                                         # mnist 데이터를 가져온다.
from tensorflow.keras.models import Sequential  # 모델을 구성하기 위한 모듈
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization  # 완전 연결계층을 구성하기 위한 모듈
from tensorflow.keras.utils import to_categorical # one encoding 하는 모듈
import  numpy as  np

tf.random.set_seed(777)

(x_train, y_train), (x_test, y_test) = load_data(path='mnist.npz')  # mnist 데이터 로드
print(x_train.shape) # (60000, 28, 28)  
print(x_test.shape) # (10000, 28, 28)    

#2. 색조까지 포함한 4차원 shape 로 reshape 해야합니다.

# 3차원(60000x28x28) ----> 4차원( ? x 28 x 28 x 1 ) 을 변경하는데 안의 요소(픽셀)의 갯수는 동일해야합니다.
x_train = x_train.reshape(-1, 28, 28, 1)
print(x_train.shape)  # (60000, 28, 28, 1)
x_test = x_test.reshape(-1, 28, 28, 1)
print(x_test.shape) # (10000, 28, 28, 1)

# 2. 정규화 진행  
x_train = x_train / 255   # 0~1 사이의 데이터로 변경합니다. 
x_test = x_test / 255

# 3. 정답 데이터를 준비한다. 
# 하나의 숫자를 one hot encoding 한다. (예:  4 ---> 0 0 0 0 1 0 0 0 0 0 ) 
y_train = to_categorical(y_train)  # 훈련 데이터의 라벨(정답)을 원핫 인코딩
y_test = to_categorical(y_test)    # 테스트 데이터의 라벨(정답)을 원핫 인코딩 

# 4. 모델을 구성합니다. 3층 신경망으로 구성
model = Sequential()
model.add(Conv2D(100, kernel_size=(5,5), input_shape=(28,28,1),  activation='relu', padding='same')  )
model.add(BatchNormalization()) 
model.add(MaxPooling2D(pool_size=(2,2), padding='same') ) # 이미지를 선명하게 해주는 층
model.add( Flatten() )  # 완전연결계층에 들어갈 수 있도록 이미지(피쳐맵)를 1차원으로 변경 
model.add(Dense(50, activation = 'sigmoid', input_shape = (784, )))  # 1층 완전연결계층
model.add(BatchNormalization())
model.add(Dense(50, activation = 'sigmoid') ) # 2층 은닉층 
model.add(BatchNormalization())
model.add(Dense(10, activation = 'softmax'))  # 3층 출력층 

# 5. 모델을 설정합니다. ( 경사하강법, 오차함수를 정의해줍니다. )
model.compile(optimizer='Adam', 
                     loss = 'categorical_crossentropy', 
                     metrics=['acc'])  # 학습과정에서 정확도를 보려고 
model.summary()

문제246.  오버피팅을 방지 하기 위해서 dropout 을 가지치기 비율을 0.3 로 해서  훈련 시키시오 



문제247.  조기종료 코드를 추가해서 오버피팅을 최소화 하면서 정확도가 가장 좋은 모델이
             생성되게하시오 !
                                             신호 보냈습니다.  45분까지 쉬세요 ~~
#6. 모델을 훈련시킵니다. 
from  tensorflow.keras.callbacks import EarlyStopping

callbacks = [EarlyStopping(monitor='val_acc', patience=5, verbose=1)]

history = model.fit(x_train, y_train, 
                         epochs = 30,  # 30에폭
                         batch_size = 100,
                         validation_data=(x_test, y_test),
                         callbacks= callbacks )

# 7.모델을 평가합니다. (오차, 정확도가 출력됩니다.)                
model.evaluate(x_test, y_test)

train_acc_list=history.history['acc']
train_acc_list

test_acc_list=history.history['val_acc']
test_acc_list

import  matplotlib.pyplot  as  plt

x = np.arange( len(train_acc_list) )
plt.plot( x, train_acc_list, label='train acc')
plt.plot( x, test_acc_list, label='test acc',  linestyle='--')
plt.ylim(0, 1)
plt.legend(loc='lower right')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.show()

지금까지 배운것은 그냥 합성곱 연산이고 이제 부터는 3차원 합성곱을 배워보겠습니다. 

■  3차원 데이터의 합성곱 연산 (p235) 

 그림 7-8

문제248. 그림 7-8의 RGB 입력 이미지와 RGB 필터 이미지를 생성하시오!

x2 =np.array([[[1,2,3,0],
                  [0,1,2,3], 
                  [3,0,1,2],
                 [2,3,0,1]],
                 [[2,3,4,1],
                  [1,2,3,4],  
                   [4,1,2,3],
                   [3,4,1,2]],
                  [[3,4,5,2],  
                 [2,3,4,5],
                 [5,2,3,4],
                [4,5,2,3]]])

filter2 =np.array([[[2,0,1],
                       [0,1,2],
                      [1,0,2]],
                   [[3,1,2],
                    [1,2,3],
                    [2,1,3]],
                  [[4,2,3],
                   [2,3,4],
                  [3,2,4]]])

문제249. 3차원 합성곱을 하기전에 먼저 원보 이미지 x2 에서 red 행렬만 출력하시오!

x2 =np.array([[[1,2,3,0],
                  [0,1,2,3], 
                  [3,0,1,2],
                 [2,3,0,1]],
                 [[2,3,4,1],
                  [1,2,3,4],  
                   [4,1,2,3],
                   [3,4,1,2]],
                  [[3,4,5,2],  
                 [2,3,4,5],
                 [5,2,3,4],
                [4,5,2,3]]])

print( x2.shape) #( 3, 4, 4 )
print( x2[0, : , : ] )

문제250. 아래의 RGB 필터 이미지에서 red 행렬만 가져오시오 !

filter2 =np.array([[[2,0,1],
                       [0,1,2],
                      [1,0,2]],
                   [[3,1,2],
                    [1,2,3],
                    [2,1,3]],
                  [[4,2,3],
                   [2,3,4],
                  [3,2,4]]])

print(filter2[ 0, : , : ])

문제251. 원본이미지의 red 행렬(3x3) 와 필터 이미지 red행렬(3x3) 과의 합성곱을 하시오 !

np.sum(x2[0,0:3,0:3] * filter2[0,:,:])

문제252.  이번에는 red 행렬 전체를 스트라이드 해서 red 행렬 filter 와  합성곱하시오 

a=[]
for  i  in  range(2):
    for  j  in  range(2):
        a.append( np.sum( x2[ 0,i:3+i , j:3+j ] * filter2[0,:,:]) ) 
a2 = np.array(a).reshape(2,2)
print(a2)

[[15 16]
 [ 6 15]]

문제253. 위의 코드의 for 문을 한번 더 써서 그림 7-8의 3차원 합성곱을 완성시키기 위해서 
            아래의 결과를 출력하시오 

[15, 16, 6, 15, 46, 48, 36, 46, 95, 98, 84, 95]

a2=[]
for  k  in  range(3):
    for  i  in  range(2):
        for  j  in  range(2):
            a2.append( np.sum( x2[ k,i:3+i , j:3+j ] * filter2[k,:,:]) ) 
print(a2)

문제254. 위의 a2 리스트에 있는 원소들로 아래와 같이 3x4 행렬을 만드시오 

 15, 16, 6, 15, 
 46, 48, 36, 46, 
 95, 98, 84, 95

a2=[]
for  k  in  range(3):
    for  i  in  range(2):
        for  j  in  range(2):
            a2.append( np.sum( x2[ k,i:3+i , j:3+j ] * filter2[k,:,:]) ) 
a3 = np.array(a2).reshape(3,4)
print(a3)

문제255. 아래의 행렬에서 세로로 값을 더해서 아래의 결과를 출력하시오 !

 15, 16, 6, 15, 
 46, 48, 36, 46, 
 95, 98, 84, 95

결과: [ 156, 162, 126, 156 ] 

답: np.sum(a3, axis= 0 )    # axis=0 이면 세로로 더한다.
                                   # axis=1 이면 가로로 더한다. 

문제256. 위의 a3 리스트를 2x2 행렬로 reshape 하시오 !

a4 = a3.reshape(2,2)
print(a4)                        50분까지 쉬세요 ~~ 

동민이 코드:
np.zeros 사용하여 사진처럼 할수있습니다.

map = np.zeros((2,2))
for k in range(3):
  for i in range(2):
    for j in range(2):
      map[i,j] += np.sum(x2[k,0+i:3+i,0+j:3+j] * filter2[k])

print(map)

#[[156. 162.]
# [126. 156.]]

R과 파이썬 머신러닝 포트폴리오 ppt 를 제출하면 됩니다.

탐색적 데이터 분석에 제출하고 사인 하세요 ~~ 답안 밑에 첨부파일에 첨부하고 올리세요~
답안은 아무것도 안써도 되고 첨부파일만 올리세요 ~

13기 공지 게시판에 올렸습니다. 워드로 작성하는데 메모장의 문제들을 다 복사해서
워드에 붙여넣고  답안과 코드를 캡쳐해서 붙이고 아래의 이름으로 저장해서 제출하세요 !!

1. 애플리케이션 테스트 수행_본인이름.tx

2. 화면 설계_본인이름.txt

화면설계 문제 7번에 문제랑 SQL이랑 다른데 문제데로 월급을 넣어서 작성하세요 !
화면설계 문제6번도 문제데로 하세요.부서번호 빼고 작성하면 됩니다. 


■ 딥러닝 책 복습 

1장. numpy 활용법
2장. 퍼셉트론
3장. 필기체 데이터를 인식하는 3층 신경망 구현(저자가 만들어온 가중치)
4장. 2층 신경망( 직접 학습을 시킴, 수치미분)
5장. 2층 신경망( 직접 학습을 시킴, 오차역전파)  --> 계산 그래프
6장. 언더피팅과 오버피팅을 방지하는 방법들 소개 
7장. CNN 을 이용해서 신경망을 구현하기 
8장. 딥러닝 활용 주제들 소개 

■ 7장. CNN 을 이용해서 신경망을 구현하기 

  이미지를 분류할 때 CNN 을 사용해야하는 이유?

    답:  이미지를 바로 flatten 시키지 않고 이미지를 이미지 자체로 인식하겠금 하는 
          합성곱과 풀링을 이용해야 이미지를 잘 분류할 수 있기 때문입니다.

4x4 의 입력이미지를 3x3 의 필터로 합성곱하면 (스트라이드 1) 하면 결과 output 의 shape 는 ?


■ 스트라이드 

  합성곱 할 때 원본 이미지를 필터로 이동하면서 피쳐맵을 생성하는 과정을 말합니다.
  이동을 몇칸으로 할지를 결정하는것 
  
  텐써플로우로 코딩을 할 때는 스트라이드를 몇을 줄지를 고민하지 않아도 됩니다.

1. 텐써플로우 2.0 으로 구현

model.add(Conv2D(100, (3, 3), padding='same', input_shape=( 4, 4, 1) )

코드설명: 입력 이미지 4x4 이미지에 3x3 필터를 이용해서 출력 이미지를 4x4 로 하겠다. 


2. 파이썬 날코딩(p251)

conv_params={'fiter_num': 100, 'filter_size':3, 'pad': 계산된 값, 'stride':1}

계산공식(p234의 식7.1)

       (OH - 1) * S - H +FH        ( 4 - 1) *  1 - 4 + 3 
P = -------------------------- = ------------------------------= 1
               2                                          2

OH= 출력 이미지의 세로
OW = 출력 이미지의 가로
H= 입력이미지의 세로
W = 입력이미지의 가로
FH = 필터의 가로
FW = 필터의 세로


model.add(Conv2D(100, (3, 3), padding='same', input_shape=( 4, 4, 1) )

※ 컨볼루션층에서 하는 작업은 원본 이미지를 가지고 여러개의 비슷한 이미지를 만들어 내는
   작업입니다.  이 비슷한 이미지들이 바로 feature map 입니다.
   그리고 이 feature ma 의 갯수는 필터의 갯수와 동일하게 생성이 됩니다.
   아래와 같이 convolution 층을 구성했으면 생성되는 피쳐맵의 갯수는?
 
model.add(Conv2D(32, (3, 3), padding='same', input_shape=( 4, 4, 1) )
                        ↓
 100장 ---->  covolution  ----> 피쳐맵의 갯수 ? 3200장

 위와 같이 여러장이 생성이 되므로 신경망이 머릿속에 잘 이해되게하려면 그림으로 이해하는게
 좋은게 그 방법이 블럭으로 생각하기 입니다.

■ 블럭으로 생각하기(p237)

 3차원 합성곱 연산은 데이터와 필터를 직육면체 블럭으로 생각하면 쉽습니다. 

 그림 7-10   ------>  설현 사진 RGB 컬러 사진 1장을 RGB 필터로 합성곱해서
                            1개의 feature map 을 출력하는 그림
                                        ↓
                           원본 이미지의 특징을 담고있는 이미지 
       ↓

 그림 7-11 ---------> 설현 사진 1장에 필터 FN 개를 합성곱하고 FN 개의 피쳐맵을 출력하는 그림

      ↓

 그림 7-12 ---------->  설현 사진 1장에 필터 FN 개를 합성곱하고 FN 의 편향을 더해서 FN 개의
                                피쳐맵을 출력하는 그림 

     ↓

 그림 7-13  ---------> 미니배치의 갯수 N 개 만큼 설현 사진을 입력해서 필터 FN개와 합성곱하여
                              미니배치 갯수 N 개 만큼 피쳐맵을 출력하는 그림 


정리하면 RGB 설현사진 1장을 32개의 RGB 필터로 합성곱하면 32개의 피쳐맵이 생기는데
100개의 설현 사진이 32개의 RGB 필터와 합성곱을 하면 설현 사진 1장당 피쳐맵이 32개가 
생성되므로 설현 사진이 100장이니까 피쳐맵이 총 3200 장이 되는 것입니다.

문제257. 설현 사진 한장을 4차원 행렬로 만드시오 !

import  numpy  as  np

x1 = np.random.rand(1, 3, 7, 7 )
print(x1)
print(x1.shape)
print(x1.ndim)

문제258. 설현 사진 10장을 생성하시오 !

import  numpy  as  np

x1 = np.random.rand(10, 3, 7, 7 )
print(x1)
print(x1.shape)
print(x1.ndim)

그림 7-13 처럼 4차원의 데이터가 신경망에 그대로 입력되어서 합성곱을 하게 되면 시간이
너무 많이 걸립니다. 그래서 시간을 줄일려면 어떻게 해줘야하는가 ?

  코드를 변경해야합니다.  4차원 ---> 2차원으로 변경해줘야 합니다. (im2col함수)
                                   그리고 2차원으로 계산해 나가면 됩니다. 

■ im2col 함수는 ?    신경망에서 합성곱을 진행하는데 입력되는 4차원 데이터를 2차원 데이터로
                             차원 축소해서 2차원 필터와 내적해서 합성곱하게 만드는 함수 

im2col 함수의 원리?  p243 

그림 7-17 

(10, 3, 7, 7 )  ----------------> ( 90, 75)  가 되는지 원리 이해 ?

게시글 793. [쉬움주의] im2col 이 convolution 층에서 하는 역활

(100, 3, 7, 7 ) -----> (100, 147)  로 reshape 된것은 필터는 생각하지 않고 원본이미지만
그냥 2차원으로 변경한것이 첫번째 그림입니다. 

그런데 합성곱을 하려면 필터를 생각해야합니다 필터의 사이즈에 맞춰서 원본이미지를 
2차원으로 변경해줘야합니다. 그게 바로 두번째 그림 입니다. 

문제259.  설현사진 10장을 가로 7, 세로 7 로 해서 RGB 채널로 생성하시오 !

import  numpy  as  np

x1 = np.random.rand(10, 3, 7, 7)

문제260. im2col 함수를 생성하시오 !

def im2col(input_data, filter_h, filter_w, stride=1, pad=0):
    """다수의 이미지를 입력받아 2차원 배열로 변환한다(평탄화).
    Parameters
    ----------
    input_data : 4차원 배열 형태의 입력 데이터(이미지 수, 채널 수, 높이, 너비)
    filter_h : 필터의 높이
    filter_w : 필터의 너비
    stride : 스트라이드
    pad : 패딩
    Returns
    -------
    col : 2차원 배열
    """
    N, C, H, W = input_data.shape
    out_h = (H + 2 * pad - filter_h) // stride + 1
    out_w = (W + 2 * pad - filter_w) // stride + 1
    img = np.pad(input_data, [(0, 0), (0, 0), (pad, pad), (pad, pad)], 'constant')
    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))
    for y in range(filter_h):
        y_max = y + stride * out_h
        for x in range(filter_w):
            x_max = x + stride * out_w
            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]
    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, -1)
    return col

문제261. 설현사진 10장을 im2col 함수에 넣어서  2차원 행렬로 변환하시오 !

         4차원 ---------------------> 2차원
    (10, 3, 7 ,7 )                          (90, 75)


import  numpy  as  np

x1 = np.random.rand(10, 3, 7, 7)
result = im2col(x1, 5, 5, stride=1, pad=0)
print(result.shape)

문제262.  설현사진 100장을 im2col 함수에 넣어서 2차원 행렬로 변환하시오 !
            (필터 5x5, 스트라이드 1, 패딩 0 )

         4차원 ---------------------> 2차원
    (100, 3, 7 ,7 )                          ( 900 , 75 )

지금 까지는 원본이미지만 2차원으로 변경했고 필터도 2차원으로 변경해줘야합니다. 
다음과 같이 rgb 필터를 10개 생성하시오

filter = np.random.rand(10, 3, 5, 5)
print(filter.shape)

원본 이미지도 2차원으로 변경해줘야하고 필터도 2차원으로 변경해줘야합니다.
그런데 원본 이미지는 im2col 을 이용해서 2차원으로 변경해주는데
필터는 im2col 를 이용하지 않고 그냥 reshape 만 이용해서 2차원으로 변경해줍니다. 

왜 reshape 만 이용하는가?  im2col 을 이용하면 안되는가 ?  

원본이미지는 필터 사이즈에 맞춰서 2차원으로 변경해줘야 하기 때문에 im2col 함수가 필요했지만
필터는 그럴 필요가 없기 때문에 그냥 reshape 만 이용하면 됩니다. 

문제263.  필터 4차원을 3차원으로 변경하시오 !

      4차원                                            3차원 
 (10, 3, 5, 5 )  -------------------------> ( 10, 3, 25 )

import  numpy  as  np

filter = np.random.randn(10, 3, 5, 5 )
filter2 = filter.reshape(10, 3, -1)  # 그냥 -1 만 사용하면 알아서 계산한다. 
print(filter2.shape)

문제264. 아래의 필터 4차원을 2차원으로 변경하시오 !

   4차원 ----------------------> 2차원
 (10, 3, 5, 5 )                      ( 10,  ?  )

import  numpy  as  np

filter = np.random.randn(10, 3, 5, 5 )
filter2 = filter.reshape(10, -1)  # 그냥 -1 만 사용하면 알아서 계산한다. 
print(filter2.shape)  # (10, 75)

원본이미지도 2차원으로 변경했고 필터도 2차원으로 변경했으니까 이제 내적만 하면 됩니다.


그림 7-19

우리는 그냥 책 246 페이지에 나온것처럼 Convolution 클래스를 안만들어도 되고 그냥 구글에 만든
Conv2D 함수를 이용해서  합성곱층을 쌓기만 하면 되지만 어떻게 만들어졌는지 원리는 이해를 
해야합니다.

model.add(Conv2D(32,(3, 3), padding='same')

그래서 정리하면 합성곱 층에서 일어나는 일은 이미지의 특징을 잡아낸 여러개의 피쳐맵을
생성하는것인데 합성곱할때 4차원의 이미지를 합성곱하면 시간이 너무 오래걸리므로
2차원으로 변경해서 계산하는게 훨씬 속도가 빠릅니다. 그래서 다음과 같이 계산하는데

1. 원본이미지 ---> im2col ---> 2차원으로 변경
2. 필터  ---------> reshape ---> 2차원으로 변경
3. 두개의 2차원 이미지를 서로 내적을 하고 (2차원 원본이미지 ◎ 2차원 필터.T) 
4. 3번의 결과를 다시 4차원으로 변경

■ 풀링계층 구현하기(p247)
                                         
                           convolution 층이 이렇게 저렇게 망쳐놓은 그림들을 가지고 
                            피쳐맵의 이미지의 각 부분에서 대표값들을 뽑아 사이즈가 작은 이미지를
                            만드는 역활(이미지가 선명해진다)
                                                         ↑
 원본이미지 -------> conv ---> relu ---> pooling ----->  fully connected 
                            ↓                                               (완전 연결계층)
                      원본이미지의 특징을 잡아내는
                      피쳐맵을 필터의 갯수에 맞춰 생성하는 층

코드예:
model.add(Conv2D(32,3,3))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))  <----- 풀링의 위치 
model.add(Dropout(0.2) )

풀링층의 역활?  convolution 층이 이미지의 특징을 잡아내는 역활을 한다면
                      pooling 층은 피쳐맵의 이미지를 선명하게 만드는 역활을 합니다.

 " 말 그대로 출력값에서 일부분만 취하는 기능 "

 마치 사진을 축소하면 해상도가 좋아지는 듯한 효과와 비슷합니다.

※ 풀링(pooling) 의 종류 3가지 ?

1. 최대풀링 : 컨볼루션 데이터(피쳐맵)에서 가장 큰값을 대표값으로 선정하는것을 말합니다.

 그림 :  https://cafe.daum.net/oracleoracle/Shyl/795

 효과: 이미지를 선명하게 만드는 효과

2. 평균풀링 : 컨볼루션 데이터(피쳐맵)에서 모든값의 평균값을 대표값으로 선정

 효과:  이미지를 부드럽게 하는 효과 

3. 확률적 풀링 :  컨볼루션 데이터에서 임의 확률로 한개를 선정 

효과:  어쩌다보니 우연히 이미지 원본 이미지처럼 나타났다.

문제265. 아래의 행렬을 넘파이로 만드시오 !

  21  8  8  12
  12  19  9  7
  8  10  4   3
 18  12  9  10

답:
x = np.array([ 21, 8, 8, 12, 12, 19, 9, 7, 8, 10, 4, 3, 18, 12, 9, 10]).reshape(4,4)
x2 =x.reshape(1,1,4,4)  # 4차원 데이터로 생성
x2

문제266. 위에서 만든 행렬에서 maxpooling 을 시도해서 아래의 결과를 출력하시오
              ( 4차원을 2차원으로 변경하는데 im2col 을 이용해서 필터 사이즈는 2x2, 스트라이드2)

  21  8  8  12          
  12  19  9  7           ------------------->    21   12
  8  10  4   3                                         18   10
 18  12  9  10

x = np.array([ 21, 8, 8, 12, 12, 19, 9, 7, 8, 10, 4, 3, 18, 12, 9, 10]).reshape(4,4)
x2 =x.reshape(1,1,4,4)  # 4차원 데이터로 생성
a = im2col( x2, 2, 2, 2, 0 )
print(a)
                     
[[21.  8. 12. 19.]  ----------------------> 21
 [ 8. 12.  9.  7.]  ----------------------> 12
 [ 8. 10. 18. 12.] -----------------------> 18
 [ 4.  3.  9. 10.]] ----------------------->  10
​
d = np.max(a, axis= 1 )
print( d.reshape(2,2) ) 

문제267. 문제266은 maxpooling 인데 이번에는 평균풀링을 하시오! 

  21  8  8  12          
  12  19  9  7           ------------------->      ?
  8  10  4   3                                        
 18  12  9  10

답:
k = np.mean(a, axis= 1 )
print( k.reshape(2,2) ) 

문제268. 문제267은 평균풀링인데 이번에는 확률적 풀링이 되게 하시오 !
             ( 카페에 답을 올려주세요 )


  21  8  8  12          
  12  19  9  7           ------------------->      ?
  8  10  4   3                                        
 18  12  9  10

답:
승혁이 코드:
b = im2col(a2,2,2,2,0)

dst = np.zeros(4,)

for i,v in enumerate(b):
    dst[i] = np.random.choice(v,1)
dst.reshape(2,2)

  21  8  8  12          
  12  19  9  7           
  8  10  4   3                                        
 18  12  9  10

동민이 코드:

res = []
for i in range(len(a)):
    res.append(np.random.choice(a[i]))
res

■ cnn 구현하기 (p250)

 책은 날코딩으로 필기체데이터를 분류하는 cnn 신경망을 만들었는데
  우리는 텐써플로우 2.0 으로 cnn 신경만을 만들어 보겠습니다.

# CNN 을 사용하지 않은 완전연결계층(https://cafe.daum.net/oracleoracle/Shyl/555)

# 1. 필요한 패키지 가져오는 코드 

import tensorflow as tf   # 텐써 플로우 2.0 
from tensorflow.keras.datasets.mnist import load_data  # 텐써플로우에 내장되어있는 
                                                                         # mnist 데이터를 가져온다.
from tensorflow.keras.models import Sequential  # 모델을 구성하기 위한 모듈
from tensorflow.keras.layers import Dense  # 완전 연결계층을 구성하기 위한 모듈
from tensorflow.keras.utils import to_categorical # one encoding 하는 모듈

tf.random.set_seed(777)

(x_train, y_train), (x_test, y_test) = load_data(path='mnist.npz')  # mnist 데이터 로드
    
# 2. 정규화 진행  
#x_train = (x_train.reshape((60000, 28 * 28))) / 255 
#x_test = (x_test.reshape((10000, 28 * 28))) / 255

x_train = x_train.reshape(-1, 28, 28, 1)  # 4차원으로 변경합니다. 
x_test = x_test.reshape(-1, 28, 28, 1 )

# 3. 정답 데이터를 준비한다. 
# 하나의 숫자를 one hot encoding 한다. (예:  4 ---> 0 0 0 0 1 0 0 0 0 0 ) 
y_train = to_categorical(y_train)  # 훈련 데이터의 라벨(정답)을 원핫 인코딩
y_test = to_categorical(y_test)    # 테스트 데이터의 라벨(정답)을 원핫 인코딩 


# 4. 모델을 구성합니다. 3층 신경망으로 구성

model = Sequential()
model.add( Conv2D(100, kernel_size=(5,5), input_shape=(28, 28, 1), activation='relu') )
model.add( MaxPooling2D(pool_size=(2,2), padding='same') )
model.add(Flatten() )
model.add(Dense(50, activation = 'relu', input_shape = (784, )))  # 1층
model.add(Dense(10, activation = 'softmax'))  # 2층 출력층 


# 5. 모델을 설정합니다. ( 경사하강법, 오차함수를 정의해줍니다. )

model.compile(optimizer='SGD', 
              loss = 'categorical_crossentropy', 
              metrics=['acc'])  # 학습과정에서 정확도를 보려고 

#6. 모델을 훈련시킵니다. 

history = model.fit(x_train, y_train, 
                    epochs = 30,  # 30에폭
                    batch_size = 100)

# 7.모델을 평가합니다. (오차, 정확도가 출력됩니다.)

model.eval‎uate(x_test, y_test)

[0.1936708241701126, 0.9829000234603882]  <--- 정확도 

문제269. 위의 신경망에 배치정규화 층을 추가하시오 !

힌트:  model.add(BatchNormalization())


문제270. 이번에는 위의 신경망 설계도에  데이터를 fashion mnist 로 변경해서 수행하시오 !

힌트:

from  tensorflow.keras.datasets.fashion_mnist  import  load_data

(x_train, y_train), (x_test, y_test) = load_data()

Epoch 30/30
600/600 [==============================] - 3s 4ms/step - loss: 0.0144 - acc: 0.9949
313/313 [==============================] - 1s 2ms/step - loss: 0.5168 - acc: 0.9126
[0.5168185234069824, 0.9125999808311462]

훈련 데이터의 정확도는 0.99 인데 테스트 데이터의 정확도가 0.91 입니다. 
그래서 오버피팅이 발생했습니다. 

문제271. 위의 패션 mnist 데이터 신경망에 오버피팅이 발생했습니다. 오버피팅이 발생하지 않도록
             dropout 을 추가하세요

힌트: model.add(Dropout(0.2))

답:

model = Sequential()
model.add( Conv2D(100, kernel_size=(5,5), input_shape=(28, 28, 1), activation='relu') )
model.add(BatchNormalization())
model.add( MaxPooling2D(pool_size=(2,2), padding='same') )
model.add(Dropout(0.4))

model.add(Flatten() )
model.add(Dense(50, activation = 'relu', input_shape = (784, )))  # 1층
model.add(BatchNormalization())
model.add(Dropout(0.4))
model.add(Dense(10, activation = 'softmax'))  # 2층 출력층 

600/600 [==============================] - 3s 5ms/step - loss: 0.1396 - acc: 0.9478
313/313 [==============================] - 1s 3ms/step - loss: 0.2519 - acc: 0.9182
[0.2519133388996124, 0.9182000160217285]

 드룹아웃 비율을 0.2 에서 0.4 로 늘렸더니 훈련 데이터의 정확도는 다소 떨어졌으나
 오버피팅이 확실히 줄었습니다

훈련 데이터의 정확도: 0.94,  테스트 데이터의 정확도: 0.91

문제272. 이번에는 다음과 같이 신경망을 설계하시오 !

 기존층:  conv --> pooling --->  fully connected  1층 ----> fully connected  2층 
   ↓
 변경된 층:  conv ---> pooling ---> conv ---> pooling ---> fc 1층 ---> fc 2층 

# 4. 모델을 구성합니다. 3층 신경망으로 구성

model = Sequential()
model.add( Conv2D(100, kernel_size=(5,5), input_shape=(28, 28, 1), activation='relu') )
model.add(BatchNormalization())
model.add( MaxPooling2D(pool_size=(2,2), padding='same') )
model.add(Dropout(0.4))
model.add( Conv2D(100, kernel_size=(5,5), activation='relu') )
model.add(BatchNormalization())
model.add( MaxPooling2D(pool_size=(2,2), padding='same') )
model.add(Dropout(0.4))

model.add(Flatten() )
model.add(Dense(50, activation = 'relu', input_shape = (784, )))  # 1층
model.add(BatchNormalization())
model.add(Dropout(0.4))
model.add(Dense(10, activation = 'softmax'))  # 2층 출력층 

Epoch 30/30
600/600 [==============================] - 4s 7ms/step - loss: 0.1758 - acc: 0.9359
313/313 [==============================] - 1s 3ms/step - loss: 0.2352 - acc: 0.9155
[0.23519083857536316, 0.9154999852180481]

훈련 데이터의 정확도는 0.93 이고 테스트 데이터의 정확도는 0.91 입니다.
이런 경우에는 에폭수를 더 늘리면 정확도가 계속 올라갑니다. 

문제273.  이번에는 30에폭이 아니라 60 에폭으로 변경해서 수행하시오 !


■ 정상 이파리와 질병 이파리를 분류하기 위한 데이터 전처리 함수들 생성하기 

 1. 로컬 주피터 노트북에서 함수를 생성하세요.
 2. 데이터셋은 저번에 다운로드 받은것 또는 아래의 링크를 통해서 다운로드 받으세요.

예제1. 이미지를 아래와 같이 준비하세요 ~

D:\leaf\train4000 <--- 훈련 데이터 이미지 4000장
D:\leaf\test100  <--- 테스트 데이터 이미지 100장 

예제2.  D:\leaf\test100 폴더에서 이미지의 이름을 가져오는 함수를 생성하시오 !

test_images='D:\\leaf\\test100'

import  os

def  image_load(path):
    file_list = os.listdir(path)  # 폴더안에 있는 파일들의 이름을 가져옵니다. 
    return  file_list

print( image_load(test_images) )

['1.jpg', '10.jpg', '1000.jpg', '11.jpg', ...........................

예제3. 위의 결과에서 .jpg 는 빼고 숫자만 출력되게하시오 !

test_images='D:\\leaf\\test100'

import  os
import  re # 데이터 전처리 전문 모듈

def  image_load(path):
    file_list = os.listdir(path)  # 폴더안에 있는 파일들의 이름을 가져옵니다. 
    file_name =[]
    for  i  in  file_list:  # file list 를 하나씩 불러오는데 
        a = int( re.sub('[^0-9]', '', i) )  # i 가 숫자가 아니면 null 로 변경해라 ~
        file_name.append(a)
    return  file_name

print( image_load(test_images) )

[1, 10, 1000, 11, 12, 13, 14, 15

예제4. 위의 결과가  정렬이 되어서 출력되게하시오 

결과: [ 1, 2, 3, 4, 5, ...... ]

test_images='D:\\leaf\\test100'

import  os
import  re # 데이터 전처리 전문 모듈

def  image_load(path):
    file_list = os.listdir(path)  # 폴더안에 있는 파일들의 이름을 가져옵니다. 
    file_name =[]
    for  i  in  file_list:  # file list 를 하나씩 불러오는데 
        a = int( re.sub('[^0-9]', '', i) )  # i 가 숫자가 아니면 null 로 변경해라 ~
        file_name.append(a)
    file_name.sort()
    return  file_name

print( image_load(test_images) )

예제5. 위에서 출력된 결과를 아래와 같이 .jpg 를 붙여서 출력되게하시오 !

[ 1.jpg, 2.jpg, 3.jpg, ..........................................  ]

test_images='D:\\leaf\\test100'

import  os
import  re # 데이터 전처리 전문 모듈

def  image_load(path):
    file_list = os.listdir(path)  # 폴더안에 있는 파일들의 이름을 가져옵니다. 
    file_name =[]
    for  i  in  file_list:  # file list 를 하나씩 불러오는데 
        a = int( re.sub('[^0-9]', '', i) )  # i 가 숫자가 아니면 null 로 변경해라 ~
        file_name.append(a)
    file_name.sort()

    file_res=[]
    for  j  in  file_name:
        file_res.append('%d.jpg' %j)

    return  file_res

print( image_load(test_images) )

예제6. (오늘의 마지막 문제) 이미지 이름 앞에 아래와 같이 절대경로가 붙게 하시오

['D:\\leaf\\test100\\1.jpg', 'D:\\leaf\\test100\\2.jpg', 'D:\\leaf\\test100\\3.jpg',.....  ]


 마지막 문제 올리시고 나머지 시간은 자유롭게 자습하세요 ~~~

 
test_images = 'D:\\leaf\\test100'

import os
import re # 데이터 전처리

def image_load(path):
    file_list = os.listdir(path) # 폴더 안에 있는 파일들의 이름을 가져옴
    file_name = []
    for i in file_list:
        a = int(re.sub('[^0-9]','',i)) # i 가 숫자가 아니면 null로 변경
        file_name.append(a)
    file_name.sort()
    
    file_res=[]
    for i in file_name:
        file_res.append('%s\\%d.jpg'%(test_images,i))

    return file_res

print(image_load(test_images))

['D:\\leaf\\test100\\1.jpg', 'D:\\leaf\\test100\\2.jpg', 'D:\\leaf\\test100\\3.jpg', 'D:\\leaf\\test100\\4.jpg', 'D:\\leaf\\test100\\5.jpg', 'D:\\leaf\\test100\\6.jpg', 'D:\\leaf\\test100\\7.jpg'

예제7.  위에서 출력되고 있는 경로와 이미지명을 가지고 그 이미지들을 숫자로 변환하는 코드를 추가하시오
          ( 이미지를 신경망에 넣으려면 숫자로 변경해줘야합니다.)

test_images = 'D:\\leaf\\test100'

import os
import re # 데이터 전처리

def image_load(path):
    file_list = os.listdir(path) # 폴더 안에 있는 파일들의 이름을 가져옴
    file_name = []
    for i in file_list:
        a = int(re.sub('[^0-9]','',i)) # i 가 숫자가 아니면 null로 변경
        file_name.append(a)
    file_name.sort()
    
    file_res=[]
    for i in file_name:
        file_res.append('%s\\%d.jpg'%(test_images,i))

    image = []
    for  k  in  file_res:
        img = cv2.imread(k)
        image.append(img)

    return np.array(image)

print(image_load(test_images))

신경망에 이미지와 정답을 넣으려면 이미지는 숫자로 변경해서 넣어야하고 
정답은 0(정상) 또는 1(질병) 로 하는 숫자 데이터를 생성해야 합니다. 

■ 이파리 데이터의 정답 데이터 만들기 (csv 파일 만들기)

테스트 데이터: 1~50까지가 정상 이파리, 51~100까지가 질병 이파리 
훈련 데이터 : 1 ~ 2000 까지가 정상 이파리, 2001 ~ 4000 까지가 질병 이파리 

예제1. 테스트 데이터에 대한 정답 데이터인 test_label.csv 를 생성하시오
        ( 숫자가 전체 100개가 있는데 50개는 0 이고 50개는 1이어야 합니다.)

path="d:\\leaf\\test_label.csv"

file=open( path, 'w')

for  i  in  range(0,50):
    file.write( str(0) + '\n')
for i  in  range(0, 50):
    file.write( str(1) + '\n')

file.close()

예제2. 훈련 데이터에 대한 정답 데이터인 train_label.csv 를 생성하시오
        (숫자가 전체 4000 개가 있는데 2000 개는 0 이고 2000개는 1이어야 합니다.)

path="d:\\leaf\\train_label.csv"

file=open( path, 'w')

for  i  in  range(0,2000):
    file.write( str(0) + '\n')
for i  in  range(0, 2000):
    file.write( str(1) + '\n')

file.close()

데이터 전처리 준비는 다 되었습니다. 이제 코렙의 GPU 를 이용해서 이파리 데이터를 분류하는
신경망을 만들어 보겠습니다.

■ 코렙에서 이파리 데이터 분류하기 


문제274.  지금 훈련 데이터의 정확도는 0.98 인데 테스트 데이터의 정확도가 0.78 이므로
             오버피팅이 발생했습니다.  오버피티을 줄이면서 테스트 데이터의 정확도가 0.80을
             넘길 수 있도록 코드를 수정하시오 ~

# 드롭아웃 적용하기

# 1. 필요한 패키지 가져오는 코드 

import tensorflow as tf   # 텐써 플로우 2.0 
from tensorflow.keras.datasets.mnist import load_data  # 텐써플로우에 내장되어있는 
                                                                         # mnist 데이터를 가져온다.
from tensorflow.keras.models import Sequential  # 모델을 구성하기 위한 모듈
from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Conv2D, MaxPooling2D ,Flatten# 완전 연결계층을 구성하기 위한 모듈
from tensorflow.keras.utils import to_categorical # one encoding 하는 모듈
import numpy as  np

tf.random.set_seed(777)


# 4. 모델을 구성합니다. 5층 신경망으로 구성
#  합성곱1 --> 합성곱2 --> 완전연결계층1 --> 완전연결계층 2 --> 출력층

model = Sequential()
model.add( Conv2D(100, kernel_size=(5,5),input_shape=(32,32,3), activation='relu',padding='same') )
model.add(BatchNormalization())
model.add( MaxPooling2D(pool_size=(2, 2), padding='same') )
model.add( Conv2D(100, kernel_size=(5,5), activation='relu',padding='same') )
model.add(BatchNormalization())
model.add( MaxPooling2D(pool_size=(2, 2), padding='same') )
model.add( Conv2D(100, kernel_size=(5,5), activation='relu',padding='same') )
model.add(BatchNormalization())
model.add( MaxPooling2D(pool_size=(2, 2), padding='same') )
model.add( Flatten() )
model.add(Dense(100, activation = 'relu', input_shape = (32*32, )))  # 1층
model.add(BatchNormalization())
model.add(Dropout(0.3))
model.add(Dense(100, activation = 'relu') ) # 2층 은닉층 
model.add(BatchNormalization())
model.add(Dropout(0.3))
model.add(Dense(2, activation = 'softmax'))  # 3층 출력층 

# 5. 모델을 설정합니다. ( 경사하강법, 오차함수를 정의해줍니다. )
model.compile(optimizer='Adam', 
                     loss = 'binary_crossentropy', 
                     metrics=['acc'])  # 학습과정에서 정확도를 보려고 

#6. 모델을 훈련시킵니다. 
from tensorflow.keras.callbacks import EarlyStopping

# 콜백을 정의합니다.
callbacks = [EarlyStopping(monitor = 'val_acc', patience = 20, verbose = 1)]

# callbacks 인자를 통해 정의한 콜백을 전달합니다.
history= model.fit(x_train, y_train,
         batch_size = 100,
         validation_data = (x_test, y_test),
         epochs = 100 ,
         callbacks = callbacks)

# 7.모델을 평가합니다. (오차, 정확도가 출력됩니다.)
model.evaluate(x_test, y_test)

# 시각화를 위해 데이터 수집 
train_acc_list=history.history['acc']   # 훈련 데이터의 정확도
train_acc_list

test_acc_list=history.history['val_acc']  # 테스트 데이터의 정확도
test_acc_list

import  matplotlib.pyplot  as  plt

x = np.arange( len(train_acc_list) )
plt.plot( x, train_acc_list, label='train acc')
plt.plot( x, test_acc_list, label='test acc',  linestyle='--')
plt.ylim(0, 1)
plt.legend(loc='lower right')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.show()

model.save('leaf_model2.h5')  # 이파리 모델을 저장합니다. 

■ 이파리 사진 한장을 신경망에 넣고 잘 맞추는지 확인하기 

1. 아래의 4개의 사진을 준비합니다.

1.jpg	3.jpg	18988.jpg	18993.jpg

2. /content/drive/MyDrive/leaf/ 밑에 img 라는 폴더를 만들고 여기에 위의 4개의 
   파일을 올리세요

문제275. (점심시간 문제) 정상 이파리와 질병 이파리를 한장씩 신경망에 넣고 잘 맞추는지
             확인하는 결과 화면을 올려주세요 ~

훈련: 0.99
테스트:0.87

내가 직접 만든 신경망 활용 홈페이지 주소를 이력서에 첨부

■ 웹에서 내가 직접 스크롤링한 이미지를 학습 시켜서 분류하기 

1. 이미지 2가지를 선택하세요( 예: 파인애플, 사과 )

2. 사과는 1번 ~ 800번까지 받았습니다.

3. 파인애플을 801번 ~  1563번까지 받았습니다.

4. 사과와 파인애플 1번 ~ 1563번을 전부 train 이라는 폴더에 담으시오

5. c 드라이브 밑에 dataset 밑에 apple_test 라는 폴더를 만드세요

6. c 드라이브 밑에 dataset 밑에 pineapple_test 라는 폴더를 만드세요

7. 빙에서 과일 사과로 검색했을때의 이미지들을 c:\\dataset\\test_apple 폴더에 다운받게
    하시오! ( 1번~ 50번까지만 사용할 것 입니다.)


8. 빙에서 파인애플로 검색했을때의 이미지들을 c:\\dataset\\test_pineapple 폴더에 
    다운받게 하시오 (51번부터 시작하세요)


9.  test 폴더를 만드시고 test 폴더에 test_apple 폴더의 사과 이미지를 1번~50번 까지를
     test 폴더에 복사하시고 test_pineapple 폴더의 51~100번까지를 test 폴더에 복사하세요


10. train 폴더와 test 폴더를 각각 압축하세요 !  

문제275.  위의 우리가 스크롤링한 이미지를 분류하는 신경망의 테스트 데이터의 정확도를
             0.80 이 넘게 하시오 !

훈련 : acc: 0.9987 , 테스트 : val_acc: 0.9100


문제276.  /content/drive/MyDrive/fruit2/fruit_model2.h5 모델을 불어와서 새로운 모델을 
             만들과 사과와 파인애플 이미지를 잘 맞추는지 확인하시오 !

 사과: 2.jpg, 12, jpg
 파인애플:   51.jpg,  53.jpg


문제277. (오늘의 마지막 문제)  내가 웹스크롤링한 이미지를 분류하는 신경망이
             테스트 사진을 잘 맞추는지 결과를 올리시오 !


■ 딥러닝 수업 복습 

1장. numpy 사용법
2장. 퍼셉트론
3장. 3층 신경망(저자가 만들어온 가중치로 구성)
4장. 2층 신경망 (수치미분으로 학습해서 구성)
5장. 2층 신경망 (오차 역전파로 학습해서 구성)
6장. 신경망의 정확도를 높이는 방법들과 오버피팅을 줄이기 위한 방법들
7장.  CNN 

  1. mnist
  2. 이파리
  3. 직접 스크롤링한 사진들 
 
모델 설계는 우리가 직접 설계를 해서 정확도를 높여보았습니다. 그리고 오버피팅도 줄이기 위해서
dropout 도 적절히 설정을 했었습니다.
오늘 배울 내용은 유명한 cnn 신경망 설계도를 가져와서 학습을 시켜볼 것입니다. 

■ 대표적인 CNN (p 257)

1. 고전 CNN LeNet  

 LeNet 은 손글씨 숫자를 인식하는 신경망으로 1998년에 제안되었습니다.
  요즘 신경망과의 차이는 활성화인데 요즘에는 주로 Relu 를 사용합니다. 
  
그림 7-27


CNN 알고리즘의 시초 신경망, MNIST 데이터를 만든 얀루쿤에 의해 개발
지금은 28*28 사이즈를 사용했는데 그 당시에는 32*32 사이즈로 신경망에 넣었습니다.

이미지 (32*32) ---> conv ---> maxpooling ---> conv ---> maxpooling ---> fully connected1
---> fully connected2 ----> fully connected3(출력층) ---> output

문제278.  cnn 을 사용하지 않고 cifar10 데이터 셋을 분류 하시오 !

코드:  https://cafe.daum.net/oracleoracle/Shyl/861

500/500 [==============================] - 1s 2ms/step - loss: 1.5913 - acc: 0.4331
313/313 [==============================] - 1s 2ms/step - loss: 1.6999 - acc: 0.3901
[1.6998504400253296, 0.39010000228881836]

30에폭 수행:

cnn 을 사용하지 않았을때는 훈련 데이터의 정확도가 0.43이고 테스트 데이터의 정확도가 0.39 
입니다. 

문제280. 1998년도에 나온 고전 cnn 인 LeNet  설계도로 문제281번의 모델을 설계하고 
             수행해서 정확도를 확인하시오 !

힌트:  이미지 --> conv--> pooling -->conv --> pooling --> fc1 ---> fc2 --->fc3 --> output 

Epoch 30/30
500/500 [==============================] - 3s 6ms/step - loss: 0.2063 - acc: 0.9347
313/313 [==============================] - 1s 3ms/step - loss: 1.3570 - acc: 0.6640
[1.3570257425308228, 0.6639999747276306]

1. cnn 안썼을 때 : 훈련 : 0.43, 테스트: 0.39
2. Lenet 신경망일때: 훈련: 0.93, 테스트: 0.66

■ 8장. 딥러닝의 역사 

게시글: 859 [쉬움주의] 8장. 딥러닝의 역사

▩ vgg 신경망 

 VGG 신경망은 옥스포드 대학의 연구팀 VGG 에 의해 개발된 모델로써, 2014년 이미넷 이미지 인식
  대회에서 준우승한 모델입니다.  VGGnet 은 16개 또는 19개의 층으로 구성된 모델입니다.
  역사적으로 봤을때 vggnet 모델부터 시작해서 네트워크의 깊이가 확 깊어졌습니다.
  
처음에는 8개의 층으로 구성되었었는데 나중에는 22층까지 구성이 되었습니다.
그런데 보통 vgg16 즉 16층으로 구성한 모델이 가장 정확도가 좋은 성능을 보입니다.
층을 더 깊게 쌓는다고 더 좋은 효과를 보이지는 않아서 보통 vgg16을 많이 사용합니다.

게시글 858번 [쉬움주의] 옥스포드 대학교 신경망 설계도 vgg16

■ 텐써플로우 2.0 의 전이학습 기능 

 전이학습은 사전에 학습된 네트워크의 가중치 또는 이미지 넷 대회에서 우승한 유명한 신경망
 모델을 가져와서 사용하는 기능을 말합니다. 

예제: 이미 짜여진 설계도 가져오기 

from   tensorflow.keras.applications  import VGG16

model = VGG16(weights='imagenet', input_shape=(32, 32, 3), include_top=False)

설명:   weights :  imagenet 대회에서 제공한 이미지들을 학습 시킨 가중치의 사용여부를 결정
                       합니다. 기본값은 None

                      weights='imagenet'  ---> 이미지넷 대회에서 준우승한 그 가중치를 사용하겠다.
                      weights='None' ---->  이미지넷 대회에서 준우승한 그 가중치를 사용안하겠다.
          include_top : 완전 연결계층의 모델의 분류기를 내가 직접 기술할지 말지를 결정한다. 
                            False 로 하게 되면 내가 직접 완전연결계층을 짜겠다.

문제281. 문제280 에서 분류한 cifar10 이미지를 vgg16 신경망으로 학습해서 분류하시오 !

코드: https://cafe.daum.net/oracleoracle/Shyl/790

※ VGG 외에 전이학습 시킬수 있는 유명한 신경망들

1.  구글에서 만든 인셉션 

from tensorflow.keras.applications  import  * 
xception = Xception(weights =None, input_shape=None, include_top=True)

2.  Resnet 신경망 (신경망이 깊어질때의 생길수 있는 문제점(기울기 소실)을 해결한 신경망)
      
from tensorflow.keras.applications  import  * 
resnet50 = ResNet50(weights =None, input_shape=None, include_top=True)

3. mobilenet ( 가벼우면서 성능이 아주 좋은 신경망)

from tensorflow.keras.applications  import  * 
mobilenet = MobileNet(weighs=None, input_shape=None, include_top=True)

사용할때:  

mobilenet = MobileNet(weighs='imagenet', input_shape=(32,32,3), include_top=False)


Epoch 45/200
450/450 [==]- 13s 29ms/step - loss: 0.0128 - acc: 0.9962 - val_loss: 0.8082 - val_acc: 0.8526
Epoch 00045: early stopping

문제282. (점심시간 문제)  지금 위의 코드는 완전 연결계층이 1층과 2층인데 한층 더 늘려서
     1층(256), 2층(256), 3층(10) 으로 완전 연결계층을 구성하시오 !

 답글로 코드 올리시고 식사하세요 ~  그럼 즐거운 식사 시간 되세요 ~~

■ 문제282번에서 생성한 모델을 불러와서 그 모델로 인터넷에서 다운받은 이미지를 분류해보기

cifar10 데이셋 설명:

0. 비행기
1. 자동차
2. 새
3. 고양이
4. 사슴
5. 개
6. 개구리
7. 말
8. 배
9. 트럭 

문제283. 인터넷에서 말 사진을 하나 캡쳐해서 2.jpg 로 저장하시오 !

https://cafe.daum.net/oracleoracle/Shyl/791

1. 인터넷에서 비행기(0), 자동차(1), 새(2), 고양이(3), 사슴(4), 개(5), 개구리(6), 말(7), 배(8), 트럭(9) 
  사진중 하나를  다운로드 받습니다.

2. 말사진 2.jpg 를 코렙에 올립니다. 

3. 이미지 데이터를 전처리 합니다.

4. 이미지를 신경망에 넣고 예측합니다. 

 2.jpg 는  는 말로 잘 맞추었습니다.

문제284.  아래의 이미지중에 하나를 골라서 인터넷에서 사진을 하나 다운로드 받고 신경망에
              넣고 잘 맞추는지 확인하시오 !

0. 비행기
1. 자동차
2. 새
3. 고양이
4. 사슴
5. 개
6. 개구리
7. 말
8. 배
9. 트럭 

문제285. 위와 같이 숫자로 출력되는게 아니라 아래와 같이 출력되게하시오 !

개구리로 예측하였습니다.

cifar_dict ={ 0:'비행기',
                 1: '자동차',
                 2: '새',
                 3: '고양이',
                 4: '사슴',
                 5: '개',
                 6: '개구리',
                 7: '말',
                 8: '배',
                 9: '트럭' } 

a = np.argmax(results)
print('신경망이 ' + cifar_dict[a] + '로 예측하였습니다.')


문제286. 기울기 소실을 최소화하는 resnet 신경망을 전이학습 시켜서 cifar10 데이터셋을 분류하는 
             신경망 모델을 cifar10_resnet.h5 라는 이름으로 만드시오 !

힌트:  1.  구글에서 만든 인셉션 

from tensorflow.keras.applications  import  * 
resnet50 = ResNet50(weights =None, input_shape=None, include_top=True)

문제287.  가벼우면서도 성능이 아주 우수한 mobilenet 신경망으로 cifar10 데이터셋을 분류하는
             신경망 모델을 cifar10_mobile.h5 라는 이름으로 만드시오 

힌트:  mobilenet = MobileNet(weights='imagenet', input_shape=(32,32,3), include_top=False)


■ 사과와 파인애플을 분류하는 신경망에 vgg 신경망을 전이학습 시키기 

문제288. (오늘의 마지막 문제) 내가 웹스크롤링해서 받은 이미지들을 분류하는 신경망에
              vgg 신경망을 전이학습 시켜서 훈련 데이터의 정확도와 테스트 데이터의 정확도를
              출력하고 모델을 생성해서 다운로드 받으시오 !

 결과 화면: 훈련 정확도와 테스트 정확도를 올려주세요 ~~~

나머지 시간은 자유롭게 시험공부 또는 포트폴리오 조 구성을 하시면 되겠습니다. 

책 270 페이지 나오는 vgg 신경망을 어제 살펴 보았습니다. 


■ 사물검출 (p278)

지금까지는 사진 전체를 분류하는 신경망을 생성했습니다. 예를들어 파인애플인지 사과인지
를 알아맞추는 인공지능 신경망을 생성했습니다.  그런데 지금부터는 사진속에 각각의 사물이
무엇인지 알아맞추는 신경망을 생성해보도록 하겠습니다. 

그림 8-17

사물검출 관련 딥러닝 활용사례:

 1. 파라바게트의 빵 스캔후 자동 계산
 2. cctv 영상속 도둑감지 사례

 이론 설명: 게시글 895  [쉬움주의] 사진 속에 사물 검출(object detection)

yolo 진행 순서

1.  사람 또는 자전거와 같이 사진이 어떤 사진인지 학습된 신경망이 준비가 되어있어야합니다.

2.  이미지가 한장이 들어오면 이미지를 여러개의 격자로 나눠서(수천장) 그 여러개의 격자중에
     사물이 있을 확률이 높은 격자만 선별합니다.  사물이 있을 확률이 높은 격자를 선택하는
      파이썬 모듈이 region proposal 입니다.  이때 사용하는 알고리즘은 selective search 알고리즘
      입니다.  그런데 yolo 는 사물이 있을 확률이 높은 격자를 선택할 때 회귀를 이용해서 속도 개선
      을 했습니다.  신경망에 이미지를 넣고 분류하는 것보다 시간이 가장 많이 걸리는 부분은
       이미지에서 사물을 검출하는 영역을 찾는것인데 이것이 yolo 이전에는 fast rcnn 이라는 모델로
      그 영역을 찾았습니다. 그런데 시간이 너무 많이 걸렸습니다. 그래서 yolo 가 이부분을 회귀를 
       이용해서 찾도록 개선을 해서 속도를 높였습니다.  

3. 사물이 있는 격자를 찾았으면 그 격자를 신경망에 넣고 사람인지 자전거인지 분류를 합니다.

4. 원본 이미지에 바운딩해서 사람인지 자전거인지 나타냅니다. 

■ 주로 사용하는 yolo 버전

  yolo v4  와  yolo  v5 가 있는데 yolo v4 버전보다 yolo v5 버전에 속도가 더 빠릅니다.
  그러나 정확도가 v4 보다 다소 떨어집니다. 속도와 성능이 서로 trade off 관계입니다. 
  이게 yolo 의 단점입니다.  yolo 를 이용해서 사물검출을 하는 신경망을 생성하고자 한다면
   v5 보다는 v4 를 사용하길 더 추천합니다. 
 
  yolo v5 는 파이토치를 기반으로 구축된 모델이고 yolo v4 는 다크넷을 기반으로 구축된 모델입니다
  yolo v4 가 느리지만 훨씬 안정적입니다.  


문제289.  다른 이미지를 넣어서 사물검출을 하고 카페에 사물검출한 결과를 올려주세요 ~


■ 동영상 속 사물 검출 

문제290.  다른 동영상으로 사물검출을 하는데 인천공항 홍보영상을 사물 검출하시오 !

1. 먼저 이름을 변경합니다.

[인천공항] 2019 인천국제공항 홍보 영상.mp4  --->  airport.mp4

2. 코렙에 올립니다.  

/content/gdrive/MyDrive/yolo-v3/data/video

3. 사물 검출을 실행합니다.

!python detect.py video 0.5 0.5 /content/gdrive/MyDrive/yolo-v3/data/video/airport.mp4

문제290. (점심시간 문제)  점심시간에 오브젝트 디텍션을 하고 싶은 영상을 준비하세요 ~ 

  강남거리를 찍어도 되고 자유롭게 준비하세요 ~~   즐거운 점심시간 되세요 ~


지금까지 작업한 사진속에 사물 검출 작업은 누군가가 이미 만들어온 가중치로 분류를 하는거라서
내가 검출하고 싶은 사물을 인식하지 못하는 가중치 입니다. 
파리바게트의 빵처럼 내가 검출하고 싶은 이미지로 사물검출을 하고 싶다면 직접 사진을 웹스크롤링
해서 학습하기 좋은 사진을 잘 골라내고 하나씩 라벨링을 해줘야합니다.

라벨링 된 데이터를 신경망에 넣고 학습을 시켜야 합니다. ( 이미지 400장에  4시간정도 소요됩니다)
코렙으로 돌렸을때

■ 내가 직접 고른 이미지의 사물을 검출하기 위해 라벨링 하는 방법 

1.  신발 뉴발란스 신발 사진들을 웹스크롤링하고 쓸만한 사진 100장만 남겨둔다

2. 신발 컨버스를 brand2 폴더에 웹스크롤링하고 쓸만한 사진 100장만 남겨둡니다.

3. shose 라는 폴더를 만들고 여기에 brand1 이미지와 brand2 이미지를 모아둡니다.

4. shose 에 있는 신발 사진들의 숫자를 1번 부터 200 번으로 수정하시오

아나콘다 프롬프트창을 엽니다. 

C:\dataset\shoes <-- 여기로 이동합니다.

(base) C:\dataset\shoes>jupyter notebook

5. 번호를 1번 ~200번으로 변경합니다.

import os
count = 1
for i in os.listdir():
    os.rename(i, str(count)+'.'+i.split('.')[-1])
    count+=1

신호 보냈습니다. ~~ 45분까지 쉬세요 ~~

잘 안되는거 있으면 질문하세요 ~~

1시간동안 오늘 시험볼 서술형 시험 미리 답을 준비하시던지 또는
포트폴리오 조별로 포트폴리오 계획및 준비를 하던지 또는
시험공부 하고 계세요 ~~

문제290.[ 오늘의 마지막 문제] 자신이 학습한 object detection 한 결과 이미지를 올려주세요


마지막 문제 올리시고 자유롭게 4시까지 시험 공부 또는 포트폴리오 계획 및 
object detection 테스트 하세요 ~~~

4시 시험 오늘은 통합구현 서술형 시험 10문제 입니다.

시험 진행해주세요 ~~

■ 적대적 신경망 (gan) p 284

문제291. (오늘의 마지막 문제) 위의 데이터를 fashion mnist 데이터로 변경해서 이미지를
             생성하고 저장하시오  

 gif 파일로 올려주세요 ~~~

■ 미술작품으로 변환 p284 

문제292. (오늘의 마지막 문제) 여러분들 정한 원본 이미지와 미술 작품으로 스타일 변환을 하세요


 신호 보냈습니다.  

 나머지 시간은 자유롭게 포트폴리오 또는 시험 공부하세요 ~

 4시에 마지막 시험 (인터페이스 설계) 있습니다.   잘 안되거나 모르는거 있으면 언제든 질문하세요 ~~
 에플리케이션 요구사항(pdf) 시험 제출물이 하나 더 남았습니다. 이 시험은 제출물로 대체할것인데
 딥러닝으로 카페에 올렸던 마지막 문제들 중 하나를 선택해서 코드와 결과 이미지를 
 pdf 로 만들어서 주말과 대체공휴일중에 에플리케이션 요구사항에 올려주세요 !

 카페에 올렸던 딥러닝 마지막 문제 다음중 하나를 선택해서 pdf 로 만들어 주세요.

 1.  일반 사진 미술 작품으로 변환(오늘 마지막 문제)
 2. 사물검출 마지막 문제(예: 신발 분류)
 3. 기타 이미지가 있었던 마지막 문제들중 하나를 자유롭게 선택하세요 ~

 pdf 로 만들어서 시험 사이트에 에플리케이션 요구사항에 올려주세요 ~ 
 주제명과 코드와 결과 이미지만 붙이면 됩니다. 

  그리고 R 머신러닝 포트폴리오(ppt)를 탐색적 데이터 분석에 올렸는데
  분석용 데이터 구축과 텍스트 데이터 분석에도 같은 포트폴리오를 각각 올려주세요 

■  딥러닝 모델을 활용하는 UI (User  Interface) 만들기 

UI 와 홈페이지를 R shiny 로 생성하겠습니다.

파이썬에서는 모델을 만들면 되고 유져 인터페이스는 R Studio 로 만들면 됩니다.  

VGG16_Model_v1.h5  <--- 파이썬이나 코렙에서는 모델만 생성하면 됩니다.

▩ R studio 에서 R shiny 를 이용할 수 있도록 환경구성 

1. 첫번째 확인작업 :  R 버전을  4.0.5  로 구성해야합니다.

 확인작업:  R studio 에서 tools ---> global option --> general --> 옆에 R 버젼이 나옵니다. 

1. R 버전을 4.0.5 버전을 설치합니다.

https://cran.r-project.org/bin/windows/base/old/4.0.5/

설치가 다 되었으면  R studio 에서 tools ---> global option --> general 여기서
change 버튼을 누르고 R 버전을 4.0.5 로 변경합니다.

2. 두번째 확인작업:  파이썬 버전은 3.8.8로 구성하길 권장합니다.

아나콘다 프롬프트창을 열고  python --version


파이썬이 필요한 이유는 이미지를 시각화를 하려면 Pillow 가 필요한데 그 Pillow 를 
사용하기 위해서 파이썬이 필요하고 그리고 모델을 불러오려면 tensorflow 와 keras 도 필요한데
그것도 파이썬에 있는 tensorflow 와 keras 를 R 에서 사용하기 때문에 파이썬이 필요합니다.

나중에 혹시 이미지가 ui 에 안뜨면 파이썬을 재설치하면 되는데 
파이썬을 재설치하는 방법은 제어판에서 python 을 삭제합니다.  그리고
구글에서 파이썬 3.8.8 설치로 검색하고 설치하시면 됩니다.

■ R 샤이니란 ?

    사용자 유져 인터페이스를 쉽고 간단하게 구현할 수 있도록 R studio 에서 제공하는 패키지
    홈페이지를 무료로 편하게 띄울수가 있고 사용자가 늘어나면 유료로 전환하면 되는 
    간단한 ui 와 홈페이지 제작 패키지입니다.

■ R 샤이니의 기본 골격 

    유져인터페이스 와   서버 로 나뉩니다. 
          ↓                      ↓
    frontier (화면)        backend  tier(화면에서 요청한 데이터를 처리하는 부분)

■ 샤이니를 실행하기 위한 패키지를 설치 

install.packages("DT")  # javascript 라이브러리 설치 
install.packages("shiny") # 샤이니 패키지 설치 
install.packages("ggplot2")

library(DT)
library(shiny)
library(ggplot2)

■ 샤이니의 큰 골격 코드 

1. 화면 개발  :  ui  <- 코드 작성 ...

2. 서버단 개발 :  server <-   서버단 코드 작성 ...

3. 실행하는 명령어 : shinyApp( ui=ui, server=server)

■ 샤이니의 기본 화면을 실행하는 방법

library(shiny)

ui <- fluidPage(                  )

server  <-  function( input, output) {       } 

shinyApp(  ui = ui,  server = server )

■ shiny ui 에 내용을 추가하는 방법 

예제1. 타이틀 명시하기 

library(shiny)

ui <- fluidPage(             
                  titlePanel("개와 고양이를 분류하는  인공신경망")
                                     )

server  <-  function( input, output) {       } 

shinyApp(  ui = ui,  server = server )

예제2. 글씨 크기를 조정하는 방법 

library(shiny)

ui <- fluidPage(             
  titlePanel(h2("개와 고양이를 분류하는  인공신경망")),
             br(),
             h2("개의 종류는 5가지로 분류를 했습니다.")
            
)

server  <-  function( input, output) {       } 

shinyApp(  ui = ui,  server = server )

예제3.  사이드바 만드는 방법 

library(shiny)

ui <- fluidPage(             
  titlePanel(h2("개와 고양이를 분류하는  인공신경망")),
             br(),
             h2("개의 종류는 5가지로 분류를 했습니다."),
)

server  <-  function( input, output) {       } 

shinyApp(  ui = ui,  server = server )

■ 샤이니 화면 개발 기능들 모아놓은 코드들

library(shiny)

# Define UI ----
ui <- fluidPage(
  titlePanel("Basic widgets"),
  fluidRow(
   
    column(3,
           h3("Buttons"),
           actionButton("action", "Action"),
           br(),
           br(), 
           submitButton("Submit")),    

    column(3,
           h3("Single checkbox"),
           checkboxInput("checkbox", "Choice A", value = TRUE)),

    column(3, 
           checkboxGroupInput("checkGroup", 
                              h3("Checkbox group"), 
                              choices = list("Choice 1" = 1, 
                                             "Choice 2" = 2, 
                                             "Choice 3" = 3),
                              selected = 1)),    

    column(3, 
           dateInput("date", 
                     h3("Date input"), 
                     value = "2014-01-01"))   
  ),

  fluidRow(
    column(3,
           dateRangeInput("dates", h3("Date range"))),
    column(3,
           fileInput("file", h3("File input"))),
    column(3, 
           h3("Help text"),
           helpText("Note: help text isn't a true widget,", 
                    "but it provides an easy way to add text to",
                    "accompany other widgets.")),
    column(3, 
           numericInput("num", 
                        h3("Numeric input"), 
                        value = 1))   
  ),

  fluidRow(
    column(3,
           radioButtons("radio", h3("Radio buttons"),
                        choices = list("Choice 1" = 1, "Choice 2" = 2,
                                       "Choice 3" = 3),selected = 1)),

    column(3,
           selectInput("select", h3("Select box"), 
                       choices = list("Choice 1" = 1, "Choice 2" = 2,
                                      "Choice 3" = 3), selected = 1)),

    column(3, 
           sliderInput("slider1", h3("Sliders"),
                       min = 0, max = 100, value = 50),
           sliderInput("slider2", "",
                       min = 0, max = 100, value = c(25, 75))
    ),   

    column(3, 
           textInput("text", h3("Text input"), 
                     value = "Enter text..."))   
  )
)

# Define server logic ----
server <- function(input, output) {
}

# Run the app ----

shinyApp(ui = ui, server = server)

■ csv파일을 불러와서 화면에 출력하는 샤이니 코드 

#install.packages("DT")

library(DT)
library(shiny)
library(ggplot2)

emp <- read.csv("d:\\data\\emp3.csv",header=T)

# Define UI ----
ui <- fluidPage(
  titlePanel("EMP DataTable"),  # 제목 
  
  DT::dataTableOutput("table")  # 패키지이름::함수("변수")
  # dataTableOutput 이라는 함수는 data 를 화면에 뿌려주는 자바스크립트 함수입니다.

)

# Define server logic ----
server <- function(input, output) {
  
  output$table <- DT::renderDataTable(DT::datatable({
   
    data <- emp
    
  }))
  
}

# Run the app ----

shinyApp(ui = ui, server = server)

문제293.  csv 파일을 emp3.csv 파일말고 다른 csv 파일을 불러와서 결과로 출력하시오 !


#install.packages("DT")

library(DT)
library(shiny)
library(ggplot2)

emp <- read.csv("d:\\data\\wisc_bc_data.csv",header=T)

# Define UI ----
ui <- fluidPage(
  titlePanel("EMP DataTable"),  # 제목 
  
  DT::dataTableOutput("table")  # 패키지이름::함수("변수")
  # dataTableOutput 이라는 함수는 data 를 화면에 뿌려주는 자바스크립트 함수입니다.

)

# Define server logic ----
server <- function(input, output) {
  
  output$table <- DT::renderDataTable(DT::datatable({
   
    data <- emp
    
  }))
  
}

# Run the app ----

shinyApp(ui = ui, server = server)


■ csv 파일을 불러와서 결과를 화면에 출력하는 방법

참고해야하는 코드:

   fileInput("file1", "Choose CSV File",   
            multiple = TRUE,
            accept = c("text/csv",
                       "text/comma-separated-values,text/plain",
                       ".csv"))

설명: 
      # file1 은 서버쪽에 csv 파일 파일 보낼때 필요한 이름
      # "Choose CSV File" 이 메세지가 화면에 나옵니다. 
      #  multiple = TRUE 는 csv 파일이나 text 이나 불러오는 포멧을 여러개하겠다.
      # accept =  csv 파일, text 파일, xls 파일 포멧을 기술하며 됩니다. 

점심 식사하시고 오후에는 조별 포트폴리오를 진행하면됩니다. 

2시 30분에 신호보내겠습니다. 그때 다시 오세요 ~~

수요일 : 9강의장, 3강의장 사용가능
금요일 : 9강의장, 3강의장 사용가능 

[공지 사항]

1. 내일하고 금요일(9강의장, 3강의장) 20명정도 가능하니까 나와서 회의하거나
   같이 포트폴리오를 할 조들은 미리 조장이 저에게 미리 애기해주세요

2. 코렙을 사용하는데 뒤에 GPU 피씨가 3대가 있어서 GPU 이용하고 싶다면 애기하세요 

3. 목요일날 머신러닝 포트폴리오 발표10분정도 대답

   심승혁, 전인훈, 서동민, 황세현, 허선우

  목요일날은 위의 5명만 교실에 오세요 ~~
  
신호 보냈습니다.   나머지 시간은 조별로 자유롭게 포트폴리오를 진행하시면 됩니다. 

교실 참석조는 미리 예약 주세요 ~~~
 
수요일 예약조: 심승혁, 서동민, 황세현, 오민석

목요일 참석인원:    심승혁, 전인훈, 서동민, 황세현, 허선우

금요일 예약조: 추해정, 허선우, 양남휘, 심승혁, 서동민, 황세현, 오민석, 
                    변명규, 편석영, 유승환, 이체린, 전수림

다음주 화요일 : 이승연외 2명(전인훈, 라태진), 변명규, 편석영, 유승환, 이체린, 전수림,
                      심승혁, 서동민, 황세현, 오민석
다음주 수요일 : 변명규, 편석영, 유승환, 이체린, 전수림
다음주 목요일 : 변명규, 편석영, 유승환, 이체린, 전수림,심승혁, 서동민, 황세현, 오민석
다음주 금요일 : 이승연외 2명(전인훈, 라태진), 변명규, 편석영, 유승환, 이체린, 전수림,
                     심승혁, 서동민, 황세현, 오민석





























































































  




































 











































































































































































































































































  




 



























































































































































  
























































































































                                                




































































































































 
















































































































































































































































































          































































 





















































































































































































































































































































































































 










